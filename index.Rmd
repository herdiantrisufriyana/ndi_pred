---
title: "Neonatal Outcomes AI Prediction using Multimodal Trajectory Database"
author: "Herdiantri Sufriyana, ..., ..., ..., Chao-Ching Huang, Emily Chia-Yu Su"
date: "2024-09-10"
output: html_document
---

# Programming environment

```{r Set random seed, include=FALSE, paged.print=FALSE}
seed <- 2024-09-10
```

```{r Load R packages, include=FALSE}
library(tidyverse)
library(knitr)
library(kableExtra)
library(ggpubr)
library(readxl)
library(broom)
library(MASS)
select <- dplyr::select
library(igraph)
library(ggnetwork)
library(brms)
library(broom.mixed)
library(pbapply)
library(mice)
filter <- dplyr::filter
cbind <- base::cbind
rbind <- base::rbind
library(parallel)
library(doParallel)
library(survival)
```

```{r Load custom functions, include=FALSE}
lapply(list.files("R/", pattern = "-function.R", full.names = TRUE), source)
```

```{r Set theme, include=FALSE}
dslabs::ds_theme_set()
kable_format <- "html"
```

# Load raw data

```{r List raw data paths, include=FALSE}
paths_old_name <-
  list.files(
    "inst/extdata/2011-202312_GA_22-30_838"
    , pattern = "\\.xlsx$"
    , full.names = TRUE
  )
```

```{r Write raw data path old names, eval=FALSE, include=FALSE}
data.frame(name = NA, path = paths_old_name)  |>
  write_csv("inst/extdata/paths_old_name.csv")
```

```{r Read raw data path new names, include=FALSE}
paths_new_name <-
  read_csv("inst/extdata/paths_new_name.csv", show_col_types = FALSE)
```

```{r table-1, echo=FALSE}
paths_new_name |>
  kable(
    caption = "Table 1. Raw data names and paths."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:2, extra_css = "vertical-align:top;")
```

```{r Read raw data, include=FALSE}
raw_data <-
  paths_new_name$path |>
  `names<-`(paths_new_name$name) |>
  lapply(read_xlsx, sheet = 1)
```

# Data preprocessing

## Data cleaning

```{r List raw data colnames, include=FALSE}
raw_data_old_colname <-
  raw_data |>
  imap(
    ~ data.frame(
        table = .y
        , old_colname = colnames(.x)
        , new_colname = NA
      )
  ) |>
  reduce(rbind)
```

```{r Write raw data old colnames, eval=FALSE, include=FALSE}
raw_data_old_colname |>
  write_csv("inst/extdata/raw_data_old_colname.csv")
```

```{r Read raw data new colnames, include=FALSE}
raw_data_new_colname <-
  read_csv("inst/extdata/raw_data_new_colname.csv", show_col_types = FALSE)
```

```{r table-2, echo=FALSE}
raw_data_new_colname |>
  mutate(table = ifelse(duplicated(table), "", table)) |>
  kable(
    caption = "Table 2. Raw data old and new column names."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:2, extra_css = "vertical-align:top;")
```

```{r Modify column names, include=FALSE}
raw_data1 <-
  raw_data |>
  imap(
    ~ .x |>
      `colnames<-`(
        data.frame(table = .y, old_colname = colnames(.x)) |>
          left_join(raw_data_new_colname, by = join_by(table, old_colname)) |>
          mutate(
            new_colname =
              ifelse(is.na(new_colname), old_colname, new_colname)
          ) |>
          pull(new_colname)
      )
  )
```

```{r Join raw data tables accordingly, include=FALSE}
raw_data2 <-
  raw_data1[!str_detect(names(raw_data1), "42d$|6w$")] |>
  reduce(\(x, y) left_join(x, y, by = join_by(id))) |>
  right_join(
    raw_data1[str_detect(names(raw_data1), "6w$")] |>
      reduce(\(x, y) left_join(x, y, by = join_by(id, t_wk)))
    , by = join_by(id, ga_wk)
  ) |>
  right_join(
    raw_data1[str_detect(names(raw_data1), "42d$")] |>
      reduce(\(x, y) left_join(x, y, by = join_by(id, t_day))) |>
      mutate(t_wk = ceiling(t_day / 7))
    , by = join_by(id, t_wk)
  ) |>
  select(-t_wk) |>
  select(id, t = t_day, everything())
```

```{r List raw data variable-types, include=FALSE}
variable_old_type <-
  data.frame(
    variable = colnames(raw_data2)
    , old_type = sapply(raw_data2, class)
    , new_type = NA
  )
```

```{r Write old variable-types, eval=FALSE, include=FALSE}
variable_old_type |>
  write_csv("inst/extdata/variable_old_type.csv")
```

```{r Read new variable-types, include=FALSE}
variable_new_type <-
  read_csv("inst/extdata/variable_new_type.csv", show_col_types = FALSE)
```

```{r table-3, echo=FALSE}
variable_new_type |>
  kable(
    caption = "Table 3. Raw data old and new variable types."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:2, extra_css = "vertical-align:top;")
```

```{r Modify variable-types, include=FALSE}
raw_data3 <-
  raw_data2 |>
  imap(
    ~ data.frame(
        value =
          ifelse(
            filter(variable_new_type, variable == .y)$new_type != "numeric"
            ,as.character
            ,as.numeric
          )(.x)
      ) |>
      `colnames<-`(.y)
  ) |>
  reduce(cbind)

raw_data3 <-
  unique(variable_new_type$new_type) |>
  `names<-`(unique(variable_new_type$new_type)) |>
  imap(
    ~ raw_data3 |>
      select_at(filter(variable_new_type, new_type == .x)$variable)
  )
```

```{r List raw data categories, include=FALSE}
raw_data_old_cat <-
  raw_data3$factor |>
  lapply(unique) |>
  lapply(sort) |>
  imap(~ data.frame(colname = .y, old_cat = .x, new_cat = NA)) |>
  reduce(rbind) |>
  mutate_at("colname", \(x) factor(x, unique(x)))
```

```{r Write raw data old categories, eval=FALSE, include=FALSE}
raw_data_old_cat |>
  write_csv("inst/extdata/raw_data_old_cat.csv")
```

```{r Read raw data new categories, include=FALSE}
raw_data_new_cat <-
  read_csv("inst/extdata/raw_data_new_cat.csv", show_col_types = FALSE) |>
  mutate_at("old_cat", as.character)
```

```{r table-4, echo=FALSE}
raw_data_new_cat |>
  kable(
    caption = "Table 4. Raw data old and new categories."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:2, extra_css = "vertical-align:top;")
```

```{r Modify categories, include=FALSE}
raw_data4 <- raw_data3

raw_data4$factor <-
  raw_data4$factor |>
  mutate(seq = seq(n())) |>
  gather(colname, old_cat, -seq) |>
  mutate_at("colname", \(x) factor(x, unique(x))) |>
  left_join(raw_data_new_cat, by = join_by(colname, old_cat)) |>
  select(-old_cat) |>
  spread(colname, new_cat) |>
  arrange(seq) |>
  select(-seq) |>
  mutate_all(as.factor)

raw_data4 <-
  raw_data4 |>
  reduce(cbind) |>
  select_at(colnames(raw_data2))
```

```{r table-5, echo=FALSE}
raw_data4 |>
  select(id, survive, death_age) |>
  unique() |>
  mutate(ms_death_age = is.na(death_age)) |>
  group_by(survive, ms_death_age) |>
  summarize(n = n(), .groups = "drop") |>
  kable(
    caption = "Table 5. Consistency check - survival and age of death."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:3, extra_css = "vertical-align:top;")
```

```{r table-6, echo=FALSE}
raw_data4 |>
  select_at(colnames(raw_data1$outcomes)) |>
  unique() |>
  select(-id, -survive) |>
  mutate_all(\(x) ifelse(is.na(x), "missing", "non-missing")) |>
  rename_all(\(x) paste0("ms_", x)) |>
  gather(variable, value, -ms_death_age) |>
  group_by(ms_death_age, variable, value) |>
  summarize(n = n(), .groups = "drop") |>
  spread(value, n, fill = 0) |>
  mutate(ms_death_age = ifelse(duplicated(ms_death_age), "", ms_death_age)) |>
  kable(
    caption = "Table 6. Consistency check - other outcomes and age of death."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:3, extra_css = "vertical-align:top;")
```

```{r table-7, echo=FALSE}
list(
    ceiled = mutate(raw_data4, t_death_age = ceiling(death_age))
    , rounded_plus1 = mutate(raw_data4, t_death_age = round(death_age) + 1)
    , floored_plus1 = mutate(raw_data4, t_death_age = floor(death_age) + 1)
  ) |>
  imap(
    ~ .x |>
      filter(survive == levels(survive)[1]) |>
      select_if(
        !colnames(.x)
        %in% c(
          colnames(select(raw_data1$demographic_surfactant_growth, -id))
          , colnames(select(raw_data1$outcomes, -id, -death_age))
          , colnames(select(raw_data1$morbidities_42d, -id))
        )
      ) |>
      mutate(
        t_wk = ceiling(t / 7)
        , t_wk_death_age = ceiling(t_death_age / 7)
      ) |>
      mutate(
        t_alive = ifelse(t <= t_death_age, "1-yes", "0-no")
        , t_wk_alive = ifelse(t_wk <= t_wk_death_age, "1-yes", "0-no")
      ) |>
      select(-death_age, -t_death_age, -t_wk_death_age) |>
      select(id, t, t_wk, t_alive, t_wk_alive, everything()) |>
      mutate_at(
        vars(-id, -t, -t_wk, -t_alive, -t_wk_alive)
        , \(x) ifelse(is.na(x), "missing", "non-missing")
      ) |>
      gather(variable, value, -id, -t, -t_wk, -t_alive, -t_wk_alive) |>
      mutate(
        t =
          ifelse(
            variable
            %in% unlist(
              lapply(raw_data1[str_detect(names(raw_data1), "6w$")], colnames)
            )
            , t_wk
            , t
          ) |>
          factor()
        , t_alive =
          ifelse(
            variable
            %in% unlist(
              lapply(raw_data1[str_detect(names(raw_data1), "6w$")], colnames)
            )
            , t_wk_alive
            , t_alive
          ) |>
          factor()
      ) |>
      select(-t_wk, -t_wk_alive) |>
      unique() |>
      mutate(
        variable = paste0("ms_", variable)
        ,variable = factor(variable, unique(variable))
      ) |>
      mutate(t_death_age_def = .y)
  ) |>
  reduce(rbind) |>
  mutate(t_death_age_def = factor(t_death_age_def, unique(t_death_age_def))) |>
  group_by(t_death_age_def, t_alive, variable, value) |>
  summarize(n = n(), .groups = "drop") |>
  spread(value, n, fill = 0) |>
  mutate(
    t_alive = as.character(t_alive)
    , t_alive =
      ifelse(
        duplicated(paste0(t_death_age_def, t_alive))
        , ""
        , t_alive
      )
    , t_death_age_def = as.character(t_death_age_def)
    , t_death_age_def = ifelse(duplicated(t_death_age_def), "", t_death_age_def)
  ) |>
  kable(
    caption =
      "Table 7. Consistency check - time-dependent variables and age of death."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:5, extra_css = "vertical-align:top;")
```

```{r Filter data up to death age if not survive, include=FALSE}
raw_data5 <-
  raw_data4 |>
  filter(is.na(death_age) | t <= (round(death_age) + 1))
```

```{r Finalize cleaned data, include=FALSE}
cleaned_data <- raw_data5
```

## Data partition

```{r Split data for each GA (week), include=FALSE}
# Determine whole set
whole_set <-
  cleaned_data |>
  select(id, ga_wk) |>
  unique()

# Split data by GA (week)
whole_id <-
  whole_set |>
  pull(ga_wk) |>
  unique() |>
  sort() |>
  lapply(\(x) filter(whole_set, ga_wk == x)$id)


# GA-wise partitioning
train_id <- list()
val_id <- list()
test_id <- list()

for(i in seq(length(whole_id))){
  set.seed(seed)
  
  test_id[[i]] <-
    whole_id[[i]] |>
    sample(size = round(0.2 * length(whole_id[[i]])), replace = FALSE)
  
  train_id[[i]] <- setdiff(whole_id[[i]], test_id[[i]])
  
  set.seed(seed)
  
  val_id[[i]] <-
    train_id[[i]] |>
    sample(size = round(0.2 * length(train_id[[i]])), replace = FALSE)
  
  train_id[[i]] <- setdiff(train_id[[i]], val_id[[i]])
}

whole_id <- reduce(whole_id, c)
train_id <- reduce(train_id, c)
val_id <- reduce(val_id, c)
test_id <- reduce(test_id, c)
```

```{r figure-1, fig.height=5, fig.width=7, include=FALSE}
whole_set |>
    mutate(
    set =
      case_when(
        id %in% train_id ~ "training"
        ,id %in% val_id ~ "validation"
        ,id %in% test_id ~ "test"
      ) |>
      factor(c("training", "validation", "test"))
  ) |>
  ggplot(aes(ga_wk)) +
  geom_histogram(binwidth = 1, color = "white") +
  facet_grid(set ~ ., scales = "free_y") +
  scale_x_continuous(breaks = seq(22, 30)) +
  theme(strip.text.y = element_text(angle = 0))
```

Figure 1. GA (week) distribution for each partition. GA, gestational week.

```{r Finalize inference data, include=FALSE}
infer_data <-
  cleaned_data |>
  filter(id %in% train_id)
```

## Numerical data transformation

```{r Separate categorical and numerical variables, include=FALSE}
cat_data <-
  infer_data |>
  select_if(!sapply(infer_data, is.numeric))

num_data <-
  infer_data |>
  select_if(sapply(infer_data, is.numeric))
```

```{r Normal QQ plots of numeric variables, include=FALSE}
normal_qq <-
  num_data |>
  imap(~ qq_plot_outlier(.x, .y))

normal_qq <-
  normal_qq |>
  length() |>
  seq() |>
  split(LETTERS[1:3]) |>
  data.frame() |>
  pmap(
    \(A, B, C)
    ggarrange(
      normal_qq[[A]]
      , normal_qq[[B]]
      , normal_qq[[C]]
      , ncol = 3
    )
  )

normal_qq <-
  ggarrange(
    normal_qq[[1]]
    , normal_qq[[2]]
    , normal_qq[[3]]
    , normal_qq[[4]]
    , normal_qq[[5]]
    , normal_qq[[6]]
    , normal_qq[[7]]
    , normal_qq[[8]]
    , normal_qq[[9]]
    , normal_qq[[10]]
    , ncol = 1
    , nrow = 10
  )
```

```{r figure-2, echo=FALSE, fig.height=50, fig.width=15}
normal_qq
```

Figure 2. QQ plot of numerical variables. QQ, quantile-to-quantile.

```{r Determine normality by QQ plot, include=FALSE}
var_num_normal_qq <-
  c("t"
    , "maternal_age"
    , "gravida"
    , "bbw_g"
    , "ga_wk"
    , "as1"
    , "as5"
    , "resuscitation_at_birth"
    , "steroid_antenatal"
    , "surfactant"
    , "bbw_z"
    , "bhc_z"
    , "resp_supp_agg_cum_day_qw"
    , "fio2_cum_day_qw"
    , "fio2_cum_level_qw"
    , "resp_supp_agg_cum_day_pct"
    , "fio2_cum_day_pct"
    , "fio2_cum_level_pct"
    , "steroid_postnatal"
    , "inotropic"
    , "blood_volume"
    , "transfusion"
    , "blood_culture"
    , "plt"
    , "wbc"
    , "feeding"
    , "nec"
    , "aki"
  )
```

```{r Numerical variables with normal distribution by QQ plots, echo=FALSE}
var_num_normal_qq |>
  paste0(collapse=', ') |>
  cat()
```

```{r Normality test of numerical variables, include=FALSE}
normal_test <-
  num_data |>
  select_if(!names(num_data) %in% var_num_normal_qq) |>
  lapply(
    \(x)
    suppressWarnings(
        ks.test(
          x
          , y = "pnorm"
          , mean = mean(x, na.rm = TRUE)
          , sd = sd(x, na.rm = TRUE)
        )
      )
  ) |>
  lapply(tidy) |>
  imap(~ mutate(.x, variable = .y)) |>
  lapply(select, variable, everything()) |>
  reduce(rbind)
```

```{r table-8, echo=FALSE}
normal_test |>
  select(-method) |>
  mutate_at("statistic", round, 3) |>
  arrange(p.value) |>
  mutate(variable = paste0(variable, ifelse(p.value<=0.05,"*",""))) |>
  mutate(p.value = ifelse(p.value<0.001, "<0.001", round(p.value,3))) |>
  kable(
    caption = "Table 8. Normality test."
    , format = kable_format
  ) |>
  footnote("*, p-value <=0.05, Shapiro-Wilk normality test.") |>
  kable_classic() |>
  column_spec(1:4, extra_css = "vertical-align:top;")
```

```{r Determine num variables that are not normally distributed, include=FALSE}
var_num_non_normal <-
  normal_test |>
  filter(p.value <= 0.05) |>
  pull(variable)
```

```{r Numerical variables that are not normally distributed, echo=FALSE}
var_num_non_normal |>
  paste0(collapse=', ') |>
  cat()
```

```{r Non-normal mumerical variables with 0, include=FALSE}
var_num_non_normal_with_zero <-
  num_data |>
  select_at(var_num_non_normal) |>
  lapply(\(x) x[!duplicated(x)]) |>
  lapply(\(x) x[!is.na(x)]) |>
  sapply(\(x) any(x==0)) |>
  which() |>
  names()
```

```{r Non-normal mumerical variables with <0, include=FALSE}
var_num_non_normal_with_neg <-
  num_data |>
  select_at(var_num_non_normal) |>
  lapply(\(x) x[!duplicated(x)]) |>
  lapply(\(x) x[!is.na(x)]) |>
  sapply(\(x) any(x<0)) |>
  which() |>
  names()
```

```{r Non-normal mumerical variables infinited exp, include=FALSE}
var_num_non_normal_with_inf_exp <-
  num_data |>
  select_at(var_num_non_normal) |>
  lapply(\(x) x[!duplicated(x)]) |>
  lapply(\(x) x[!is.na(x)]) |>
  sapply(\(x) any(is.infinite(exp(x)))) |>
  which() |>
  names()
```

```{r Determine choices for a transformation technique, include=FALSE}
trans_choice <-
  data.frame(variable = var_num_non_normal) |>
  mutate(
    log =
      ifelse(
        variable%in%var_num_non_normal_with_zero
        | variable%in%var_num_non_normal_with_neg
        , 0
        , 1
      )
    ,sqrt =
      ifelse(
        variable%in%var_num_non_normal_with_neg
        , 0
        , 1
      )
    ,inv =
      ifelse(
        variable%in%var_num_non_normal_with_zero
        | variable%in%var_num_non_normal_with_neg
        , 0
        , 1
      )
    ,log2 =
      ifelse(
        variable%in%var_num_non_normal_with_zero
        | variable%in%var_num_non_normal_with_neg
        , 0
        , 1
      )
    ,exp =
      ifelse(
        variable%in%var_num_non_normal_with_inf_exp
        , 0
        , 1
      )
    ,asinh = 1
    ,bct =
      ifelse(
        variable%in%var_num_non_normal_with_zero
        | variable%in%var_num_non_normal_with_neg
        , 0
        , 1
      )
  )
```

```{r Choices for a transformation technique, echo=FALSE}
trans_choice |>
  colnames() |>
  setdiff("variable") |>
  paste0(collapse=', ') |>
  cat()
```

```{r Simple transformations, include=FALSE}
simple_trans <-
  trans_choice |>
  gather(func, do, -variable) |>
  filter(do == 1) |>
  select(-do) |>
  filter(!func %in% c("bct"))

simple_trans <-
  simple_trans |>
  pull(func) |>
  unique() |>
  lapply(
    \(x)
    simple_trans |>
      filter(func == x) |>
      pull(variable) |>
      lapply(
        \(y)
        list(
            log = log
            , sqrt = sqrt
            , inv = \(x) 1/x
            , log2 = log2
            , exp = exp
            , asinh = asinh
          )[[x]](num_data[[y]]) |>
          as.data.frame() |>
          `colnames<-`(y)
      ) |>
       `names<-`(
         simple_trans |>
          filter(func == x) |>
          pull(variable)
       )
  ) |>
  `names<-`(unique(simple_trans$func))
```

```{r Box-Cox transformation (BCT), include=FALSE}
bc_trans <-
  trans_choice |>
  gather(func, do, -variable) |>
  filter(do == 1) |>
  select(-do) |>
  filter(func %in% c("bct")) |>
  pull(variable)

bc_trans <-
  bc_trans |>
  `names<-`(as.character(bc_trans)) |>
  as.list()

for(i in names(bc_trans)){
  bc_trans[[i]]=
    boxcox(
      lm(num_data[[i]] ~ 1)
      , lambda = seq(-2, 2, by = 0.1)
      , plot = F
    ) |>
    c(list(value = num_data[[i]]))
}

rm(i)

bc_trans=
  bc_trans |>
  lapply(
    \(x)
    list(
      rep(NA, length(x$value))
       ,(x$value^(x$x[which.max(x$y)]) - 1) / x$x[which.max(x$y)]
    )[[ifelse(abs(x$x[which.max(x$y)]) < 1e-10, 1, 2)
    ]]
  ) |>
  imap(
    ~ data.frame(trans=.x) |>
      `colnames<-`(.y)
  )

bc_trans <-
  bc_trans[sapply(bc_trans, \(x) !all(is.na(x[[1]])))]
```

```{r Normality test of transformed numerical variables, include=FALSE}
normal_test_after_trans <-
  simple_trans |>
  c(list(bct = bc_trans)) |>
  imap(
    ~ .x |>
      lapply(
        \(x)
        suppressWarnings(
            ks.test(
              x[[1]]
              , y = "pnorm"
              , mean = mean(x[[1]], na.rm = TRUE)
              , sd = sd(x[[1]], na.rm = TRUE)
            )
          )
      ) |>
      lapply(tidy) |>
      imap(~ mutate(.x, variable = .y)) |>
      reduce(rbind) |>
      mutate(func = .y)
  ) |>
  reduce(rbind) |>
  select(func, variable, p.value) |>
  mutate_at("func", \(x) factor(x, unique(x))) |>
  group_by(variable) |>
  mutate(best_trans = func[which.max(p.value)]) |>
  ungroup() |>
  spread(func, p.value) |>
  right_join(
    data.frame(variable = var_num_non_normal)
    , by = join_by(variable)
  ) |>
  mutate(
    p.value=
      ifelse(
        best_trans == "log"
        , log
        , ifelse(
          best_trans == "sqrt"
          , sqrt
          , ifelse(
            best_trans == "inv"
            , inv
            , ifelse(
              best_trans == "log2"
              , log2
              , ifelse(
                best_trans == "exp"
                , exp
                , ifelse(
                  best_trans == "asinh"
                  , asinh
                  , bct
                )
              )
            )
          )
        )
      )
  ) |>
  select(variable, best_trans, p.value, everything())
```

```{r table-9, echo=FALSE}
normal_test_after_trans |>
  mutate(variable = paste0(variable, ifelse(p.value <= 0.05, "*", ""))) |>
  arrange(p.value) |>
  mutate_if(is.numeric, \(x) ifelse(x < 0.001, "<0.001", round(x, 3))) |>
  mutate_if(is.numeric, as.character) |>
  kable(
    caption = "Table 9. Normality test after transformation."
    , format = kable_format
  ) |>
  footnote("*, p-value <=0.05, Shapiro-Wilk normality test.") |>
  kable_classic() |>
  column_spec(1:10, extra_css = "vertical-align:top;")
```

```{r Determine num vars that are not normal after transformed, include=FALSE}
var_num_non_normal_after_trans <-
  normal_test_after_trans |>
  filter(p.value <= 0.05) |>
  pull(variable)
```

```{r Numerical variables that are not normal after transformation, echo=FALSE}
var_num_non_normal_after_trans |>
  paste0(collapse = ", ") |>
  cat()
```

```{r Finalize transformed data, include=FALSE}
transformed_data <-
  num_data |>
  cbind(cat_data) |>
  select_at(colnames(infer_data))
```

# Outlier analysis

```{r Determine exception for outlier analysis, include=FALSE}
trans_ps_num_exception <-
  c("t"
    ,"maternal_age"
    , "gravida"
    , "bbw_g"
    , "ga_wk"
    , "as1"
    , "as5"
    , "resuscitation_at_birth"
    , "steroid_antenatal"
    , "surfactant"
    , "bbw_z"
    , "bhc_z"
    , "death_age"
    , "resp_supp_agg_cum_day_qw"
    , "fio2_cum_day_qw"
    , "fio2_cum_level_qw"
    , "resp_supp_agg_cum_day_pct"
    , "fio2_cum_day_pct"
    , "fio2_cum_level_pct"
    , "steroid_postnatal"
    , "fio2_raw"
    , "inotropic"
    , "blood_volume"
    , "transfusion"
    , "blood_culture"
    , "plt"
    , "wbc"
    , "feeding"
    , "nec"
    , "aki"
  )
```

```{r Numerical var after transformation, include=FALSE}
trans_ps_num_data <-
  transformed_data |>
  select_if(sapply(transformed_data, is.numeric))

trans_ps_num_data <-
  trans_ps_num_data |>
  select_at(setdiff(colnames(trans_ps_num_data), trans_ps_num_exception))
```

```{r Relevant numerical var after transformation, echo=FALSE}
trans_ps_num_data |>
  colnames() |>
  paste0(collapse = ", ") |>
  cat()
```

# Correlation matrix

```{r Identify and create missingness variables, include=FALSE}
ms_added_data0 <-
  transformed_data |>
  select(-id) |>
  sapply(\(x) any(is.na(x))) |>
  which() |>
  names() |>
  lapply(
    \(x)
    transformed_data |>
      select_at(x) |>
      `colnames<-`("value") |>
      mutate(value = ifelse(is.na(value), "yes", "no")) |>
      `colnames<-`(paste0("ms_", x))
  ) |>
  reduce(cbind) |>
  cbind(mutate(transformed_data, t_wk = ceiling(t / 7))) |>
  select(id, t_wk, t, everything())

ms_added_data <-
  ms_added_data0 |>
  select(-id)
```

```{r Check categorical variables with a category of 1 value, include=FALSE}
var_cat_val1 <-
  ms_added_data |>
  select_if(!sapply(ms_added_data, is.numeric)) |>
  mutate_all(as.character) |>
  gather(variable, value) |>
  group_by_all() |>
  summarize(n = n(), .groups = "drop") |>
  filter(n <= 1) |>
  pull(variable) |>
  unique()
```

```{r Categorical variables with a category of 1 value, echo=FALSE}
var_cat_val1 %>%
  paste0(collapse=', ') %>%
  cat()
```

```{r Pair-wise distribution of categorical variables, include=FALSE}
pairwise_cat_sum <-
  ms_added_data |>
  select_if(
    !sapply(ms_added_data, is.numeric)
    & !colnames(ms_added_data) %in% var_cat_val1
  ) |>
  colnames() |>
  combn(2) |>
  as.data.frame() |>
  lapply(
    \(x)
    ms_added_data |>
      select_at(x) |>
      group_by_all() |>
      summarize(n = n(), .groups = "drop") |>
      select_at(c(x, "n")) |>
      `colnames<-`(c("V1_value", "V2_value", "n")) |>
      mutate(V1 = x[1], V2 = x[2])
  ) |>
  lapply(
    \(x)
    expand.grid(
      V1_value = unique(x$V1_value)
      , V2_value = unique(x$V2_value)
      ) |>
      mutate_all(as.character) |>
      left_join(x, by = join_by(V1_value, V2_value)) |>
      mutate_at("n", \(x) ifelse(is.na(x), 0, x)) |>
      fill(V1, V2)
  ) |>
  reduce(rbind) |>
  select(V1, V1_value, V2, V2_value, everything())
```

```{r Pair-wise perfect separation, include=FALSE}
pairwise_cat_sum_ps <-
  pairwise_cat_sum |>
  group_by(V1, V2) |>
  summarize(ps = any(n == 0), .groups = "drop")
```

```{r table-10, echo=FALSE}
pairwise_cat_sum |>
  inner_join(
    pairwise_cat_sum_ps |>
      filter(ps) |>
      select(-ps)
    , by = join_by(V1, V2)
  ) |>
  filter(n == 0) |>
  kable(
    caption =
      "Table 10. Categorical variables with pair-wise perfect separation."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:5, extra_css = "vertical-align:top;")
```

```{r Variable pairs for correlation tests, include=FALSE}
correlation_pair <-
  ms_added_data |>
  colnames() |>
  setdiff(var_cat_val1) |>
  combn(2) |>
  as.data.frame() |>
  t() |>
  as.data.frame() |>
  `rownames<-`(NULL) |>
  filter(str_remove_all(V1, "^ms_") != str_remove_all(V2, "^ms_")) |>
  filter(!(str_detect(V1, "resp_supp") & str_detect(V2, "resp_supp"))) |>
  filter(
    !(str_detect(V1, "fio2_cum_level") & str_detect(V2, "fio2_cum_level"))
  ) |>
  filter(
    !(str_detect(V1, "fio2_cum_day") & str_detect(V2, "fio2_cum_day"))
  ) |>
  filter(
    !((str_detect(V1, "fio2_raw") & str_detect(V2, "fio2_cum_level"))
      | (str_detect(V1, "fio2_cum_level") & str_detect(V2, "fio2_raw"))
    )
  ) |>
  filter(!(str_detect(V1, "bbw") & str_detect(V2, "bbw"))) |>
  filter(!(str_detect(V1, "bhc") & str_detect(V2, "bhc"))) |>
  filter(
    !((str_detect(V1, "qw") & str_detect(V2, "pct"))
      | (str_detect(V1, "pct") & str_detect(V2, "qw"))
    )
  ) |>
  filter(!(str_detect(V1, "^ms_plt") | str_detect(V2, "^ms_plt"))) |>
  filter(!(str_detect(V1, "^ms_wbc") | str_detect(V2, "^ms_wbc"))) |>
  filter(
    !(str_detect(V1, "^ms_death_age") | str_detect(V2, "^ms_death_age"))
  ) |>
  filter(
    !(str_detect(V1, "^ms_rop_severe") | str_detect(V2, "^ms_rop_severe"))
  ) |>
  filter(
    !(str_detect(V1, "^ms_bpd_grade") | str_detect(V2, "^ms_bpd_grade"))
  ) |>
  filter(
    !(str_detect(V1, "^ms_eugr_hc") | str_detect(V2, "^ms_eugr_hc"))
  ) |>
  filter(
    !(str_detect(V1, "^ms_eugr_bw") | str_detect(V2, "^ms_eugr_bw"))
  ) |>
  filter(
    !(str_detect(V1, "^ms_hearing") | str_detect(V2, "^ms_hearing"))
  ) |>
  filter(!(V1 %in% c("t", "t_wk") & V2 %in% c("t", "t_wk"))) |>
  mutate(V1_unit = V1, V2_unit = V2) |>
  mutate_at(
    vars(V1_unit, V2_unit)
    , \(x)
      case_when(
        str_remove_all(x, "^ms_")
        %in% unlist(
          lapply(raw_data1[str_detect(names(raw_data1), "42d$")], colnames)
        )
        | str_remove_all(x, "^ms_") == "t"
        ~ "id|t_wk|t"
        , str_remove_all(x, "^ms_")
          %in% unlist(
            lapply(raw_data1[str_detect(names(raw_data1), "6w$")], colnames)
          )
          | str_remove_all(x, "^ms_") == "t_wk"
          ~ "id|t_wk"
        , str_remove_all(x, "^ms_")
          %in% unlist(
            lapply(
              raw_data1[!str_detect(names(raw_data1), "42d$|6w$")]
              , colnames
            )
          )
          ~ "id"
      )
  ) |>
  mutate(
    unit =
      mapply(
        \(x, y)
          c(str_split(x, "\\|")[[1]], str_split(y, "\\|")[[1]]) |>
            unique() |>
            paste0(collapse = "|")
        , V1_unit
        , V2_unit
      )
  ) |>
  filter(
    !(V1 == "t" | V2 == "t")
    | (V1 == "t" & V2_unit != "id")
    | (V2 == "t" & V1_unit != "id")
  ) |>
  filter(
    !(V1 == "t_wk" | V2 == "t_wk")
    | (V1 == "t_wk" & V2_unit != "id")
    | (V2 == "t_wk" & V1_unit != "id")
  ) |>
  select(-V1_unit, -V2_unit)
```

```{r Conduct correlation tests per pair with PS, eval=FALSE, include=FALSE}
correlation_matrix_ps0 <-
  correlation_pair |>
  filter(
    paste0(V1, V2)
    %in% c(
      pairwise_cat_sum_ps |>
        filter(ps) |>
        unite(V1V2, V1, V2, sep = "") |>
        pull(V1V2)
    )
  )

correlation_matrix_ps <-
  correlation_matrix_ps0 |>
  pmap(
    \(V1, V2, unit)
    list(
      data =
        ms_added_data0[, c(V1, V2, str_split(unit, "\\|")[[1]])] |>
        unique()
      , V1 = V1
      , V2 = V2
    )
  )

if (!dir.exists("data/correlation_matrix_ps")){
  dir.create("data/correlation_matrix_ps")
}

start <- TRUE
cl <- min(6, detectCores())
source("R/parallel_computing-codes.R")

correlation_matrix_ps[
  correlation_matrix_ps |>
    sapply(
      \(x)
      !paste0(x$V1, "_", x$V2, ".rds")
      %in% list.files("data/correlation_matrix_ps")
    )
  ] |>
  pblapply(
    FUN =
      \(x, auto_stat_tests = auto_stat_tests, ms_added_data = ms_added_data)
      suppressWarnings(auto_stat_tests(
          x$data[[x$V1]]
          , x$data[[x$V2]]
          , perfect_separation = TRUE
        )) |>
        list() |>
        `names<-`("obj") |>
        c(list(V1 = x$V1, V2 = x$V2)) |>
        saveRDS(paste0("data/correlation_matrix_ps/",x$V1,"_",x$V2,".rds"))
    , auto_stat_tests = auto_stat_tests
    , ms_added_data = ms_added_data
    ,  cl = cl
  )

start <- FALSE
source("R/parallel_computing-codes.R")

correlation_matrix_ps <-
  correlation_matrix_ps0 |>
  pmap(\(V1, V2, unit) list(V1 = V1, V2 = V2)) |>
  pblapply(
    \(x)
    suppressWarnings(
      tidy(
        readRDS(
          paste0("data/correlation_matrix_ps/",x$V1,"_",x$V2,".rds")
        )$obj
      )
    ) |>
    filter(!str_detect(term, "\\(Intercept\\)")) |>
    filter(!(conf.low <= 0 & conf.high >= 0)) |>
    summarize(n_sig = n()) |>
    mutate(p.value = ifelse(n_sig > 0, 0, 1)) |>
    filter(!is.na(p.value)) |>
    select(p.value) |>
    mutate(V1 = x$V1, V2 = x$V2)
  ) |>
  reduce(rbind)

saveRDS(correlation_matrix_ps, "data/correlation_matrix_ps.rds")
```

```{r Load pre-conducted correlation tests per pair with PS, include=FALSE}
correlation_matrix_ps <- readRDS("data/correlation_matrix_ps.rds")
```

```{r Conduct correlation tests for each pair without PS, include=FALSE}
correlation_matrix_non_ps <-
  correlation_pair |>
  filter(
    !paste0(V1, V2)
    %in% c(
      pairwise_cat_sum_ps |>
        filter(ps) |>
        unite(V1V2, V1, V2, sep = "") |>
        pull(V1V2)
    )
  ) |>
  pmap(
    \(V1, V2, unit)
    list(
      data =
        ms_added_data0[, c(V1, V2, str_split(unit, "\\|")[[1]])]
      , V1 = V1
      , V2 = V2
    )
  ) |>
  lapply(
    \(x)
    list(
      obj =
        try(
          suppressWarnings(auto_stat_tests(
              x$data[[x$V1]]
              ,x$data[[x$V2]]
              ,normal_V1 = !x$V1 %in% var_num_non_normal_after_trans
              ,normal_V2 = !x$V2 %in% var_num_non_normal_after_trans
            ))
        )
      , V1 = x$V1
      ,V2 = x$V2
    )
  )


correlation_matrix_non_ps_succeed <-
  correlation_matrix_non_ps[
    sapply(
      correlation_matrix_non_ps
      , \(x) paste0(class(x$obj), collapse = " ") != "try-error"
    )
  ] |>
  lapply(
    \(x)
    x$obj |>
      tidy() |>
      filter(!is.na(p.value)) |>
      select(p.value) |>
      mutate(
        V1 = x$V1
        ,V2 = x$V2
      )
  ) |>
  reduce(rbind)

correlation_matrix_non_ps_failed <-
  correlation_pair |>
  filter(
    !paste0(V1, V2)
    %in% c(
      pairwise_cat_sum_ps |>
        filter(ps) |>
        unite(V1V2, V1, V2, sep = "") |>
        pull(V1V2)
    )
  ) |>
  slice(
    which(
      sapply(
        correlation_matrix_non_ps
        , \(x) paste0(class(x$obj), collapse = " ") == "try-error"
      )
    )
  ) |>
  mutate(p.value = as.numeric(NA)) |>
  select(p.value, V1, V2)

correlation_matrix_non_ps <-
  correlation_matrix_non_ps_succeed |>
  rbind(correlation_matrix_non_ps_failed)
```

```{r Conduct correlation tests for each pair, include=FALSE}
correlation_matrix <-
  correlation_matrix_ps |>
  rbind(correlation_matrix_non_ps) |>
  mutate(p.value = p.adjust(p.value, "BH")) |>
  rename(cor.p.value = p.value) |>
  right_join(
    ms_added_data |>
      colnames() |>
      combn(2) |>
      as.data.frame() |>
      t() |>
      as.data.frame() |>
      `rownames<-`(NULL)
    , by = join_by(V1, V2)
  ) |>
  mutate(
    V1 = factor(V1, colnames(ms_added_data))
    ,V2 = factor(V2, levels(V1))
  ) |>
  arrange(V1, V2)
```

```{r Plot correlation matrix, include=FALSE}
same_v_corr_df =
  data.frame(
    cor.p.value = 0
    , V1 = colnames(ms_added_data)
    , V2 = colnames(ms_added_data)
    , sig = "2 - Significant"
  )

correlation_matrix_plot <-
  correlation_matrix |>
  mutate(
    V1 = factor(V1, rev(levels(V1)))
    , sig =
      ifelse(
        is.na(cor.p.value)
        ,ifelse(
          str_remove_all(V1, "^ms_") == str_remove_all(V2, "^ms_")
          ,"3 - Not tested†"
          ,ifelse(
            V1 %in% var_cat_val1
            | V2 %in% var_cat_val1
            ,"4 - Not tested‡"
            ,"5 - Not tested§"
          )
        )
        ,ifelse(cor.p.value <= 0.05, "2 - Significant", "1 - Not significant")
      ) |>
      factor()
    , sig = factor(sig)
    , cor.p.value = ifelse(cor.p.value<0.001, "<0.001", round(cor.p.value,3))
  ) |>
  rbind(same_v_corr_df) |>
  ggplot(aes(V1, V2, fill = sig)) +
  geom_tile(color = "white", na.rm = TRUE) +
  # geom_text(aes(label = cor.p.value), size = 2.5, na.rm = TRUE) +
  geom_tile(data = same_v_corr_df, fill = "white") +
  geom_text(
    data =
      same_v_corr_df |>
      mutate(label = V1)
    , aes(label = label)
    , size = 1.5
    , angle = 45
    , hjust = 1
    , nudge_x = 0.15
    , nudge_y = 0.15
  ) +
  coord_flip() +
  scale_x_discrete(expand = expansion(add = 10)) +
  scale_y_discrete(expand = expansion(add = 5)) +
  xlab("") +
  ylab("") +
  scale_fill_discrete("Significance*") +
  theme(
    panel.grid = element_blank()
    , panel.border = element_blank()
    , axis.ticks = element_blank()
    , axis.text = element_blank()
  )
```

```{r figure-3, echo=FALSE, fig.height=5, fig.width=7}
correlation_matrix_plot
```

Figure 3. Correlation matrix. *, based on p-value (frequentist) or 95% CI (Bayesian); †, pair of variable and its missingness; ‡, at least 1 variable was a categorical variable with a category of 1 value; §, insufficient sample size.

```{r Write pairs with significant correlations, eval=FALSE, include=FALSE}
correlation_matrix |>
  filter(cor.p.value <= 0.05) |>
  select(V1, V2) |>
  write_csv("inst/extdata/correlation.csv")
```

# Missing value imputation

```{r Imputation predictor matrix, include=FALSE}
imp_predictor_matrix <-
  correlation_matrix |>
  filter(!is.na(cor.p.value)) |>
  mutate(imp_predictor = ifelse(cor.p.value <= 0.05, 1, 0)) |>
  filter(imp_predictor == 1) |>
  select(V1, V2, imp_predictor) |>
  mutate_at(c("V1", "V2"), str_remove_all, "^ms_") |>
  mutate_at(c("V1", "V2"), as.character) |>
  mutate_at(c("V1", "V2"), \(x) ifelse(x == "t_wk", "t", x)) |>
  unique()

imp_predictor_matrix <-
  imp_predictor_matrix |>
  rbind(`colnames<-`(imp_predictor_matrix, c("V2", "V1", "imp_predictor"))) |>
  unique() |>
  right_join(
    expand.grid(
      V1 = colnames(transformed_data)
      , V2 = colnames(transformed_data)
      , stringsAsFactors = FALSE
    )
    , by = join_by(V1, V2)
  ) |>
  spread(V2, imp_predictor, fill = 0) |>
  column_to_rownames(var = "V1") |>
  as.matrix()

imp_predictor_matrix <-
  imp_predictor_matrix[
    colnames(transformed_data)
    , colnames(transformed_data)
  ]
```

```{r Performing multiple imputation, eval=FALSE, include=FALSE}
imp_results <-
  suppressWarnings(
    mice(
      data = transformed_data
      , method = 'pmm'
      , m = 10
      , seed = seed
      , predictorMatrix = imp_predictor_matrix
      , print = FALSE
    )
  )

saveRDS(imp_results, "data/imp_results.rds")
```

```{r Load pre-performed multiple imputation, include=FALSE}
imp_results <- readRDS("data/imp_results.rds")
```

```{r Obtain imputed data, eval=FALSE, include=FALSE}
imputed_data <-
  mice.mids(imp_results, newdata = cleaned_data) |>
  complete(1)

imputed_data <-
  imputed_data |>
  imap(
    ~ list(
        select_at(cleaned_data, .y)
        , select_at(imputed_data, .y)
      )[[ifelse(.y %in% colnames(raw_data1$outcomes), 1, 2)]]
  ) |>
  reduce(cbind)

saveRDS(imputed_data, "data/imputed_data.rds")
```

```{r Load pre-obtained imputed data, include=FALSE}
imputed_data <- readRDS("data/imputed_data.rds")
```

```{r Finalize readily-analyzed data, include=FALSE}
processed_data <- imputed_data
```

# Descriptive statistics

```{r Determine variables, include=FALSE}
var <- list()

var$s <- c("id")

var$t <- c("t")

var$dependent <-
  raw_data1[str_detect(names(raw_data1), "outcome")] |>
  lapply(colnames) |>
  reduce(c) |>
  unique() |>
  setdiff(c(var$s, var$t, "t_day", "t_wk", "ga_wk", "death_age"))

var$independent <-
  raw_data1[str_detect(names(raw_data1), "breath")] |>
  lapply(colnames) |>
  reduce(c) |>
  unique() |>
  setdiff(c(var$s, var$t, "t_day", "t_wk", "ga_wk", "death_age"))

var$covariates=
  processed_data %>%
  colnames() %>%
  setdiff(unlist(var))
```

```{r Read descriptive variable-types, include=FALSE}
variable_desc_type <-
  read_csv("inst/extdata/variable_desc_type.csv", show_col_types = FALSE)
```

```{r Modify descriptive variable-types, include=FALSE}
desc_data <-
  processed_data |>
  filter(id %in% train_id) |>
  imap(
    ~ data.frame(
        value =
          ifelse(
            filter(variable_desc_type, variable == .y)$desc_type != "numeric"
            , ifelse(.y == "id", as.character, as.factor)
            , as.numeric
          )(.x)
      ) |>
      `colnames<-`(.y)
  ) |>
  reduce(cbind)
```

```{r Simplify correlation pair to identify unit of obs, include=FALSE}
correlation_pair_simplified <-
  correlation_pair |>
  mutate_at(c("V1", "V2"), \(x) ifelse(x == "t_wk", "t", x)) |>
  mutate_at("unit", str_replace_all, "t_wk\\|t", "t") |>
  mutate_at("unit", str_replace_all, "t_wk", "t") |>
  unique()
```

```{r Identify unit of obs for each outcome-variable, include=FALSE}
outcome_variable_unit <-
  var$dependent |>
  lapply(
    \(x)
    data.frame(outcome = x, variable = c(var$independent, var$covariates))
  ) |>
  reduce(rbind) |>
  mutate(
    unit =
      mapply(
        FUN =
          \(x, y)
          correlation_pair_simplified |>
            filter((V1 == x & V2 == y) | (V2 == y & V1 == x)) |>
            pull(unit) |>
            paste0(collapse = "//")
          , outcome
          , variable
      )
  ) |>
  mutate(unit = ifelse(unit == "", "id", unit))
```

```{r Outcome-wise average and SD, include=FALSE}
avg_sd_data <-
  var$dependent |>
  `names<-`(var$dependent) |>
  lapply(
    \(x)
    desc_data |>
      select_at(c(var$independent, var$covariates, var$dependent[var$dependent != x])) |>
      select_if(is.numeric) |>
      mutate(seq = seq(n())) |>
      gather(variable, value, -seq) |>
      left_join(
        desc_data |>
          select_at(c(var$s, var$t, x)) |>
          mutate(seq = seq(n()))
        , by = join_by(seq)
      ) |>
      select(-seq) |>
      mutate(outcome = x) |>
      left_join(outcome_variable_unit, by = join_by(outcome, variable)) |>
      mutate(unit_id = ifelse(unit == "id", id, paste0(id, "_" ,t))) |>
      rename_at(x, \(x) "category") |>
      select(unit_id, outcome, category, variable, unit, value) |>
      unique()|>
      group_by(variable) |>
      mutate(N = n()) |>
      group_by(outcome, category, variable, unit, N) |>
      summarize(
        avg = mean(value)
        , std = sd(value)
        , .groups = 'drop'
      )
  ) |>
  reduce(rbind)
```

```{r Outcome-wise proportion, include=FALSE}
prop_n_data <-
  var$dependent |>
  `names<-`(var$dependent) |>
  lapply(
    \(x)
    desc_data |>
      select_at(c(var$independent, var$covariates)) |>
      select_if(\(x) !is.numeric(x)) |>
      mutate_all(as.character) |>
      mutate(seq = seq(n())) |>
      gather(variable, value, -seq) |>
      left_join(
        desc_data |>
          select_at(c(var$s, var$t, x)) |>
          mutate(seq=seq(n()))
        ,by = join_by(seq)
      ) |>
      select(-seq) |>
      mutate(outcome = x) |>
      left_join(outcome_variable_unit, by = join_by(outcome, variable)) |>
      mutate(unit_id = ifelse(unit == "id", id, paste0(id, "_" ,t))) |>
      rename_at(x, \(x) "category") |>
      select(unit_id, outcome, category, variable, unit, value) |>
      unique() |>
      group_by(variable) |>
      mutate(N = n()) |>
      group_by(outcome, category, variable, unit, N, value) |>
      summarize(n = n(), .groups='drop') |>
      group_by(outcome, category, variable, unit, N) |>
      mutate(total = sum(n)) |>
      ungroup() |>
      mutate(p = round(n / total * 100, 0))
  ) |>
  reduce(rbind)
```

```{r Summarize sample characteristics, include=FALSE}
desc_stats <-
  list(
    avg_sd_data |>
      mutate_at(c("avg", "std"), round, 2) |>
      mutate(std = paste0("(", as.character(std), ")")) |>
      unite(avg_std, avg, std, sep=" ") |>
      mutate(value = NA) |>
      rename(summary = avg_std)
    ,prop_n_data |>
      select(-total) |>
      mutate(n = paste0("(", as.character(n), ")")) |>
      unite(p_n, p, n, sep = " ") |>
      rename(summary = p_n)
  ) |>
  lapply(mutate_at, "category", as.character) |>
  lapply(mutate_at, "category", \(x) ifelse(is.na(x), "(missing)", x)) |>
  lapply(unite, dep_var, outcome, category, sep = " ") |>
  lapply(mutate_at, "dep_var", \(x) factor(x, unique(x))) |>
  lapply(spread, dep_var, summary, fill = "0 (0)") |>
  reduce(rbind) |>
  mutate_at("value", as.character) |>
  mutate_at(
    "value"
    ,\(x) ifelse(is.na(x), "average (SD)", paste0(x," % (n)"))
  ) |>
  rbind(
    prop_n_data |>
      mutate_at("category", as.character) |>
      mutate_at("category", \(x) ifelse(is.na(x), "(missing)", x)) |>
      unite(variable, outcome, category, sep = " ") |>
      select(variable, unit, N,  total) |>
      unique() |>
      mutate_at("variable", \(x) factor(x, unique(x))) |>
      mutate(total = paste0(total, " (", round(total/N*100, 2),")")) |>
      spread(variable, total, fill = 0) |>
      mutate(variable = "total (prevalence)", value = "n (%)") |>
      select(unit, N, variable, value, everything())
  ) |>
  arrange(
    desc(unit)
    , N
    , factor(variable, c("total (prevalence)", var$independent, var$covariates))
  ) |>
  select(unit, N, everything()) |>
  group_by(unit, N) |>
  mutate(variable = ifelse(duplicated(variable), "", variable)) |>
  ungroup() |>
  mutate(
    unit = ifelse(duplicated(unit), "", unit)
    , N = ifelse(duplicated(N), "", N)
  ) |>
  mutate_all(str_replace_all, "NA \\(NA\\)", "N/A")
```

```{r table-11, echo=FALSE}
desc_stats |>
  select_if(
    colnames(desc_stats) %in% c("unit", "N", "variable", "value")
    | str_detect(colnames(desc_stats), "^survive")
  ) |>
  left_join(
    rbind(
        correlation_matrix |>
          filter(str_detect(V2, "^survive")) |>
          select(variable = V1, cor.p.value)
        , correlation_matrix |>
          filter(str_detect(V1, "^survive")) |>
          select(variable = V2, cor.p.value)
      )
    , by = join_by(variable)
  ) |>
  mutate(
    cor.p.value =
      ifelse(
        is.na(cor.p.value)
        , ""
        , ifelse(
            cor.p.value < 0.001
            , "<0.001"
            , ifelse(cor.p.value > 0.05, ">0.05", round(cor.p.value, 3))
          )
      )
  ) |>
  kable(
    caption = "Table 11. Sample characteristics by survival."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:6, extra_css = "vertical-align:top;")
```

```{r table-12, echo=FALSE}
desc_stats |>
  select_if(!str_detect(colnames(desc_stats), "^survive")) |>
  kable(
    caption = "Table 12. Sample characteristics by other outcomes."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:20, extra_css = "vertical-align:top;")
```

# Feature extraction

```{r Write processed data old categories, eval=FALSE, include=FALSE}
processed_data |>
  filter(id %in% train_id) |>
  select_if(is.factor) |>
  gather(colname, old_cat) |>
  mutate(colname = factor(colname, unique(colname))) |>
  group_by(colname, old_cat) |>
  summarize(n = n(), .groups = "drop") |>
  select(-n) |>
  mutate(new_cat = NA) |>
  write_csv("inst/extdata/processed_data_old_cat.csv")
```

```{r Read processed data new categories, include=FALSE}
processed_data_new_cat <-
  read_csv("inst/extdata/processed_data_new_cat.csv", show_col_types = FALSE) |>
  mutate_at("old_cat", as.character)
```

```{r table-13, echo=FALSE}
processed_data_new_cat |>
  kable(
    caption = "Table 13. Processed data old and new categories."
    , format = kable_format
  ) |>
  footnote("*, inversed nominal category.") |>
  kable_classic() |>
  column_spec(1:2, extra_css = "vertical-align:top;")
```

```{r Modify categories in processed data, include=FALSE}
processed_data2 <-
  unique(variable_new_type$new_type) |>
  `names<-`(unique(variable_new_type$new_type)) |>
  imap(
    ~ processed_data |>
      select_at(filter(variable_new_type, new_type == .x)$variable)
  )

processed_data2$factor <-
  processed_data2$factor |>
  mutate_all(as.character) |>
  mutate(seq = seq(n())) |>
  gather(colname, old_cat, -seq) |>
  left_join(processed_data_new_cat, by = join_by(colname, old_cat)) |>
  select(-old_cat) |>
  mutate_at("colname", \(x) factor(x, unique(x))) |>
  spread(colname, new_cat) |>
  arrange(seq) |>
  select(-seq) |>
  mutate_all(as.factor)

processed_data2 <-
  processed_data2 |>
  reduce(cbind) |>
  select_at(colnames(processed_data))
```

```{r Split nominal categories in processed data, include=FALSE}
processed_data3 <- list()

for(i in seq(ncol(processed_data2))){
  processed_data3[[i]] <-
    processed_data2 |>
    select(all_of(i))
  
  if(is.factor(processed_data2[[i]])){
    if(!all(str_detect(levels(processed_data2[[i]]), "[:digit:]-"))){
      processed_data3[[i]] <-
        processed_data3[[i]] |>
        mutate(seq = seq(n())) |>
        gather(old_colname, new_colname, -seq) |>
        select(-old_colname) |>
        mutate(
          new_colname =
            new_colname |>
            factor(
              processed_data_new_cat |>
                filter(colname == colnames(processed_data2)[i]) |>
                pull(new_cat) |>
                unique() |>
                setdiff(NA)
            )
        ) |>
        mutate(cat = "1-yes") |>
        spread(new_colname, cat, fill = "0-no") |>
        arrange(seq) |>
        select(-seq) |>
        mutate_all(as.factor)
      
      if("(removed)" %in% colnames(processed_data3[[i]])){
        processed_data3[[i]] <-
          processed_data3[[i]] |>
          select_if(colnames(processed_data3[[i]]) != "(removed)")
      }
      
      if("(missing)" %in% colnames(processed_data3[[i]])){
        processed_data3[[i]] <-
          processed_data3[[i]] |>
          mutate_all(as.character) |>
          mutate(seq = seq(n())) |>
          gather(colname, cat, -seq, -`(missing)`) |>
          mutate(cat = ifelse(`(missing)` == "1-yes", NA, cat)) |>
          mutate_at("colname", \(x) factor(x, unique(x))) |>
          spread(colname, cat) |>
          arrange(seq) |>
          select(-seq, -`(missing)`) |>
          mutate_all(as.factor)
      }
      
      if(any(str_detect(colnames(processed_data3[[i]]), "\\*$"))){
        processed_data3[[i]] <-
          processed_data3[[i]] |>
          mutate_if(
            str_detect(colnames(processed_data3[[i]]), "\\*$")
            , \(x) as.factor(ifelse(x == "1-yes", "0-no", "1-yes"))
          ) |>
          `colnames<-`(str_remove_all(colnames(processed_data3[[i]]), "\\*$"))
      }
    }
  }
}

processed_data3 <-
  processed_data3 |>
  reduce(cbind)
```

```{r Finalize data for modeling and evaluation, include=FALSE}
modeval_data <- processed_data3
```

```{r Finalize regression-ready data, include=FALSE}
reg_data <-
  modeval_data |>
  filter(id %in% train_id)
```

```{r Regression-ready data new colnames, include=FALSE}
reg_data_new_colname <-
  processed_data_new_cat |>
  rename(old_colname = colname) |>
  mutate(
    new_colname =
      ifelse(
        str_detect(new_cat, "[:digit:]-")
        , old_colname
        , new_cat
      )
  ) |>
  select(old_colname, new_colname) |>
  filter(new_colname != "(removed)") |>
  filter(new_colname != "(missing)") |>
  mutate(new_colname = str_remove_all(new_colname, "\\*$")) |>
  unique()
```

```{r Identify unit of obs for each outcome-modified variable, include=FALSE}
outcome_variable_unit_reg <-
  outcome_variable_unit |>
  left_join(
    reg_data_new_colname |>
      rename(variable = old_colname)
    , by = join_by(variable)
    , relationship = "many-to-many"
  ) |>
  mutate(
    variable = ifelse(is.na(new_colname), variable, new_colname)
  ) |>
  select(-new_colname)
```

```{r Modify pre-determined variables to use new colnames, include=FALSE}
var_reg <-
  var |>
  lapply(
    \(x)
    data.frame(old_colname = x) |>
      left_join(
        reg_data_new_colname
        , by = join_by(old_colname)
      ) |>
      mutate(
        old_colname = ifelse(is.na(new_colname), old_colname, new_colname)
      ) |>
      select(-new_colname) |>
      rename(variable = old_colname) |>
      pull(variable)
  )
```

# Univariate regression analysis

```{r Conduct univariate regression analysis, include=FALSE}
univar_reg <-
  var_reg$dependent |>
  lapply(
    \(x)
    setdiff(c(var_reg$independent, var_reg$covariates), "death_age") |>
      `names<-`(setdiff(c(var_reg$independent, var_reg$covariates), "death_age")) |>
      lapply(c, x) |>
      lapply(rev) |>
      lapply(paste0, collapse = '~') |>
      lapply(as.formula) |>
      lapply(
        \(x)
        suppressWarnings(
          reg_fn(
            formula = x
            , data =
              reg_data |>
              select_at(
                c(outcome_variable_unit_reg |>
                    filter(outcome == as.character(x)[2]) |>
                    filter(variable == as.character(x)[3]) |>
                    pull(unit) |>
                    str_split("\\|") |>
                    unlist()
                  , as.character(x)[2]
                  , as.character(x)[3]
                )
              ) |>
              mutate_at(
                as.character(x)[2]
                , \(x) ifelse(x == levels(x)[1], 0, 1)
              ) |>
              unique()
          )
        )
      ) |>
      lapply(tidy) |>
      imap( ~ mutate(.x, outcome = x, variable = .y)) |>
      lapply(\(x) select_if(x, colnames(x) != "robust.se")) |>
      reduce(rbind) |>
      select(outcome, variable, everything()) |>
      mutate(
        term = str_remove_all(term, variable)
        , term = ifelse(term == "", "value", term)
        , OR = exp(estimate)
        , LB = exp(estimate - qnorm(0.975) * std.error)
        , UB = exp(estimate + qnorm(0.975) * std.error)
      )
  ) |>
  reduce(rbind)
```

```{r table-14, echo=FALSE}
univar_reg  |>
  filter(term != "(Intercept)") |>
  select_at(c("outcome", "variable", "term", "OR", "LB", "UB", "p.value")) |>
  mutate(
    variable =
      paste0(
        variable
        , ifelse((LB > 1 | UB < 1) & p.value <= 0.05, "*", "")
      )
  ) |>
  mutate_at(4:7, round, 3) |>
  mutate(outcome = factor(outcome, unique(outcome))) |>
  arrange(outcome, p.value) |>
  mutate(
    p.value =
      ifelse(p.value < 0.001, "<0.001", round(p.value, 3)) |>
      as.character()
  ) |>
  kable(
    caption = "Table 14. Univariate regression analysis."
    , format = kable_format
  ) |>
  footnote("*, either LB > 1 or UB < 1 and p-value <= 0.05.") |>
  kable_classic() |>
  column_spec(1:7, extra_css = "vertical-align:top;")
```

```{r Filter significant univariate regression, include=FALSE}
univar_reg_sig <-
  univar_reg |>
  filter(term != '(Intercept)') |>
  filter((LB > 1 | UB < 1) & p.value <= 0.05) |>
  mutate(outcome = factor(outcome, unique(outcome))) |>
  arrange(outcome, p.value)
```

```{r Obtain variables in sig uni reg results, include=FALSE}
univar_reg_sig_var <-
  var_reg$dependent |>
  `names<-`(var_reg$dependent) |>
  lapply(
    \(x)
    univar_reg_sig |>
      filter(outcome == x) |>
      pull(variable) |>
      unique()
  )
```

# Covariate selection

```{r Variables with significant correlations, include=FALSE}
sig_var <-
  correlation_matrix |>
  filter(!(str_detect(V1, "^ms_") | str_detect(V2, "^ms_"))) |>
  filter(!is.na(cor.p.value)) |>
  mutate(predictor = ifelse(cor.p.value <= 0.05, 1, 0)) |>
  filter(predictor == 1) |>
  select(V1, V2, predictor) |>
  mutate_at(c("V1", "V2"), as.character) |>
  mutate_at(c("V1", "V2"), \(x) ifelse(x == "t_wk", "t", x)) |>
  unique()

sig_var <-
  sig_var |>
  left_join(
    reg_data_new_colname |>
      rename(V1 = old_colname)
    , by = join_by(V1)
    , relationship = "many-to-many"
  ) |>
  mutate(
    V1 = ifelse(is.na(new_colname), V1, new_colname)
  ) |>
  select(-new_colname) |>
  left_join(
    reg_data_new_colname |>
      rename(V2 = old_colname)
    , by = join_by(V2)
    , relationship = "many-to-many"
  ) |>
  mutate(
    V2 = ifelse(is.na(new_colname), V2, new_colname)
  ) |>
  select(-new_colname)

sig_var <-
  sig_var |>
  rbind(`colnames<-`(sig_var, c("V2", "V1", "predictor"))) |>
  unique() |>
  right_join(
    expand.grid(
      V1 = colnames(reg_data)
      , V2 = colnames(reg_data)
      , stringsAsFactors = FALSE
    )
    , by = join_by(V1, V2)
  ) |>
  spread(V2, predictor, fill = 0) |>
  column_to_rownames(var = "V1") |>
  as.matrix()

sig_var <-
  sig_var[
    colnames(reg_data)
    , colnames(reg_data)
  ]
```

```{r Create graph data frame based on simplified direction, include=FALSE}
correlation_graph_df <-
  univar_reg_sig_var |>
  imap(
    ~ sig_var[.x, .x] |>
      as.data.frame() |>
      rownames_to_column(var = "from") |>
      gather(to, predictor, -from) |>
      filter(predictor == 1) |>
      select(-predictor)
  )
```

```{r Determine adjustment per pair variable-covariate, include=FALSE}
multivar_adjustment_paired <-
  correlation_graph_df |>
  imap(
    ~ .x |>
      right_join(data.frame(to = univar_reg_sig_var[[.y]]), by = join_by(to)) |>
      select(variable = to, covariates = from) |>
      mutate(covariates = paste0(variable, "+", covariates)) |>
      mutate(formula = paste0(.y, "~", covariates)) |>
      mutate(
        covariates = str_remove_all(covariates, paste0(variable, "\\+*"))
      ) |>
      arrange(
        factor(variable, unique(filter(univar_reg_sig, outcome == .y)$variable))
      )
  )
```

```{r Conduct multi reg analysis per pair var-covar, eval=FALSE, include=FALSE}
multivar_reg_paired <-
  var_reg$dependent |>
  pblapply(
    \(x)
    multivar_adjustment_paired[[x]] |>
      pull(formula) |>
      `names<-`(multivar_adjustment_paired[[x]]$variable) |>
      lapply(as.formula) |>
      lapply(
        \(x)
        suppressWarnings(
            reg_fn(
              formula = x
              , data =
                reg_data |>
                mutate_at(
                  as.character(x)[2]
                  , \(x) ifelse(x == levels(x)[1], 0, 1)
                )
            )
          ) |>
          tidy() |>
          list() |>
          c(list(formula = x))
      ) |>
      imap(
        ~ .x[[1]] |>
          mutate(
            outcome = x
            , variable = .y
            , covariates =
              str_split(as.character(.x[[2]])[3], "\\+")[[1]][2]
          )
      ) |>
      lapply(\(x) select_if(x, colnames(x) != "robust.se")) |>
      reduce(rbind) |>
      select(outcome, variable, covariates, everything()) |>
      mutate(
        term = str_remove_all(term, variable)
        , term = ifelse(term == "", "value", term)
        , OR = exp(estimate)
        , LB = exp(estimate - qnorm(0.975) * std.error)
        , UB = exp(estimate + qnorm(0.975) * std.error)
      )
  ) |>
  reduce(rbind)

saveRDS(multivar_reg_paired, "data/multivar_reg_paired.rds")
```

```{r Load pre-conducted multi reg analysis per pair var-covar, include=FALSE}
multivar_reg_paired <- readRDS("data/multivar_reg_paired.rds")
```

```{r Identify effect size changes after paired adjustment, include=FALSE}
es_change_paired <-
  univar_reg  |>
  filter(term != "(Intercept)") |>
  filter((LB > 1 | UB < 1) & p.value <= 0.05) |>
  select(outcome, variable, term, OR, LB, UB) |>
  left_join(
    multivar_reg_paired  |>
      filter(term != "(Intercept)") |>
      inner_join(
        univar_reg |>
          select(outcome, variable, term) |>
          unique()
        , by = join_by(outcome, variable, term)
      ) |>
      select(outcome, variable, covariates, term, OR, LB, UB)
    , by = join_by(outcome, variable, term)
  ) |>
  mutate_at(c("outcome", "variable"), \(x) factor(x, unique(x))) |>
  select(outcome, variable, covariates, everything()) |>
  mutate(
    es_change =
      case_when(
        (LB.x > 1 & LB.y > OR.x) | (UB.x < 1 & UB.y < OR.x) ~ "larger"
        , (LB.x > 1 & UB.y < 1) | (UB.x < 1 & LB.y > 1) ~ "flipped"
        , (LB.x > 1 & UB.y < OR.x & LB.y > 1)
          | (UB.x < 1 & LB.y > OR.x & UB.y < 1)
          ~ "smaller"
        , (LB.x > 1 & UB.y > 1 & LB.y < 1)
          | (UB.x < 1 & UB.y > 1 & LB.y < 1)
          ~ "insignificant"
        , (UB.y > OR.x & LB.y < OR.x) ~ "unchanged"
        , TRUE ~ "unclassified"
      )
  )
```

```{r Create data frame based on selected covariates, include=FALSE}
covariate_df <-
  var_reg$dependent |>
  `names<-`(var_reg$dependent) |>
  lapply(
    \(x)
    es_change_paired |>
      rbind(
        es_change_paired |>
          mutate(variable2 = covariates, covariates2 = variable) |>
          mutate(variable = variable2, covariates = covariates2) |>
          select(-variable2, -covariates2)
      ) |>
      filter(outcome == "survive") |>
      filter(es_change %in% c("smaller")) |>
      select(from = variable, to = covariates) |>
      unique() |>
      mutate_all(as.character)
  )
```

# Multivariate regression analysis

```{r Determine adjustment, include=FALSE}
multivar_adjustment <-
  covariate_df |>
  imap(
    ~ .x |>
      right_join(data.frame(to = univar_reg_sig_var[[.y]]), by = join_by(to)) |>
      group_by(to) |>
      mutate(seq = seq(n())) |>
      rbind(
        univar_reg_sig |>
          filter(outcome == .y) |>
          select(-outcome) |>
          select(to = variable) |>
          mutate(seq = 0, from = to)
      ) |>
      arrange(to, seq) |>
      group_by(to) |>
      summarize(covariates = paste0(from[!is.na(from)], collapse = "+")) |>
      rename(variable = to) |>
      mutate(formula = paste0(.y, "~", covariates)) |>
      mutate(
        covariates = str_remove_all(covariates, paste0(variable, "\\+*"))
      ) |>
      arrange(
        factor(variable, unique(filter(univar_reg_sig, outcome == .y)$variable))
      )
  )
```

```{r Conduct multivariate regression analysis, include=FALSE}
multivar_reg <-
  var_reg$dependent |>
  lapply(
    \(x)
    multivar_adjustment[[x]] |>
      pull(formula) |>
      `names<-`(multivar_adjustment[[x]]$variable) |>
      lapply(as.formula) |>
      lapply(
        \(x)
        suppressWarnings(
          reg_fn(
            formula = x
            , data =
              reg_data |>
              mutate_at(
                as.character(x)[2]
                , \(x) ifelse(x == levels(x)[1], 0, 1)
              )
          )
        ) |>
          tidy() |>
          list() |>
          c(list(formula = x))
      ) |>
      imap(
        ~ .x[[1]] |>
          mutate(
            outcome = x
            , variable = .y
            , covariates =
              str_split(as.character(.x[[2]])[3], "\\+")[[1]][-1] |>
              paste0(collapse = " + ")
          )
      ) |>
      lapply(\(x) select_if(x, colnames(x) != "robust.se")) |>
      reduce(rbind) |>
      select(outcome, variable, covariates, everything()) |>
      mutate(
        term = str_remove_all(term, variable)
        , term = ifelse(term == "", "value", term)
        , OR = exp(estimate)
        , LB = exp(estimate - qnorm(0.975) * std.error)
        , UB = exp(estimate + qnorm(0.975) * std.error)
      )
  ) |>
  reduce(rbind)
```

```{r table-15, echo=FALSE}
multivar_reg  |>
  filter(term != "(Intercept)") |>
  inner_join(
    univar_reg |>
      select(outcome, variable, term) |>
      unique()
    , by = join_by(outcome, variable, term)
  ) |>
  select_at(c("outcome", "variable", "term", "OR", "LB", "UB", "p.value")) |>
  mutate(
    variable =
      paste0(
        variable
        , ifelse((LB > 1 | UB < 1) & p.value <= 0.05, "*", "")
      )
  ) |>
  mutate_at(4:7, round, 3) |>
  left_join(
    multivar_adjustment |>
      imap(~ select(mutate(.x, outcome = .y), outcome, everything())) |>
      reduce(rbind) |>
      select(-formula) |>
      mutate_at("covariates", str_replace_all, "\\+", ", ")
    , by = join_by(outcome, variable)
  ) |>
  mutate_at(c("outcome", "variable"), \(x) factor(x, unique(x))) |>
  select(outcome, variable, everything()) |>
  arrange(outcome, p.value) |>
  mutate(
    p.value =
      ifelse(p.value<0.001, "<0.001", round(p.value,3)) |>
      as.character()
  ) |>
  kable(
    caption = "Table 15. Multivariate regression analysis."
    , format = kable_format
  ) |>
  footnote("*, either LB > 1 or UB < 1 and p-value <= 0.05.") |>
  kable_classic() |>
  column_spec(1:8, extra_css = "vertical-align:top;")
```

```{r Filter significant multivariate regression, include=FALSE}
multivar_reg_sig <-
  multivar_reg  |>
  filter(term != "(Intercept)") |>
  inner_join(
    univar_reg |>
      select(outcome, variable, term) |>
      unique()
    , by = join_by(outcome, variable, term)
  ) |>
  filter((LB > 1 | UB < 1) & p.value <= 0.05) |>
  mutate(outcome = factor(outcome, unique(outcome))) |>
  arrange(outcome, p.value)
```

```{r Obtain variables in sig multi reg results, include=FALSE}
multivar_reg_sig_var <-
  var_reg$dependent |>
  `names<-`(var_reg$dependent) |>
  lapply(
    \(x)
    multivar_reg_sig |>
      filter(outcome == x) |>
      pull(variable) |>
      unique()
  )
```

```{r Plot effect sizes, include=FALSE}
es_plots <-
  var_reg$dependent |>
  `names<-`(var_reg$dependent) |>
  lapply(
    \(x)
    univar_reg  |>
      filter(outcome == x) |>
      filter(term != "(Intercept)") |>
      filter((LB > 1 | UB < 1) & p.value <= 0.05) |>
      select(outcome, variable, term, OR, LB, UB) |>
      left_join(
        multivar_reg  |>
          filter(outcome == x) |>
          filter(term != "(Intercept)") |>
          inner_join(
            univar_reg |>
              select(outcome, variable, term) |>
              unique()
            , by = join_by(outcome, variable, term)
          ) |>
          select(outcome, variable, term, OR, LB, UB)
        , by = join_by(outcome, variable, term)
      ) |>
      mutate_at(c("outcome"), \(x) factor(x, unique(x))) |>
      mutate(
        es_change =
          case_when(
            (LB.x > 1 & LB.y > OR.x) | (UB.x < 1 & UB.y < OR.x) ~ "larger"
            , (LB.x > 1 & UB.y < 1) | (UB.x < 1 & LB.y > 1) ~ "flipped"
            , (LB.x > 1 & UB.y < OR.x & LB.y > 1)
              | (UB.x < 1 & LB.y > OR.x & UB.y < 1)
              ~ "smaller"
            , (LB.x > 1 & UB.y > 1 & LB.y < 1)
              | (UB.x < 1 & UB.y > 1 & LB.y < 1)
              ~ "insignificant"
            , (UB.y > OR.x & LB.y < OR.x) ~ "unchanged"
            , TRUE ~ "unclassified"
          ) |>
          factor(
            c("larger"
              , "unchanged"
              , "smaller"
              , "insignificant"
              , "flipped"
              , "unclassified"
            )
          )
      ) |>
      unite(variable_term, variable, term, sep = " = ") |>
      mutate(variable_term = reorder(variable_term, OR.y)) |>
      mutate(seq = seq(n())) |>
      gather(metric, value, -seq, -outcome, -variable_term, -es_change) |>
      separate(metric, c("metric", "adjustment"), sep = "\\.") |>
      spread(metric, value) |>
      arrange(seq) |>
      select(-seq) |>
      mutate(adjustment = ifelse(adjustment == "x", "no", "yes")) |>
      mutate_at(c("OR", "LB", "UB"), \(x) ifelse(x >= 4, 4, x)) |>
      ggplot(aes(variable_term, OR, color = adjustment)) +
      geom_hline(yintercept = 1, lty = 2) +
      geom_point(
        aes(size = adjustment)
        , alpha =0.75, , show.legend = FALSE, na.rm = TRUE
      ) +
      geom_errorbar(
        aes(ymin = LB, ymax = UB)
        , alpha =0.75, width = 0.75, na.rm = TRUE
      ) +
      facet_grid(
        es_change ~ outcome
        , switch = "y", scales = "free_y", space = "free_y"
      ) +
      coord_flip() +
      scale_y_continuous(limits = c(0, 4), labels = c(0 , 1, 2, 3, "4+")) +
      scale_size_manual(values = c(2, 1)) +
      xlab("") +
      ylab("") +
      theme(
        legend.position = "none"
        , strip.text.y.left = element_text(angle = 0)
        , strip.placement = "outside"
      )
  )
```

```{r figure-4, echo=FALSE, fig.height=35, fig.width=7}
ggarrange(
  es_plots[[1]] + theme(legend.position = "top")
  , es_plots[[2]]
  , es_plots[[3]]
  , es_plots[[4]]
  , es_plots[[5]]
  , es_plots[[6]]
  , es_plots[[7]]
  , nrow = length(es_plots)
  , ncol = 1
  , widths = 7
  , heights =
    c(nrow(es_plots[[1]]$data) + 9
      , nrow(es_plots[[2]]$data)
      , nrow(es_plots[[3]]$data) + 9
      , nrow(es_plots[[4]]$data) + 9
      , nrow(es_plots[[5]]$data)
      , nrow(es_plots[[6]]$data)
      , nrow(es_plots[[7]]$data)
    )
)
```

Figure 4. Effect size changes before and after adjustment for confounders.

# Feature selection

```{r Select predictors for baseline and residual, include=FALSE}
predictor <-
  multivar_reg_sig_var |>
  lapply(\(x) data.frame(new_colname = x)) |>
  lapply(left_join, reg_data_new_colname, by = join_by(new_colname)) |>
  lapply(
    mutate
    , old_colname = ifelse(is.na(old_colname), new_colname, old_colname)
  ) |>
  lapply(
    left_join
    , raw_data1 |>
        imap(~ data.frame(dataset = .y, old_colname = colnames(.x))) |>
        reduce(rbind)
    , by = join_by(old_colname)
  ) |>
  lapply(
    mutate
    , type =
      ifelse(!str_detect(dataset, "42d$|6w$"), "baseline", "residual")
  ) |>
  lapply(select, variable = new_colname, type) |>
  imap(
    ~ c("baseline", "residual") |>
      `names<-`(c("baseline", "residual")) |>
      lapply(\(x) .x$variable[.x$type == x])
  )
```

```{r Split data for mod & eval by pre-defined pred & partition, include=FALSE}
modeval_data_set_ori <-
  predictor |>
  lapply(\(x) x[sapply(x, length) > 0]) |>
  imap(
    ~ list(
        baseline =
          modeval_data |>
          mutate_if(is.factor, \(x) ifelse(is.na(x), NA, as.numeric(x) - 1)) |>
          select_at(c(var$s, .y, .x$baseline)) |>
          rename_at(.y, \(x) "outcome") |>
          unique()
        , residual =
          modeval_data |>
          mutate_if(is.factor, \(x) ifelse(is.na(x), NA, as.numeric(x) - 1)) |>
          select_at(c(var$s, .y, var$t, .x$residual)) |>
          rename_at(.y, \(x) "outcome") |>
          unique()
      ) |>
      imap(
        ~ list(train = train_id, validation = val_id, test = test_id) |>
          lapply(\(x) filter(.x, id %in% x))
      )
  )
```

# Dimensional reduction

```{r Dim reduction needed for regression training, include=FALSE}
dim_red_train_regression <-
  modeval_data_set_ori |>
  imap(
    ~ names(.x) |>
      lapply(
        \(x)
        names(.x[[x]]) |>
          lapply(
            \(y)
            .x[[x]][[y]] |>
              rename(cat = outcome) |>
              mutate(outcome = .y, type = x, set = y) |>
              group_by(outcome, type, set, cat) |>
              summarize(n = n(), .groups = "drop") |>
              mutate(
                pred =
                  sum(!colnames(.x[[x]][[y]]) %in% c("id", "outcome"))
              )
          ) |>
          reduce(rbind)
      ) |>
      reduce(rbind)
  ) |>
  reduce(rbind) |>
  filter(set == "train") |>
  filter(!is.na(cat)) |>
  group_by(outcome, type, set) |>
  filter(n == min(n)) |>
  ungroup() |>
  mutate(epv = ceiling(n/pred), min_epv = 20) |>
  mutate(max_pred = floor(n/min_epv))
```

```{r table-16, echo=FALSE}
dim_red_train_regression |>
  mutate(
    outcome =
      paste0(outcome, ifelse(pred > max_pred & max_pred > 1, "*", ""))
  ) |>
  select(-set) |>
  kable(
    caption = "Table 16. Dimensional reduction needed for regression training."
    , format = kable_format
  ) |>
  footnote("*, require dimensional reduction.") |>
  kable_classic() |>
  column_spec(1:8, extra_css = "vertical-align:top;")
```

```{r Prepare dimensional reduction inputs, include=FALSE}
dr_input <-
  dim_red_train_regression |>
  filter(pred > max_pred & max_pred > 1) |>
  select(outcome, type, set, pred, max_pred)

dr_input <-
  seq(nrow(dr_input)) |>
  lapply(
    \(x)
    modeval_data_set_ori[[
        dr_input$outcome[x]
      ]][[
        dr_input$type[x]
      ]] |>
      list() |>
      `names<-`(dr_input$type[x])
  ) |>
  `names<-`(dr_input$outcome)
```

```{r Conduct principal component analysis, include=FALSE}
dr_model <-
  dr_input |>
  lapply(lapply, \(x) select(x$train, -id, -outcome)) |>
  lapply(lapply, \(x) prcomp(x, scale. = TRUE))
```

```{r Describe dimensional reduction models, include=FALSE}
dr_model_desc <-
  dr_model |>
  imap(
    ~ names(.x) |>
      `names<-`(names(.x)) |>
      lapply(
        \(x)
        .x[[x]]$rotation[
            , dim_red_train_regression |>
              filter(outcome == .y & type == x) |>
              pull(max_pred) |>
              seq()
            , drop = FALSE
          ] |>
          as.data.frame() |>
          rownames_to_column(var =  "old_dim") |>
          gather(new_dim, weight, -old_dim) |>
          mutate(outcome = .y, type = x) |>
          mutate(
            pve =
              c(.x[[x]]$sdev^2/sum(.x[[x]]$sdev^2))[
                dim_red_train_regression |>
                  filter(outcome == .y & type == x) |>
                  pull(max_pred) |>
                  seq()
              ] |>
              sum()
          ) |>
          select(outcome, type, pve, everything())
      ) |>
      reduce(rbind)
  ) |>
  reduce(rbind)
```

```{r Write new dimension old names, eval=FALSE, include=FALSE}
dr_model_desc |>
  select(outcome, type, old_name = new_dim) |>
  unique() |>
  mutate(new_name = NA) |>
  write_csv("inst/extdata/new_dimension_old_name.csv")
```

```{r Load new dimension new names, include=FALSE}
new_dimension_new_name <-
  read_csv("inst/extdata/new_dimension_new_name.csv", show_col_types = FALSE)
```

```{r Plot dimensional reduction model weights, include=FALSE}
dr_model_weight_plot <-
  unique(dr_model_desc$outcome) |>
  `names<-`(unique(dr_model_desc$outcome)) |>
  lapply(
    \(x)
    unique(filter(dr_model_desc, outcome == x)$type) |>
      `names<-`(unique(filter(dr_model_desc, outcome == x)$type)) |>
      lapply(
        \(y)
        dr_model_desc |>
          filter(outcome == x & type == y) |>
          mutate(
            direction = ifelse(weight < 0, "-", "+")
            , weight  = abs(weight)
          ) |>
          arrange(new_dim, desc(weight)) |>
          group_by(new_dim) |>
          mutate(rank = seq(n())) |>
          ungroup() |>
          mutate(old_dim = reorder(paste0(old_dim, "-", rank), rank)) |>
          left_join(
            new_dimension_new_name |>
              rename(new_dim = old_name)
            , by = join_by(outcome, type, new_dim)
          ) |>
          mutate(new_dim = new_name) |>
          ggplot(aes(old_dim, weight, fill = direction)) +
          geom_col() +
          facet_grid(
            ~ new_dim
            , scales = "free_x"
          ) +
          scale_y_continuous(limits = c(0, max(abs(dr_model_desc$weight)))) +
          scale_fill_discrete("") +
          xlab("") +
          ylab(
            paste0(
              "PVE = "
              , dr_model_desc |>
                filter(outcome == x & type == y) |>
                pull(pve) |>
                unique() |>
                sapply(\(x) round(x*100, 2))
              , "%"
            )
          ) +
          theme(
            axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
            , axis.title.y = element_text(size = 9)
          )
      )
  )
```

```{r figure-5, echo=FALSE, fig.height=3, fig.width=7}
ggarrange(
  ggarrange(
    dr_model_weight_plot$rop_severe$baseline +
        theme(legend.position = "none")
    , NULL
    , ncol = 1
    , nrow = 2
    , heights = c(4, 1)
  )
  , dr_model_weight_plot$survive$baseline
  , ncol = 2
  , nrow = 1
  , widths =
    c(nrow(dr_model_weight_plot$rop_severe$baseline$data)
      , nrow(dr_model_weight_plot$survive$baseline$data) +3
    )
  , labels = LETTERS[1:2]
)
```

Figure 5. Dimensional reduction model weights for predictors of: (A) Severe ROP baseline prediction; and (B) survival baseline prediction. PVE, proportion of variance explained

```{r Reduce dimensions using the models, include=FALSE}
dr_output <-
  dr_input |>
  imap(
    ~ names(.x) |>
      `names<-`(names(.x)) |>
      lapply(
        \(x)
        names(.x[[x]]) |>
          `names<-`(names(.x[[x]])) |>
          lapply(\(y) reduce_dim_pca(dr_input, dr_model, .y, x, y))
      )
  )
```

```{r Change data for mod & eval to dr outputs accordingly, include=FALSE}
modeval_data_set <-
  modeval_data_set_ori |>
  imap(
    ~ names(.x) |>
      `names<-`(names(.x)) |>
      lapply(
        \(x)
        list(
          .x[[x]]
          , dr_output[[.y]][[x]]
        )[[
          ifelse(
            nrow(filter(dr_model_desc, outcome == .y & type == x)) > 0
            , 2, 1
          )
        ]]
      )
  )
```

# Predictive modeling

```{r Determine prediction sequence by competing risks, include=FALSE}
pred_seq <-
  list(
    survive = c("survive")
    , rop_severe = c("survive", "rop_severe")
    , bpd = c("survive", "bpd")
    , bpd_moderate_severe = c("survive", "bpd", "bpd_moderate_severe")
    , eugr_hc = c("survive", "eugr_hc")
    , eugr_bw = c("survive", "eugr_bw")
    , rop_severe = c("survive", "hearing")
  )

save_dir <- "inst/extdata/modeval_data_set/"
if(!dir.exists(save_dir)) dir.create(save_dir, recursive = TRUE)
```


```{r Show prediction sequence by competing risks, echo=FALSE}
pred_seq |>
  imap(~ paste0(.y, ": ", paste0(.x, collapse = " -> "))) |>
  unlist() |>
  paste0(collapse = "\n") |>
  cat()
```

## Survival prediction

```{r Survival prediction - Write baseline 1, include=FALSE}
modeval_data_set$survive$baseline |>
  imap(
    ~ .x |>
      write_csv(
        paste0("inst/extdata/modeval_data_set/survive_baseline1_", .y, ".csv")
      )
  )
```

```{r Survival prediction - Baseline 1 results, include=FALSE}
survive_baseline1 <-
  obtain_obs_pred(
    prefix = "survive_baseline1"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r Survival prediction - Write stack, include=FALSE}
stack_prediction(
    modeval_data_set$survive$residual
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
    , prior_model_name = "survive_baseline1"
    , indices = c("id")
  ) |>
  imap(
    ~ .x |>
      write_csv(
        paste0(
          "inst/extdata/modeval_data_set/survive_stack_", .y, ".csv"
        )
      )
  )
```

```{r Survival prediction - Stack results, include=FALSE}
survive_stack <-
  obtain_obs_pred(
    prefix = "survive_stack"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

## Severe ROP prediction

```{r Severe ROP prediction - Write baseline 2, include=FALSE}
stack_prediction(
    modeval_data_set$rop_severe$baseline
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
    , prior_model_name = "survive_baseline1"
    , indices = c("id")
  ) |>
  lapply(filter, !is.na(outcome)) |>
  imap(
    ~ .x |>
      write_csv(
        paste0(
          "inst/extdata/modeval_data_set/rop_severe_baseline2_", .y, ".csv"
        )
      )
  )
```

```{r Severe ROP prediction - Baseline 2 results, include=FALSE}
rop_severe_baseline2 <-
  obtain_obs_pred(
    prefix = "rop_severe_baseline2"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r Severe ROP prediction - Write stack 1, include=FALSE}
stack_prediction(
    lapply(modeval_data_set$rop_severe$baseline, select, id, outcome) |>
      imap(
        ~ .x |>
          right_join(
            select(modeval_data_set$survive$residual[[.y]], -outcome)
            , by = join_by(id)
          )
      )
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
    , prior_model_name = "rop_severe_baseline2"
    , indices = c("id")
  ) |>
  lapply(filter, !is.na(outcome)) |>
  imap(
    ~ .x |>
      write_csv(
        paste0(
          "inst/extdata/modeval_data_set/rop_severe_stack1_", .y, ".csv"
        )
      )
  )
```

```{r Severe ROP prediction - Stack 1 results, include=FALSE}
rop_severe_stack1 <-
  obtain_obs_pred(
    prefix = "rop_severe_stack1"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r Severe ROP prediction - Write stack, include=FALSE}
stack_prediction(
    modeval_data_set$rop_severe$residual
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
    , prior_model_name = "rop_severe_stack1"
    , indices =  c("id", "t")
  ) |>
  lapply(filter, !is.na(outcome)) |>
  imap(
    ~ .x |>
      write_csv(
        paste0(
          "inst/extdata/modeval_data_set/rop_severe_stack_", .y, ".csv"
        )
      )
  )
```

```{r Severe ROP prediction - Stack results, include=FALSE}
rop_severe_stack <-
  obtain_obs_pred(
    prefix = "rop_severe_stack"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

## BPD prediction

```{r BPD prediction - Write baseline 2, include=FALSE}
stack_prediction(
    modeval_data_set$bpd$baseline
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
    , prior_model_name = "survive_baseline1"
    , indices = c("id")
  ) |>
  lapply(filter, !is.na(outcome)) |>
  imap(
    ~ .x |>
      write_csv(
        paste0(
          "inst/extdata/modeval_data_set/bpd_baseline2_", .y, ".csv"
        )
      )
  )
```

```{r BPD prediction - Baseline 2 results, include=FALSE}
bpd_baseline2 <-
  obtain_obs_pred(
    prefix = "bpd_baseline2"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r BPD prediction - Write stack 1, include=FALSE}
stack_prediction(
    lapply(modeval_data_set$bpd$baseline, select, id, outcome) |>
      imap(
        ~ .x |>
          right_join(
            select(modeval_data_set$survive$residual[[.y]], -outcome)
            , by = join_by(id)
          )
      )
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
    , prior_model_name = "bpd_baseline2"
    , indices = c("id")
  ) |>
  lapply(filter, !is.na(outcome)) |>
  imap(
    ~ .x |>
      write_csv(
        paste0(
          "inst/extdata/modeval_data_set/bpd_stack1_", .y, ".csv"
        )
      )
  )
```

```{r BPD prediction - Stack 1 results, include=FALSE}
bpd_stack1 <-
  obtain_obs_pred(
    prefix = "bpd_stack1"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r BPD prediction - Write stack, include=FALSE}
stack_prediction(
    modeval_data_set$bpd$residual
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
    , prior_model_name = "bpd_stack1"
    , indices =  c("id", "t")
  ) |>
  lapply(filter, !is.na(outcome)) |>
  imap(
    ~ .x |>
      write_csv(
        paste0(
          "inst/extdata/modeval_data_set/bpd_stack_", .y, ".csv"
        )
      )
  )
```

```{r BPD prediction - Stack results, include=FALSE}
bpd_stack <-
  obtain_obs_pred(
    prefix = "bpd_stack"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

## Moderate/severe BPD prediction

```{r Mod/sev BPD prediction - Write baseline 3, include=FALSE}
stack_prediction(
    modeval_data_set$bpd_moderate_severe$baseline
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
    , prior_model_name = "bpd_baseline2"
    , indices = c("id")
  ) |>
  lapply(filter, !is.na(outcome)) |>
  imap(
    ~ .x |>
      write_csv(
        paste0(
          "inst/extdata/modeval_data_set/bpd_moderate_severe_baseline3_"
          , .y, ".csv"
        )
      )
  )
```

```{r Mod/sev BPD prediction - Baseline 3 results, include=FALSE}
bpd_moderate_severe_baseline3 <-
  obtain_obs_pred(
    prefix = "bpd_moderate_severe_baseline3"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r Mod/sev BPD prediction - Write stack 1, include=FALSE}
stack_prediction(
    modeval_data_set$bpd_moderate_severe$baseline |>
      lapply(select, id, outcome) |>
      imap(
        ~ .x |>
          right_join(
            select(modeval_data_set$survive$residual[[.y]], -outcome)
            , by = join_by(id)
          )
      )
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
    , prior_model_name = "bpd_moderate_severe_baseline3"
    , indices = c("id")
  ) |>
  lapply(filter, !is.na(outcome)) |>
  imap(
    ~ .x |>
      write_csv(
        paste0(
          "inst/extdata/modeval_data_set/bpd_moderate_severe_stack1_"
          , .y, ".csv"
        )
      )
  )
```

```{r Mod/sev BPD prediction - Stack 1 results, include=FALSE}
bpd_moderate_severe_stack1 <-
  obtain_obs_pred(
    prefix = "bpd_moderate_severe_stack1"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r Mod/sev BPD prediction - Write stack 2, include=FALSE}
stack_prediction(
    modeval_data_set$bpd$residual
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
    , prior_model_name = "bpd_moderate_severe_stack1"
    , indices =  c("id", "t")
  ) |>
  lapply(filter, !is.na(outcome)) |>
  imap(
    ~ .x |>
      write_csv(
        paste0(
          "inst/extdata/modeval_data_set/bpd_moderate_severe_stack2_"
          , .y, ".csv"
        )
      )
  )
```

```{r Mod/sev BPD prediction - Stack 2 results, include=FALSE}
bpd_moderate_severe_stack2 <-
  obtain_obs_pred(
    prefix = "bpd_moderate_severe_stack2"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r Mod/sev BPD prediction - Write stack, include=FALSE}
stack_prediction(
    modeval_data_set$bpd_moderate_severe$residual
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
    , prior_model_name = "bpd_moderate_severe_stack2"
    , indices =  c("id", "t")
  ) |>
  lapply(filter, !is.na(outcome)) |>
  imap(
    ~ .x |>
      write_csv(
        paste0(
          "inst/extdata/modeval_data_set/bpd_moderate_severe_stack_"
          , .y, ".csv"
        )
      )
  )
```

```{r Mod/sev BPD prediction - Stack results, include=FALSE}
bpd_moderate_severe_stack <-
  obtain_obs_pred(
    prefix = "bpd_moderate_severe_stack"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

## EUGR-HC prediction

```{r EUGR-HC prediction - Write baseline 2, include=FALSE}
stack_prediction(
    modeval_data_set$eugr_hc$baseline
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
    , prior_model_name = "survive_baseline1"
    , indices = c("id")
  ) |>
  lapply(filter, !is.na(outcome)) |>
  imap(
    ~ .x |>
      write_csv(
        paste0(
          "inst/extdata/modeval_data_set/eugr_hc_baseline2_", .y, ".csv"
        )
      )
  )
```

```{r EUGR-HC prediction - Baseline 2 results, include=FALSE}
eugr_hc_baseline2 <-
  obtain_obs_pred(
    prefix = "eugr_hc_baseline2"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r EUGR-HC prediction - Write stack 1, include=FALSE}
stack_prediction(
    lapply(modeval_data_set$eugr_hc$baseline, select, id, outcome) |>
      imap(
        ~ .x |>
          right_join(
            select(modeval_data_set$survive$residual[[.y]], -outcome)
            , by = join_by(id)
          )
      )
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
    , prior_model_name = "eugr_hc_baseline2"
    , indices = c("id")
  ) |>
  lapply(filter, !is.na(outcome)) |>
  imap(
    ~ .x |>
      write_csv(
        paste0(
          "inst/extdata/modeval_data_set/eugr_hc_stack1_", .y, ".csv"
        )
      )
  )
```

```{r EUGR-HC prediction - Stack 1 results, include=FALSE}
eugr_hc_stack1 <-
  obtain_obs_pred(
    prefix = "eugr_hc_stack1"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r EUGR-HC prediction - Write stack, include=FALSE}
stack_prediction(
    modeval_data_set$eugr_hc$residual
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
    , prior_model_name = "eugr_hc_stack1"
    , indices =  c("id", "t")
  ) |>
  lapply(filter, !is.na(outcome)) |>
  imap(
    ~ .x |>
      write_csv(
        paste0(
          "inst/extdata/modeval_data_set/eugr_hc_stack_", .y, ".csv"
        )
      )
  )
```

```{r EUGR-HC prediction - Stack results, include=FALSE}
eugr_hc_stack <-
  obtain_obs_pred(
    prefix = "eugr_hc_stack"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

## EUGR-BW prediction

```{r EUGR-BW prediction - Write stack, include=FALSE}
stack_prediction(
    modeval_data_set$eugr_bw$residual
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
    , prior_model_name = "survive_stack"
    , indices =  c("id", "t")
  ) |>
  lapply(filter, !is.na(outcome)) |>
  imap(
    ~ .x |>
      write_csv(
        paste0(
          "inst/extdata/modeval_data_set/eugr_bw_stack_", .y, ".csv"
        )
      )
  )
```

```{r EUGR-BW prediction - Stack results, include=FALSE}
eugr_bw_stack <-
  obtain_obs_pred(
    prefix = "eugr_bw_stack"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

## Failed hearing test prediction

```{r Failed hearing prediction - Write stack, include=FALSE}
stack_prediction(
    modeval_data_set$hearing$residual
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
    , prior_model_name = "survive_stack"
    , indices =  c("id", "t")
  ) |>
  lapply(filter, !is.na(outcome)) |>
  imap(
    ~ .x |>
      write_csv(
        paste0(
          "inst/extdata/modeval_data_set/hearing_stack_", .y, ".csv"
        )
      )
  )
```

```{r Failed hearing prediction - Stack results, include=FALSE}
hearing_stack <-
  obtain_obs_pred(
    prefix = "hearing_stack"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

# Model evaluation

```{r Create empty list for model evaluation, include=FALSE}
eval <- list()
eval_plot <- list()
th <- list()
```

```{r Create list for model evaluation data, include=FALSE}
eval_df_list <-
  list(
    survive_baseline1 = survive_baseline1
    , survive_stack = survive_stack
    , rop_severe_baseline2 = rop_severe_baseline2
    , rop_severe_stack = rop_severe_stack
    , bpd_baseline2 = bpd_baseline2
    , bpd_stack = bpd_stack
    , bpd_moderate_severe_baseline3 = bpd_moderate_severe_baseline3
    , bpd_moderate_severe_stack = bpd_moderate_severe_stack
    , eugr_hc_baseline2 = eugr_hc_baseline2
    , eugr_hc_stack = eugr_hc_stack
    , eugr_bw_stack = eugr_bw_stack
    , hearing_stack = hearing_stack
  )
```

```{r Evaluate calibration, include=FALSE}
eval$calibration <-
  eval_df_list |>
  lapply(\(x) lapply(x, calibration, seed = seed))
```

```{r Evaluate decision, eval=FALSE, include=FALSE}
eval$decision <-
  eval_df_list |>
  pblapply(\(x) lapply(lapply(x, select, -id), decision, seed = seed))

saveRDS(eval$decision, "data/eval_decision.rds")
```

```{r Load pre-evaluated decision, include=FALSE}
eval$decision <- readRDS("data/eval_decision.rds")
```

```{r Evaluate discrimination, eval=FALSE, include=FALSE}
eval$discrimination <-
  eval_df_list |>
  pblapply(\(x) lapply(lapply(x, select, -id), discrimination, seed = seed))

saveRDS(eval$discrimination, "data/eval_discrimination.rds")
```

```{r Load pre-evaluated discrimination, include=FALSE}
eval$discrimination <- readRDS("data/eval_discrimination.rds")
```

```{r Determine threshold using train set, eval=FALSE, include=FALSE}
eval$threshold <-
  eval_df_list |>
  pblapply(
    \(x)
    lapply(x, select, -id)["train"] |>
    lapply(
      thresholding
      , custom_metric = "tnr", custom_ref = 0.95, seed = seed
    )
  )

saveRDS(eval$threshold, "data/eval_threshold.rds")
```

```{r Load pre-evaluated threshold, include=FALSE}
eval$threshold <- readRDS("data/eval_threshold.rds")
```

## Evaluation metrics

### Survival baseline

```{r Determine threshold for survive baseline by train set, include=FALSE}
th$survive_baseline1 <-
  eval$threshold$survive_baseline1$train |>
  filter(ref_type == "TNR" & ref_value == 0.95 & metric == "th") |>
  pull(avg)
```

```{r Evaluate survive baseline using test set, include=FALSE}
eval_plot$survive_baseline1 <-
  lapply(eval, \(x) x$survive_baseline1$test) |>
  arrange_eval_plot(
    threshold = th$survive_baseline1
    , dc_xby = 0.1, dc_yby = 0.1, dc_ta_angle = -60
  )
```

```{r figure-6, echo=FALSE, fig.height=4, fig.width=10}
eval_plot$survive_baseline1
```

Figure 6. Survival baseline prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; and (C) ROC curve. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics.

### Survival stack

```{r Determine threshold for survive stack by train set, include=FALSE}
th$survive_stack <-
  eval$threshold$survive_stack$train |>
  filter(ref_type == "(TPR+TNR)/2" & metric == "th") |>
  pull(avg)
```

```{r Evaluate survive stack using test set, include=FALSE}
eval_plot$survive_stack <-
  lapply(eval, \(x) x$survive_stack$test) |>
  arrange_eval_plot(
    threshold = th$survive_stack
    , dc_xby = 0.1, dc_yby = 0.1
    , dc_ta_angle = -60
  )
```

```{r figure-7, echo=FALSE, fig.height=4, fig.width=10}
eval_plot$survive_stack
```

Figure 7. Survival stacked prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; and (C) ROC curve. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics.

### Severe ROP baseline

```{r Determine threshold for severe ROP baseline by train set, include=FALSE}
th$rop_severe_baseline2 <-
  eval$threshold$rop_severe_baseline2$train |>
  filter(ref_type == "TNR" & ref_value == 0.95 & metric == "th") |>
  pull(avg)
```

```{r Evaluate severe ROP baseline using test set, include=FALSE}
eval_plot$rop_severe_baseline2 <-
  lapply(eval, \(x) x$rop_severe_baseline2$test) |>
  arrange_eval_plot(
    threshold = th$rop_severe_baseline2
    , dc_xmax = 0.4, dc_xby = 0.1
    , dc_ymax = 0.13
    , dc_ta_angle = -80
  )
```

```{r figure-8, echo=FALSE, fig.height=4, fig.width=10}
eval_plot$rop_severe_baseline2
```

Figure 8. Severe ROP baseline prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; and (C) ROC curve. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics.

### Severe ROP stack

```{r Determine threshold for severe ROP stack by train set, include=FALSE}
th$rop_severe_stack <-
  eval$threshold$rop_severe_stack$train |>
  filter(ref_type == "TNR" & ref_value == 0.95 & metric == "th") |>
  pull(avg)
```

```{r Evaluate severe ROP stack using test set, include=FALSE}
eval_plot$rop_severe_stack <-
  lapply(eval, \(x) x$rop_severe_stack$test) |>
  arrange_eval_plot(
    threshold = th$rop_severe_stack
    , dc_xmax = 0.4, dc_xby = 0.1
    , dc_ymax = 0.15, dc_yby = 0.01
    , dc_ta_angle = -80
  )
```

```{r figure-9, echo=FALSE, fig.height=4, fig.width=10}
eval_plot$rop_severe_stack
```

Figure 9. Severe ROP stacked prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; and (C) ROC curve. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics.

### BPD baseline

```{r Determine threshold for BPD baseline by train set, include=FALSE}
th$bpd_baseline2 <-
  eval$threshold$bpd_baseline2$train |>
  filter(ref_type == "TNR" & ref_value == 0.95 & metric == "th") |>
  pull(avg)
```

```{r Evaluate BPD baseline using test set, include=FALSE}
eval_plot$bpd_baseline2 <-
  lapply(eval, \(x) x$bpd_baseline2$test) |>
  arrange_eval_plot(
    threshold = th$bpd_baseline2
    , dc_xmax = 0.6, dc_xby = 0.1
    , dc_ymax = 0.35, dc_yby = 0.05
    , dc_ta_angle = -70
  )
```

```{r figure-10, echo=FALSE, fig.height=4, fig.width=10}
eval_plot$bpd_baseline2
```

Figure 10. BPD baseline prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; and (C) ROC curve. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics.

### BPD stack

```{r Determine threshold for BPD stack by train set, include=FALSE}
th$bpd_stack <-
  eval$threshold$bpd_stack$train |>
  filter(ref_type == "(TPR+TNR)/2" & metric == "th") |>
  pull(avg)
```

```{r Evaluate BPD stack using test set, include=FALSE}
eval_plot$bpd_stack <-
  lapply(eval, \(x) x$bpd_stack$test) |>
  arrange_eval_plot(
    threshold = th$bpd_stack
    , dc_xmax = 0.6, dc_xby = 0.1
    , dc_ymax = 0.35, dc_yby = 0.05
    , dc_ta_angle = -70
  )
```

```{r figure-11, echo=FALSE, fig.height=4, fig.width=10}
eval_plot$bpd_stack
```

Figure 11. BPD stacked prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; and (C) ROC curve. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics.

### Moderate/severe BPD baseline

```{r Determine threshold for moderate/severe BPD baseline by train set, include=FALSE}
th$bpd_moderate_severe_baseline3 <-
  eval$threshold$bpd_moderate_severe_baseline3$train |>
  filter(ref_type == "TNR" & ref_value == 0.95 & metric == "th") |>
  pull(avg)
```

```{r Evaluate moderate/severe BPD baseline using test set, include=FALSE}
eval_plot$bpd_moderate_severe_baseline3 <-
  lapply(eval, \(x) x$bpd_moderate_severe_baseline3$test) |>
  arrange_eval_plot(
    threshold = th$bpd_moderate_severe_baseline3
    , dc_xmax = 0.6, dc_xby = 0.1
    , dc_ymax = 0.35, dc_yby = 0.05
    , dc_ta_angle = -70
  )
```

```{r figure-12, echo=FALSE, fig.height=4, fig.width=10}
eval_plot$bpd_moderate_severe_baseline3
```

Figure 12. Moderate/severe BPD baseline prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; and (C) ROC curve. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics.

### Moderate/severe BPD stack

```{r Determine threshold for moderate/severe BPD stack by train set, include=FALSE}
th$bpd_moderate_severe_stack <-
  eval$threshold$bpd_moderate_severe_stack$train |>
  filter(ref_type == "TNR" & ref_value == 0.95 & metric == "th") |>
  pull(avg)
```

```{r Evaluate moderate/severe BPD stack using test set, include=FALSE}
eval_plot$bpd_moderate_severe_stack <-
  lapply(eval, \(x) x$bpd_moderate_severe_stack$test) |>
  arrange_eval_plot(
    threshold = th$bpd_moderate_severe_stack
    , dc_xmax = 0.6, dc_xby = 0.1
    , dc_ymax = 0.35, dc_yby = 0.05
    , dc_ta_angle = -70
  )
```

```{r figure-13, echo=FALSE, fig.height=4, fig.width=10}
eval_plot$bpd_moderate_severe_stack
```

Figure 13. Moderate/severe BPD stacked prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; and (C) ROC curve. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics.

### EUGR-HC baseline

```{r Determine threshold for EUGR-HC baseline by train set, include=FALSE}
th$eugr_hc_baseline2 <-
  eval$threshold$eugr_hc_baseline2$train |>
  filter(ref_type == "TNR" & ref_value == 0.95 & metric == "th") |>
  pull(avg)
```

```{r Evaluate EUGR-HC baseline using test set, include=FALSE}
eval_plot$eugr_hc_baseline2 <-
  lapply(eval, \(x) x$eugr_hc_baseline2$test) |>
  arrange_eval_plot(
    threshold = th$eugr_hc_baseline2
    , dc_xmax = 0.6, dc_xby = 0.1
    , dc_ymax = 0.3, dc_yby = 0.05
    , dc_ta_angle = -75
  )
```

```{r figure-14, echo=FALSE, fig.height=4, fig.width=10}
eval_plot$eugr_hc_baseline2
```

Figure 14. EUGR-HC baseline prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; and (C) ROC curve. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics.

### EUGR-HC stack

```{r Determine threshold for EUGR-HC stack by train set, include=FALSE}
th$eugr_hc_stack <-
  eval$threshold$eugr_hc_stack$train |>
  filter(ref_type == "TNR" & ref_value == 0.95 & metric == "th") |>
  pull(avg)
```

```{r Evaluate EUGR-HC stack using test set, include=FALSE}
eval_plot$eugr_hc_stack <-
  lapply(eval, \(x) x$eugr_hc_stack$test) |>
  arrange_eval_plot(
    threshold = th$eugr_hc_stack
    , dc_xmax = 0.6, dc_xby = 0.1
    , dc_ymax = 0.3, dc_yby = 0.05
    , dc_ta_angle = -75
  )
```

```{r figure-15, echo=FALSE, fig.height=4, fig.width=10}
eval_plot$eugr_hc_stack
```

Figure 15. EUGR-HC stacked prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; and (C) ROC curve. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics.

### EUGR-BW stack

```{r Determine threshold for EUGR-BW stack by train set, include=FALSE}
th$eugr_bw_stack <-
  eval$threshold$eugr_bw_stack$train |>
  filter(ref_type == "TNR" & ref_value == 0.95 & metric == "th") |>
  pull(avg)
```

```{r Evaluate EUGR-BW stack using test set, include=FALSE}
eval_plot$eugr_bw_stack <-
  lapply(eval, \(x) x$eugr_bw_stack$test) |>
  arrange_eval_plot(
    threshold = th$eugr_bw_stack
    , dc_xmax = 0.6, dc_xby = 0.1
    , dc_ymax = 0.25, dc_yby = 0.05
    , dc_ta_angle = -80
  )
```

```{r figure-16, echo=FALSE, fig.height=4, fig.width=10}
eval_plot$eugr_bw_stack
```

Figure 16. EUGR-BW stacked prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; and (C) ROC curve. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics.

### Failed hearing test stack

```{r Determine threshold for failed hearing stack by train set, include=FALSE}
th$hearing_stack <-
  eval$threshold$hearing_stack$train |>
  filter(ref_type == "TNR" & ref_value == 0.95 & metric == "th") |>
  pull(avg)
```

```{r Evaluate failed hearing stack using test set, include=FALSE}
eval_plot$hearing_stack <-
  lapply(eval, \(x) x$hearing_stack$test) |>
  arrange_eval_plot(
    threshold = th$hearing_stack
    , dc_xmax = 0.3, dc_xby = 0.1
    , dc_ymax = 0.12, dc_yby = 0.02
    , dc_ta_angle = -80
  )
```

```{r figure-17, echo=FALSE, fig.height=4, fig.width=10}
eval_plot$hearing_stack
```

Figure 17. Failed hearing test stacked prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; and (C) ROC curve. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics.

## Predictive performance

```{r Compute CM using train-set threshold, eval=FALSE, include=FALSE}
eval$cm <-
  names(eval_df_list) |>
  `names<-`(names(eval_df_list)) |>
  pblapply(
    \(x)
    lapply(eval_df_list[[x]], select, -id)[c("validation", "test")] |>
    lapply(
      thresholding
      , custom_metric = "th", custom_ref = th[[x]], seed = seed
    )
  )

saveRDS(eval$cm, "data/eval_cm.rds")
```

```{r Load pre-computed CM using train-set threshold, include=FALSE}
eval$cm <- readRDS("data/eval_cm.rds")
```

```{r Summarize confusion matrix using test set, include=FALSE}
cm_summary <-
  eval[c("calibration", "decision", "discrimination")] |>
  lapply(\(x) reduce(imap(x, ~ mutate(.x$test$metrics, model = .y)), rbind)) |>
  reduce(rbind) |>
  filter(term %in% c("AUC-ROC")) |>
  mutate(lb = estimate - ci, ub = estimate + ci) |>
  select(-ci) |>
  select(model, metric = term, avg = estimate, everything()) |>
  rbind(
    eval$cm |>
      imap(~ mutate(.x$test, model = .y)) |>
      reduce(rbind) |>
      filter(ref_type == "TH" & !metric %in% c("th", "nb")) |>
      mutate(metric = str_to_upper(metric)) |>
      select(-ref_type, -ref_value) |>
      select(model, metric, avg, everything())
  ) |>
  mutate_at(c("avg", "lb", "ub"), format, digits = 2) |>
  unite(ci, lb, ub, sep = ", ") |>
  mutate_at("ci", \(x) paste0("(", x, ")")) |>
  unite(summary, avg, ci, sep = " ") |>
  mutate(
    model = factor(model, unique(model))
    , metric = factor(metric, c("AUC-ROC", "TNR", "TPR", "PPV", "NPV"))
  ) |>
  spread(metric, summary) |>
  left_join(
    reduce(imap(th, ~ data.frame(model = .y, TH = .x)), rbind)
    , by = join_by(model)
  ) |>
  select(model, `AUC-ROC`, TH, everything())
```

```{r table-17, echo=FALSE}
cm_summary |>
  kable(
    caption = "Table 17. Predictive performance using test set."
    , format = kable_format
  ) |>
  footnote(
    paste0(
      "AUC-ROC, area under the curve - receiver operating characteristics; "
      , "TH, the chosen threshold, ~95% specificity if possible; "
      , "TNR, true negative rate (specificity), ~95% if possible; "
      , "TPR, true positive rate (sensitivity/recall); "
      , "PPV, positive predictive value (precision); "
      , "NPV, negative predictive value. "
    )
  ) |>
  kable_classic() |>
  column_spec(1:7, extra_css = "vertical-align:top;")
```

# Model deployment

```{r Compile any-outcome baseline & stack predictions per id-t, include=FALSE}
pred_results_train <-
  c("baseline", "stack") |>
  lapply(
    \(x)
    names(eval_df_list)[str_detect(names(eval_df_list), x)] |>
      `names<-`(names(eval_df_list)[str_detect(names(eval_df_list), x)]) |>
      imap(
        ~ .x |>
          obtain_pred(
            data_dir = "inst/extdata/modeval_data_set/"
            , model_dir = "inst/extdata/model/"
            , identifiers =
              ifelse(c(x, x) %in% "baseline", c("id", "id"), c("id", "t")) |>
              unique()
          ) |>
          mutate(model = .y) |>
          left_join(
            reduce(imap(th, ~ data.frame(model = .y, TH = .x)), rbind)
            , by = join_by(model)
          ) |>
          select(-model) |>
          mutate(target = str_remove_all(.y, paste0("_", x, "[:digit:]*"))) |>
          select(target, everything())
      ) |>
      reduce(rbind) |>
      rename_at("pred", \(y) x) |>
      rename_at("TH", \(y) paste0(x, "_th"))
  ) |>
  reduce(right_join, by = join_by(id, target)) |>
  mutate_at("id", as.character) |>
  left_join(
    modeval_data_set |>
      imap(~ mutate(select(.x$residual$train, id, t, outcome), target = .y)) |>
      reduce(rbind)
    , by = join_by(id, t, target)
  ) |>
  left_join(select(modeval_data, id, t, death_age), by = join_by(id, t)) |>
  mutate(death_age = (round(death_age) + 1))
```

```{r Create empty list to select prediction results, include=FALSE}
selected_pred_results <- list()
```

```{r Truely (~90%)-predicted die in 14-42 days, include=FALSE}
selected_pred_results$die_14_to_42_day_true <-
  pred_results_train |>
  filter(
    id %in% c(
      pred_results_train |>
        filter(target == "survive") |>
        filter(outcome == 0 & stack < stack_th) |>
        filter(death_age >= 14 & death_age <= 42) |>
        group_by(id) |>
        filter(n() >= 0.9 * 42) |>
        ungroup() |>
        pull(id)
    )
  )
```

```{r Falsely (1+)-predicted die in 14-42 days, include=FALSE}
selected_pred_results$die_14_to_42_day_false <-
  pred_results_train |>
  filter(
    id %in% c(
      pred_results_train |>
        filter(target == "survive") |>
        filter(outcome == 1 & stack < stack_th) |>
        pull(id)
    )
  )
```

```{r Truely (~50%)-predicted survive, include=FALSE}
selected_pred_results$survive_true <-
  pred_results_train |>
  filter(
    id %in% c(
      pred_results_train |>
        filter(target == "survive") |>
        filter(outcome == 1 & stack >= stack_th) |>
        group_by(id) |>
        filter(n() >= 0.5 * 42) |>
        ungroup() |>
        pull(id)
    )
  )
```

```{r Falsely (~20%)-predicted survive, include=FALSE}
selected_pred_results$survive_false <-
  pred_results_train |>
  filter(
    id %in% c(
      pred_results_train |>
        filter(target == "survive") |>
        filter(outcome == 0 & stack >= stack_th) |>
        group_by(id) |>
        filter(n() >= 0.2 * 42) |>
        ungroup() |>
        pull(id)
    )
  )
```

```{r Truely (~20%)-pred ous among truely (~50%)-pred survivors, include=FALSE}
selected_pred_results$other_outcomes_true <-
  selected_pred_results$survive_true |>
  filter(
    id %in% c(
      c("rop_severe"
        , "bpd", "bpd_moderate_severe"
        , "eugr_hc", "eugr_bw"
        , "hearing"
        ) |>
        lapply(
          \(x)
          selected_pred_results$survive_true |>
            filter(target == x) |>
            filter(outcome == 1 & stack >= stack_th) |>
            group_by(id) |>
            filter(n() >= 0.2 * 42) |>
            ungroup() |>
            pull(id)
        ) |>
        reduce(intersect)
    )
  )
```

```{r Falsely (~20%)-pred ous among truely (~50%)-pred survivors, include=FALSE}
selected_pred_results$other_outcomes_false <-
  selected_pred_results$survive_true |>
  filter(
    id %in% c(
      c("rop_severe"
        , "bpd", "bpd_moderate_severe"
        , "eugr_hc", "eugr_bw"
        , "hearing"
        ) |>
        lapply(
          \(x)
          selected_pred_results$survive_true |>
            filter(target == x) |>
            filter(outcome == 1 & stack < stack_th) |>
            group_by(id) |>
            filter(n() >= 0.2 * 42) |>
            ungroup() |>
            pull(id)
        ) |>
        reduce(intersect)
    )
  )
```

```{r Randomly select ID for each evaluation type, include=FALSE}
selected_pred_ids <- c()

for(i in names(selected_pred_results)){
  set.seed(seed)
  selected_pred_ids <-
    selected_pred_ids |>
    c(`names<-`(sample(unique(selected_pred_results[[i]]$id), 1), i))
}

selected_pred_ids <-
  data.frame(
    eval_type = names(selected_pred_ids)
    , id = selected_pred_ids
    , row.names = NULL
  )
```

```{r Compile demo trajectories, include=FALSE}
demo_trajectories <-
  selected_pred_ids |>
  filter(eval_type != "survive_true") |>
  inner_join(
    pred_results_train, by = join_by(id), relationship = "many-to-many"
  )

demo_trajectories <-
  demo_trajectories |>
  select(-t, -stack, -stack_th) |>
  rename(pred = baseline, th = baseline_th) |>
  unique() |>
  mutate(t = 0) |>
  rbind(
    demo_trajectories |>
      select(-baseline, -baseline_th) |>
      rename(pred = stack, th = stack_th)
  ) |>
  mutate_at(c("eval_type", "target"), \(x) factor(x, unique(x))) |>
  arrange(eval_type, target, t)
```

```{r figure-18, echo=FALSE, fig.height=5, fig.width=7}
demo_trajectories |>
  filter(eval_type == "other_outcomes_true") |>
  mutate(
    pred_class = ifelse(pred >= th, "+", "-")
    , outcome = ifelse(outcome == 1, "+", "-")
    , eval =
      case_when(
        outcome == "+" & pred_class == "+" ~ "TP"
        , outcome == "+" & pred_class == "-" ~ "FN"
        , outcome == "-" & pred_class == "+" ~ "FP"
        , outcome == "-" & pred_class == "-" ~ "TN"
      )
    , th_type = ifelse(t == 0, "at birth", "during care")
  ) |>
  filter(!is.na(eval)) |>
  ggplot(aes(t, pred, color = target)) +
  geom_vline(xintercept = c(14, 28, 42), color = "grey", linewidth = 2, lty = 1) +
  geom_smooth(method = "loess", formula = y ~ x, se = FALSE, na.rm = TRUE) +
  geom_point(aes(shape = eval), na.rm = TRUE) +
  scale_x_continuous(
    breaks = c(0, 7, 14, 21, 28, 35, 42), limits = c(0, 42)
  ) +
  scale_linetype_manual(values = c(3, 4)) +
  ylab("") +
  theme(
    strip.text.y.left = element_text(angle = 0)
    , strip.placement = "outside"
  )
```

Figure 18. A case with ~50% truely-predicted survive and ~20% truely-predicted positives for other outcomes.

```{r Plot demo trajectories, include=FALSE}
demo_trajectories_plot <-
  list(TRUE, FALSE) |>
  lapply(
    \(x)
    demo_trajectories |>
      filter(str_detect(eval_type, "die_14_to_42|survive_false") ==  x) |>
      filter(str_detect(target, "survive") ==  x) |>
      mutate(
        pred_class = ifelse(pred >= th, "+", "-")
        , outcome = ifelse(outcome == 1, "+", "-")
        , eval =
          case_when(
            outcome == "+" & pred_class == "+" ~ "TP"
            , outcome == "+" & pred_class == "-" ~ "FN"
            , outcome == "-" & pred_class == "+" ~ "FP"
            , outcome == "-" & pred_class == "-" ~ "TN"
          )
        , th_type = ifelse(t == 0, "at birth", "during care")
      ) |>
      filter(!is.na(eval)) |>
      ggplot(aes(t, pred)) +
      geom_vline(aes(xintercept = death_age), lty = 2, na.rm = TRUE) +
      geom_hline(aes(yintercept = th, lty = th_type), na.rm = TRUE) +
      geom_line(na.rm = TRUE) +
      geom_point(aes(color = eval), size = 0.5, na.rm = TRUE) +
      facet_grid(
        target ~ eval_type
        , switch = "y", scales = "free_y"
      ) +
      scale_x_continuous(
        breaks = c(0, 7, 14, 21, 28, 35, 42), limits = c(0, 42)
      ) +
      scale_linetype_manual(values = c(3, 4)) +
      ylab("") +
      theme(
        strip.text.y.left = element_text(angle = 0)
        , strip.placement = "outside"
      )
  )
```

```{r figure-19, echo=FALSE, fig.height=3, fig.width=7}
demo_trajectories_plot[[1]]
```

Figure 19. Survival trajectories with ~90% truely and 1+ falsely predicted deaths and ~20% falsely predicted survive. Vertical dashed line indicates death age.

```{r figure-20, echo=FALSE, fig.height=5, fig.width=7}
demo_trajectories_plot[[2]]
```

Figure 20. Other outcome trajectories with ~20% truely and ~20% falsely predicted deaths among ~50% truely predicted survive.













































































