---
title: "Neonatal outcomes AI prediction using multimodal trajectory database"
author: "Herdiantri Sufriyana, Yung-Chieh Lin, Chien-Jung Ho, Ting-Chun Yeh, Chao-Ching Huang, Emily Chia-Yu Su"
date: "2024-09-10"
output: html_document
---

# Programming environment

```{r Set random seed, include=FALSE, paged.print=FALSE}
seed <- 2024-09-10
```

```{r Load R packages, include=FALSE}
library(tidyverse)
library(knitr)
library(kableExtra)
library(ggpubr)
library(readxl)
library(broom)
library(MASS)
select <- dplyr::select
library(igraph)
library(ggnetwork)
library(brms)
library(broom.mixed)
library(pbapply)
library(mice)
filter <- dplyr::filter
cbind <- base::cbind
rbind <- base::rbind
tidy <- broom.mixed::tidy
library(parallel)
library(doParallel)
library(survival)
```

```{r Load custom functions, include=FALSE}
lapply(list.files("R/", pattern = "-function.R", full.names = TRUE), source)
```

```{r Set theme, include=FALSE}
dslabs::ds_theme_set()
kable_format <- "html"
```

# Load raw data

```{r List raw data paths, include=FALSE}
paths_old_name <-
  list.files(
    "inst/extdata/2011-202312_GA_22-30_838"
    , pattern = "\\.xlsx$"
    , full.names = TRUE
  )
```

```{r Write raw data path old names, eval=FALSE, include=FALSE}
data.frame(name = NA, path = paths_old_name)  |>
  write_csv("inst/extdata/paths_old_name.csv")
```

```{r Read raw data path new names, include=FALSE}
paths_new_name <-
  read_csv("inst/extdata/paths_new_name.csv", show_col_types = FALSE)
```

```{r List raw indep-test data paths, include=FALSE}
paths_old_name_indep_test <-
  list.files(
    "inst/extdata/validation_87"
    , pattern = "\\.xlsx$"
    , full.names = TRUE
  )
```

```{r Write raw indep-test data path old names, eval=FALSE, include=FALSE}
data.frame(name = NA, path = paths_old_name_indep_test)  |>
  write_csv("inst/extdata/paths_old_name_indep_test.csv")
```

```{r Read raw indep-test data path new names, include=FALSE}
paths_new_name_indep_test <-
  read_csv("inst/extdata/paths_new_name_indep_test.csv", show_col_types = FALSE)
```

```{r table-1, echo=FALSE}
paths_new_name |>
  mutate(dataset = "Modeling") |>
  rbind(mutate(paths_new_name, dataset = "Independent test")) |>
  select(dataset, everything()) |>
  mutate(dataset = ifelse(duplicated(dataset), "", dataset)) |>
  kable(
    caption = "Table 1. Raw data names and paths."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:3, extra_css = "vertical-align:top;")
```

```{r Read raw data, include=FALSE}
raw_data <-
  paths_new_name$path |>
  `names<-`(paths_new_name$name) |>
  lapply(read_xlsx, sheet = 1)
```

```{r Read raw indep-test data, include=FALSE}
raw_data_indep_test <-
  paths_new_name_indep_test$path |>
  `names<-`(paths_new_name_indep_test$name) |>
  lapply(read_xlsx, sheet = 1)

raw_data_indep_test$demographic_surfactant_growth <-
  raw_data_indep_test$demographic_surfactant_growth |>
  rename(BBWZ = BBW_Z, BHCZ = BHC_Z)
```

# Data preprocessing

## Data cleaning

```{r List raw data colnames, include=FALSE}
raw_data_old_colname <-
  raw_data |>
  imap(
    ~ data.frame(
        table = .y
        , old_colname = colnames(.x)
        , new_colname = NA
      )
  ) |>
  reduce(rbind)
```

```{r List raw indep-test data colnames, include=FALSE}
raw_data_old_colname_indep_test <-
  raw_data_indep_test |>
  imap(
    ~ data.frame(
        table = .y
        , old_colname = colnames(.x)
      )
  ) |>
  reduce(rbind)
```

```{r Write raw data old colnames, eval=FALSE, include=FALSE}
raw_data_old_colname |>
  write_csv("inst/extdata/raw_data_old_colname.csv")
```

```{r Read raw data new colnames, include=FALSE}
raw_data_new_colname <-
  read_csv("inst/extdata/raw_data_new_colname.csv", show_col_types = FALSE)
```

```{r Read raw indep-test data new colnames, include=FALSE}
raw_data_new_colname_indep_test <-
  raw_data_old_colname_indep_test |>
  left_join(raw_data_new_colname, by = join_by(table, old_colname))
```

```{r table-2, echo=FALSE}
raw_data_new_colname |>
  mutate(dataset = "Modeling") |>
  rbind(
    mutate(raw_data_new_colname_indep_test, dataset = "Independent test")
  ) |>
  select(dataset, everything()) |>
  mutate(table = ifelse(duplicated(paste0(dataset, table)), "", table)) |>
  mutate(dataset = ifelse(duplicated(dataset), "", dataset)) |>
  kable(
    caption = "Table 2. Raw data old and new column names."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:4, extra_css = "vertical-align:top;")
```

```{r Modify column names, include=FALSE}
raw_data1 <-
  raw_data |>
  imap(
    ~ .x |>
      `colnames<-`(
        data.frame(table = .y, old_colname = colnames(.x)) |>
          left_join(raw_data_new_colname, by = join_by(table, old_colname)) |>
          mutate(
            new_colname =
              ifelse(is.na(new_colname), old_colname, new_colname)
          ) |>
          pull(new_colname)
      )
  )
```

```{r Modify column names for indep-test, include=FALSE}
raw_data1_indep_test <-
  raw_data_indep_test |>
  imap(
    ~ .x |>
      `colnames<-`(
        data.frame(table = .y, old_colname = colnames(.x)) |>
          left_join(
            raw_data_new_colname_indep_test, by = join_by(table, old_colname)
          ) |>
          mutate(
            new_colname =
              ifelse(is.na(new_colname), old_colname, new_colname)
          ) |>
          pull(new_colname)
      )
  )
```

```{r Join raw data tables accordingly, include=FALSE}
raw_data2 <-
  raw_data1[!str_detect(names(raw_data1), "42d$|6w$")] |>
  reduce(\(x, y) left_join(x, y, by = join_by(id))) |>
  right_join(
    raw_data1[str_detect(names(raw_data1), "6w$")] |>
      reduce(\(x, y) left_join(x, y, by = join_by(id, t_wk)))
    , by = join_by(id, ga_wk)
  ) |>
  right_join(
    raw_data1[str_detect(names(raw_data1), "42d$")] |>
      reduce(\(x, y) left_join(x, y, by = join_by(id, t_day))) |>
      mutate(t_wk = ceiling(t_day / 7))
    , by = join_by(id, t_wk)
  ) |>
  select(-t_wk) |>
  select(id, t = t_day, everything())
```

```{r Join raw indep-test data tables accordingly, include=FALSE}
raw_data2_indep_test <-
  raw_data1_indep_test[
    !str_detect(names(raw_data1_indep_test), "42d$|6w$")
  ] |>
  reduce(\(x, y) left_join(x, y, by = join_by(id))) |>
  right_join(
    raw_data1_indep_test[
        str_detect(names(raw_data1_indep_test), "6w$")
      ] |>
      reduce(\(x, y) left_join(x, y, by = join_by(id, t_wk)))
    , by = join_by(id, ga_wk)
  ) |>
  right_join(
    raw_data1_indep_test[str_detect(names(raw_data1_indep_test), "42d$")] |>
      reduce(\(x, y) left_join(x, y, by = join_by(id, t_day))) |>
      mutate(t_wk = ceiling(t_day / 7))
    , by = join_by(id, t_wk)
  ) |>
  select(-t_wk) |>
  select(id, t = t_day, everything())
```

```{r List raw data variable-types, include=FALSE}
variable_old_type <-
  data.frame(
    variable = colnames(raw_data2)
    , old_type = sapply(raw_data2, class)
    , new_type = NA
  )
```

```{r Write old variable-types, eval=FALSE, include=FALSE}
variable_old_type |>
  write_csv("inst/extdata/variable_old_type.csv")
```

```{r Read new variable-types, include=FALSE}
variable_new_type <-
  read_csv("inst/extdata/variable_new_type.csv", show_col_types = FALSE)
```

```{r table-3, echo=FALSE}
variable_new_type |>
  kable(
    caption = "Table 3. Raw data old and new variable types."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:2, extra_css = "vertical-align:top;")
```

```{r Modify variable-types, include=FALSE}
raw_data3 <-
  raw_data2 |>
  imap(
    ~ data.frame(
        value =
          ifelse(
            filter(variable_new_type, variable == .y)$new_type != "numeric"
            ,as.character
            ,as.numeric
          )(.x)
      ) |>
      `colnames<-`(.y)
  ) |>
  reduce(cbind)

raw_data3 <-
  unique(variable_new_type$new_type) |>
  `names<-`(unique(variable_new_type$new_type)) |>
  imap(
    ~ raw_data3 |>
      select_at(filter(variable_new_type, new_type == .x)$variable)
  )
```

```{r Modify variable-types for indep-test, include=FALSE}
raw_data3_indep_test <-
  raw_data2_indep_test |>
  imap(
    ~ data.frame(
        value =
          ifelse(
            filter(variable_new_type, variable == .y)$new_type != "numeric"
            ,as.character
            ,as.numeric
          )(.x)
      ) |>
      `colnames<-`(.y)
  ) |>
  reduce(cbind)

raw_data3_indep_test <-
  unique(variable_new_type$new_type) |>
  `names<-`(unique(variable_new_type$new_type)) |>
  imap(
    ~ raw_data3_indep_test |>
      select_at(filter(variable_new_type, new_type == .x)$variable)
  )
```

```{r List raw data categories, include=FALSE}
raw_data_old_cat <-
  raw_data3$factor |>
  lapply(unique) |>
  lapply(sort) |>
  imap(~ data.frame(colname = .y, old_cat = .x, new_cat = NA)) |>
  reduce(rbind) |>
  mutate_at("colname", \(x) factor(x, unique(x)))
```

```{r Write raw data old categories, eval=FALSE, include=FALSE}
raw_data_old_cat |>
  write_csv("inst/extdata/raw_data_old_cat.csv")
```

```{r Read raw data new categories, include=FALSE}
raw_data_new_cat <-
  read_csv("inst/extdata/raw_data_new_cat.csv", show_col_types = FALSE) |>
  mutate_at("old_cat", as.character)
```

```{r table-4, echo=FALSE}
raw_data_new_cat |>
  kable(
    caption = "Table 4. Raw data old and new categories."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:2, extra_css = "vertical-align:top;")
```

```{r Modify categories, include=FALSE}
raw_data4 <- raw_data3

raw_data4$factor <-
  raw_data4$factor |>
  mutate(seq = seq(n())) |>
  gather(colname, old_cat, -seq) |>
  mutate_at("colname", \(x) factor(x, unique(x))) |>
  left_join(raw_data_new_cat, by = join_by(colname, old_cat)) |>
  select(-old_cat) |>
  spread(colname, new_cat) |>
  arrange(seq) |>
  select(-seq) |>
  mutate_all(as.factor)

raw_data4 <-
  raw_data4 |>
  reduce(cbind) |>
  select_at(colnames(raw_data2))
```

```{r Modify categories for indep-test, include=FALSE}
raw_data4_indep_test <- raw_data3_indep_test

raw_data4_indep_test$factor <-
  raw_data4_indep_test$factor |>
  mutate(seq = seq(n())) |>
  gather(colname, old_cat, -seq) |>
  mutate_at("colname", \(x) factor(x, unique(x))) |>
  left_join(raw_data_new_cat, by = join_by(colname, old_cat)) |>
  select(-old_cat) |>
  spread(colname, new_cat) |>
  arrange(seq) |>
  select(-seq) |>
  mutate_all(as.factor)

raw_data4_indep_test <-
  raw_data4_indep_test |>
  reduce(cbind) |>
  select_at(colnames(raw_data2_indep_test))
```

```{r table-5, echo=FALSE}
raw_data4 |>
  mutate(dataset = "Modeling") |>
  rbind(mutate(raw_data4_indep_test, dataset = "Independent test")) |>
  mutate(dataset = factor(dataset, unique(dataset))) |>
  select(dataset, id, survive, death_age) |>
  unique() |>
  mutate(ms_death_age = is.na(death_age)) |>
  group_by(dataset, survive, ms_death_age) |>
  summarize(n = n(), .groups = "drop") |>
  mutate(
    dataset = as.character(dataset)
    , dataset = ifelse(duplicated(dataset), "", dataset)
  ) |>
  kable(
    caption = "Table 5. Consistency check - survival and age of death."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:3, extra_css = "vertical-align:top;")
```

```{r table-6, echo=FALSE}
table6 <-
  raw_data4 |>
  select_at(colnames(raw_data1$outcomes)) |>
  mutate(dataset = "Modeling") |>
  rbind(
    raw_data4_indep_test |>
      select_at(colnames(raw_data1_indep_test$outcomes)) |>
      mutate(dataset = "Independent test")
  ) |>
  unique() |>
  select(-id, -survive)

table6 |>
  mutate_if(
    colnames(table6) != "dataset"
    , \(x) ifelse(is.na(x), "missing", "non-missing")
  ) |>
  rename_if(
    colnames(table6) != "dataset"
    , \(x) paste0("ms_", x)
  ) |>
  gather(variable, value, -dataset, -ms_death_age) |>
  mutate(dataset = factor(dataset, unique(dataset))) |>
  group_by(dataset, ms_death_age, variable, value) |>
  summarize(n = n(), .groups = "drop") |>
  spread(value, n, fill = 0) |>
  mutate(
    ms_death_age =
      ifelse(duplicated(paste0(dataset, ms_death_age)), "", ms_death_age)
  ) |>
  mutate(dataset = as.character(dataset)) |>
  mutate(dataset = ifelse(duplicated(dataset), "", dataset)) |>
  kable(
    caption = "Table 6. Consistency check - other outcomes and age of death."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:3, extra_css = "vertical-align:top;")
```

```{r table-7, echo=FALSE}
list(
    ceiled = mutate(raw_data4, t_death_age = ceiling(death_age))
    , rounded_plus1 = mutate(raw_data4, t_death_age = round(death_age) + 1)
    , floored_plus1 = mutate(raw_data4, t_death_age = floor(death_age) + 1)
  ) |>
  imap(
    ~ .x |>
      filter(survive == levels(survive)[1]) |>
      select_if(
        !colnames(.x)
        %in% c(
          colnames(select(raw_data1$demographic_surfactant_growth, -id))
          , colnames(select(raw_data1$outcomes, -id, -death_age))
          , colnames(select(raw_data1$morbidities_42d, -id))
        )
      ) |>
      mutate(
        t_wk = ceiling(t / 7)
        , t_wk_death_age = ceiling(t_death_age / 7)
      ) |>
      mutate(
        t_alive = ifelse(t <= t_death_age, "1-yes", "0-no")
        , t_wk_alive = ifelse(t_wk <= t_wk_death_age, "1-yes", "0-no")
      ) |>
      select(-death_age, -t_death_age, -t_wk_death_age) |>
      select(id, t, t_wk, t_alive, t_wk_alive, everything()) |>
      mutate_at(
        vars(-id, -t, -t_wk, -t_alive, -t_wk_alive)
        , \(x) ifelse(is.na(x), "missing", "non-missing")
      ) |>
      gather(variable, value, -id, -t, -t_wk, -t_alive, -t_wk_alive) |>
      mutate(
        t =
          ifelse(
            variable
            %in% unlist(
              lapply(raw_data1[str_detect(names(raw_data1), "6w$")], colnames)
            )
            , t_wk
            , t
          ) |>
          factor()
        , t_alive =
          ifelse(
            variable
            %in% unlist(
              lapply(raw_data1[str_detect(names(raw_data1), "6w$")], colnames)
            )
            , t_wk_alive
            , t_alive
          ) |>
          factor()
      ) |>
      select(-t_wk, -t_wk_alive) |>
      unique() |>
      mutate(
        variable = paste0("ms_", variable)
        ,variable = factor(variable, unique(variable))
      ) |>
      mutate(t_death_age_def = .y)
  ) |>
  reduce(rbind) |>
  mutate(t_death_age_def = factor(t_death_age_def, unique(t_death_age_def))) |>
  group_by(t_death_age_def, t_alive, variable, value) |>
  summarize(n = n(), .groups = "drop") |>
  spread(value, n, fill = 0) |>
  mutate(
    t_alive = as.character(t_alive)
    , t_alive =
      ifelse(
        duplicated(paste0(t_death_age_def, t_alive))
        , ""
        , t_alive
      )
    , t_death_age_def = as.character(t_death_age_def)
    , t_death_age_def = ifelse(duplicated(t_death_age_def), "", t_death_age_def)
  ) |>
  kable(
    caption =
      "Table 7. Consistency check - time-dependent variables and age of death."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:5, extra_css = "vertical-align:top;")
```

```{r Filter data up to death age if not survive, include=FALSE}
raw_data5 <-
  raw_data4 |>
  filter(is.na(death_age) | t <= (round(death_age) + 1))
```

```{r Filter data up to death age if not survive for indep-test, include=FALSE}
raw_data5_indep_test <-
  raw_data4_indep_test |>
  filter(is.na(death_age) | t <= (round(death_age) + 1))
```

```{r Remove raw variables, include=FALSE}
raw_data6 <-
  raw_data5 |>
  select_if(!str_detect(colnames(raw_data5), "bbw_g|raw"))
```

```{r Remove raw variables for indep-test, include=FALSE}
raw_data6_indep_test <-
  raw_data5_indep_test |>
  select_if(!str_detect(colnames(raw_data5_indep_test), "bbw_g|raw"))
```

```{r Finalize cleaned data, include=FALSE}
cleaned_data <- raw_data6
```

```{r Finalize cleaned data for indep-test, include=FALSE}
cleaned_data_indep_test <- raw_data6_indep_test
```

## Data partition

```{r Split data for each GA (week), include=FALSE}
# Determine whole set
whole_set <-
  cleaned_data |>
  select(id, ga_wk) |>
  unique()

# Split data by GA (week)
whole_id <-
  whole_set |>
  pull(ga_wk) |>
  unique() |>
  sort() |>
  lapply(\(x) filter(whole_set, ga_wk == x)$id)


# GA-wise partitioning
train_id <- list()
val_id <- list()
test_id <- list()

for(i in seq(length(whole_id))){
  set.seed(seed)
  
  test_id[[i]] <-
    whole_id[[i]] |>
    sample(size = round(0.2 * length(whole_id[[i]])), replace = FALSE)
  
  train_id[[i]] <- setdiff(whole_id[[i]], test_id[[i]])
  
  set.seed(seed)
  
  val_id[[i]] <-
    train_id[[i]] |>
    sample(size = round(0.2 * length(train_id[[i]])), replace = FALSE)
  
  train_id[[i]] <- setdiff(train_id[[i]], val_id[[i]])
}

whole_id <- reduce(whole_id, c)
train_id <- reduce(train_id, c)
val_id <- reduce(val_id, c)
test_id <- reduce(test_id, c)
```

```{r figure-1, echo=FALSE, fig.height=5, fig.width=7}
whole_set |>
  mutate(
    set =
      case_when(
        id %in% train_id ~ "Training"
        ,id %in% val_id ~ "Validation"
        ,id %in% test_id ~ "Test"
      )
  ) |>
  rbind(
    cleaned_data_indep_test |>
      select(id, ga_wk) |>
      unique() |>
      mutate(set = "Independent test")
  ) |>
  mutate(
    set =
      set |>
      factor(c("Training", "Validation", "Test", "Independent test"))
  ) |>
  ggplot(aes(ga_wk)) +
  geom_histogram(binwidth = 1, color = "white") +
  facet_grid(set ~ ., scales = "free_y") +
  scale_x_continuous(breaks = seq(22, 30)) +
  theme(strip.text.y = element_text(angle = 0))
```

Figure 1. GA (week) distribution for each partition and independent test. GA, gestational week.

```{r Finalize inference data, include=FALSE}
infer_data <-
  cleaned_data |>
  filter(id %in% train_id)
```

## Numerical data transformation

```{r Separate categorical and numerical variables, include=FALSE}
cat_data <-
  infer_data |>
  select_if(!sapply(infer_data, is.numeric))

num_data <-
  infer_data |>
  select_if(sapply(infer_data, is.numeric))
```

```{r Normal QQ plots of numeric variables, include=FALSE}
normal_qq <-
  num_data |>
  imap(~ qq_plot_outlier(.x, .y))

normal_qq <-
  normal_qq |>
  length() |>
  seq() |>
  split(LETTERS[1:4]) |>
  data.frame() |>
  pmap(
    \(A, B, C, D)
    ggarrange(
      normal_qq[[A]]
      , normal_qq[[B]]
      , normal_qq[[C]]
      , normal_qq[[D]]
      , ncol = 4
    )
  )

normal_qq <-
  ggarrange(
    normal_qq[[1]]
    , normal_qq[[2]]
    , normal_qq[[3]]
    , normal_qq[[4]]
    , normal_qq[[5]]
    , normal_qq[[6]]
    , normal_qq[[7]]
    , ncol = 1
    , nrow = 7
  )
```

```{r figure-2, echo=FALSE, fig.height=35, fig.width=20}
normal_qq
```

Figure 2. QQ plot of numerical variables. QQ, quantile-to-quantile.

```{r Determine normality by QQ plot, include=FALSE}
var_num_normal_qq <-
  c("t"
    , "maternal_age"
    , "gravida"
    , "ga_wk"
    , "as1"
    , "as5"
    , "resuscitation_at_birth"
    , "steroid_antenatal"
    , "surfactant"
    , "bbw_z"
    , "bhc_z"
    , "resp_supp_agg_cum_day_qw"
    , "fio2_cum_day_qw"
    , "fio2_cum_level_qw"
    , "resp_supp_agg_cum_day_pct"
    , "fio2_cum_day_pct"
    , "fio2_cum_level_pct"
    , "steroid_postnatal"
    , "inotropic"
    , "blood_volume"
    , "transfusion"
    , "blood_culture"
    , "plt"
    , "wbc"
    , "feeding"
    , "nec"
    , "aki"
  )
```

```{r Numerical variables with normal distribution by QQ plots, echo=FALSE}
var_num_normal_qq |>
  paste0(collapse=', ') |>
  cat()
```

```{r Normality test of numerical variables, include=FALSE}
normal_test <-
  num_data |>
  select_if(!names(num_data) %in% var_num_normal_qq) |>
  lapply(
    \(x)
    suppressWarnings(
        ks.test(
          x
          , y = "pnorm"
          , mean = mean(x, na.rm = TRUE)
          , sd = sd(x, na.rm = TRUE)
        )
      )
  ) |>
  lapply(tidy) |>
  imap(~ mutate(.x, variable = .y)) |>
  lapply(select, variable, everything()) |>
  reduce(rbind)
```

```{r table-8, echo=FALSE}
normal_test |>
  select(-method) |>
  mutate_at("statistic", round, 3) |>
  arrange(p.value) |>
  mutate(variable = paste0(variable, ifelse(p.value<=0.05,"*",""))) |>
  mutate(p.value = ifelse(p.value<0.001, "<0.001", round(p.value,3))) |>
  kable(
    caption = "Table 8. Normality test."
    , format = kable_format
  ) |>
  footnote("*, p-value <=0.05, Shapiro-Wilk normality test.") |>
  kable_classic() |>
  column_spec(1:4, extra_css = "vertical-align:top;")
```

```{r Determine num variables that are not normally distributed, include=FALSE}
var_num_non_normal <-
  normal_test |>
  filter(p.value <= 0.05) |>
  pull(variable)
```

```{r Numerical variables that are not normally distributed, echo=FALSE}
var_num_non_normal |>
  paste0(collapse=', ') |>
  cat()
```

```{r Non-normal mumerical variables with 0, include=FALSE}
var_num_non_normal_with_zero <-
  num_data |>
  select_at(var_num_non_normal) |>
  lapply(\(x) x[!duplicated(x)]) |>
  lapply(\(x) x[!is.na(x)]) |>
  sapply(\(x) any(x==0)) |>
  which() |>
  names()
```

```{r Non-normal mumerical variables with <0, include=FALSE}
var_num_non_normal_with_neg <-
  num_data |>
  select_at(var_num_non_normal) |>
  lapply(\(x) x[!duplicated(x)]) |>
  lapply(\(x) x[!is.na(x)]) |>
  sapply(\(x) any(x<0)) |>
  which() |>
  names()
```

```{r Non-normal mumerical variables infinited exp, include=FALSE}
var_num_non_normal_with_inf_exp <-
  num_data |>
  select_at(var_num_non_normal) |>
  lapply(\(x) x[!duplicated(x)]) |>
  lapply(\(x) x[!is.na(x)]) |>
  sapply(\(x) any(is.infinite(exp(x)))) |>
  which() |>
  names()
```

```{r Determine choices for a transformation technique, include=FALSE}
trans_choice <-
  data.frame(variable = var_num_non_normal) |>
  mutate(
    log =
      ifelse(
        variable%in%var_num_non_normal_with_zero
        | variable%in%var_num_non_normal_with_neg
        , 0
        , 1
      )
    ,sqrt =
      ifelse(
        variable%in%var_num_non_normal_with_neg
        , 0
        , 1
      )
    ,inv =
      ifelse(
        variable%in%var_num_non_normal_with_zero
        | variable%in%var_num_non_normal_with_neg
        , 0
        , 1
      )
    ,log2 =
      ifelse(
        variable%in%var_num_non_normal_with_zero
        | variable%in%var_num_non_normal_with_neg
        , 0
        , 1
      )
    ,exp =
      ifelse(
        variable%in%var_num_non_normal_with_inf_exp
        , 0
        , 1
      )
    ,asinh = 1
    ,bct =
      ifelse(
        variable%in%var_num_non_normal_with_zero
        | variable%in%var_num_non_normal_with_neg
        , 0
        , 1
      )
  )
```

```{r Choices for a transformation technique, echo=FALSE}
trans_choice |>
  colnames() |>
  setdiff("variable") |>
  paste0(collapse=', ') |>
  cat()
```

```{r Simple transformations, include=FALSE}
simple_trans <-
  trans_choice |>
  gather(func, do, -variable) |>
  filter(do == 1) |>
  select(-do) |>
  filter(!func %in% c("bct"))

simple_trans <-
  simple_trans |>
  pull(func) |>
  unique() |>
  lapply(
    \(x)
    simple_trans |>
      filter(func == x) |>
      pull(variable) |>
      lapply(
        \(y)
        list(
            log = log
            , sqrt = sqrt
            , inv = \(x) 1/x
            , log2 = log2
            , exp = exp
            , asinh = asinh
          )[[x]](num_data[[y]]) |>
          as.data.frame() |>
          `colnames<-`(y)
      ) |>
       `names<-`(
         simple_trans |>
          filter(func == x) |>
          pull(variable)
       )
  ) |>
  `names<-`(unique(simple_trans$func))
```

```{r Box-Cox transformation (BCT), include=FALSE}
bc_trans <-
  trans_choice |>
  gather(func, do, -variable) |>
  filter(do == 1) |>
  select(-do) |>
  filter(func %in% c("bct")) |>
  pull(variable)

bc_trans <-
  bc_trans |>
  `names<-`(as.character(bc_trans)) |>
  as.list()

for(i in names(bc_trans)){
  bc_trans[[i]]=
    boxcox(
      lm(num_data[[i]] ~ 1)
      , lambda = seq(-2, 2, by = 0.1)
      , plot = F
    ) |>
    c(list(value = num_data[[i]]))
}

rm(i)

bc_trans=
  bc_trans |>
  lapply(
    \(x)
    list(
      rep(NA, length(x$value))
       ,(x$value^(x$x[which.max(x$y)]) - 1) / x$x[which.max(x$y)]
    )[[ifelse(abs(x$x[which.max(x$y)]) < 1e-10, 1, 2)
    ]]
  ) |>
  imap(
    ~ data.frame(trans=.x) |>
      `colnames<-`(.y)
  )

bc_trans <-
  bc_trans[sapply(bc_trans, \(x) !all(is.na(x[[1]])))]
```

```{r Normality test of transformed numerical variables, include=FALSE}
normal_test_after_trans <-
  simple_trans |>
  c(list(bct = bc_trans)) |>
  imap(
    ~ .x |>
      lapply(
        \(x)
        suppressWarnings(
            ks.test(
              x[[1]]
              , y = "pnorm"
              , mean = mean(x[[1]], na.rm = TRUE)
              , sd = sd(x[[1]], na.rm = TRUE)
            )
          )
      ) |>
      lapply(tidy) |>
      imap(~ mutate(.x, variable = .y)) |>
      reduce(rbind) |>
      mutate(func = .y)
  ) |>
  reduce(rbind) |>
  select(func, variable, p.value) |>
  mutate_at("func", \(x) factor(x, unique(x))) |>
  group_by(variable) |>
  mutate(best_trans = func[which.max(p.value)]) |>
  ungroup() |>
  spread(func, p.value) |>
  right_join(
    data.frame(variable = var_num_non_normal)
    , by = join_by(variable)
  ) |>
  mutate(
    p.value=
      ifelse(
        best_trans == "log"
        , log
        , ifelse(
          best_trans == "sqrt"
          , sqrt
          , ifelse(
            best_trans == "inv"
            , inv
            , ifelse(
              best_trans == "log2"
              , log2
              , ifelse(
                best_trans == "exp"
                , exp
                , ifelse(
                  best_trans == "asinh"
                  , asinh
                  , bct
                )
              )
            )
          )
        )
      )
  ) |>
  select(variable, best_trans, p.value, everything())
```

```{r table-9, echo=FALSE}
normal_test_after_trans |>
  mutate(variable = paste0(variable, ifelse(p.value <= 0.05, "*", ""))) |>
  arrange(p.value) |>
  mutate_if(is.numeric, \(x) ifelse(x < 0.001, "<0.001", round(x, 3))) |>
  mutate_if(is.numeric, as.character) |>
  kable(
    caption = "Table 9. Normality test after transformation."
    , format = kable_format
  ) |>
  footnote("*, p-value <=0.05, Shapiro-Wilk normality test.") |>
  kable_classic() |>
  column_spec(1:10, extra_css = "vertical-align:top;")
```

```{r Determine num vars that are not normal after transformed, include=FALSE}
var_num_non_normal_after_trans <-
  normal_test_after_trans |>
  filter(p.value <= 0.05) |>
  pull(variable)
```

```{r Numerical variables that are not normal after transformation, echo=FALSE}
var_num_non_normal_after_trans |>
  paste0(collapse = ", ") |>
  cat()
```

```{r Finalize transformed data, include=FALSE}
transformed_data <-
  num_data |>
  cbind(cat_data) |>
  select_at(colnames(infer_data))
```

# Outlier analysis

```{r Determine exception for outlier analysis, include=FALSE}
trans_ps_num_exception <-
  c("t"
    ,"maternal_age"
    , "gravida"
    , "ga_wk"
    , "as1"
    , "as5"
    , "resuscitation_at_birth"
    , "steroid_antenatal"
    , "surfactant"
    , "bbw_z"
    , "bhc_z"
    , "death_age"
    , "resp_supp_agg_cum_day_qw"
    , "fio2_cum_day_qw"
    , "fio2_cum_level_qw"
    , "resp_supp_agg_cum_day_pct"
    , "fio2_cum_day_pct"
    , "fio2_cum_level_pct"
    , "steroid_postnatal"
    , "fio2_raw"
    , "inotropic"
    , "blood_volume"
    , "transfusion"
    , "blood_culture"
    , "plt"
    , "wbc"
    , "feeding"
    , "nec"
    , "aki"
  )
```

```{r Numerical var after transformation, include=FALSE}
trans_ps_num_data <-
  transformed_data |>
  select_if(sapply(transformed_data, is.numeric))

trans_ps_num_data <-
  trans_ps_num_data |>
  select_at(setdiff(colnames(trans_ps_num_data), trans_ps_num_exception))
```

```{r Relevant numerical var after transformation, echo=FALSE}
trans_ps_num_data |>
  colnames() |>
  paste0(collapse = ", ") |>
  cat()
```

# Correlation matrix

```{r Identify and create missingness variables, include=FALSE}
ms_added_data0 <-
  transformed_data |>
  select(-id) |>
  sapply(\(x) any(is.na(x))) |>
  which() |>
  names() |>
  lapply(
    \(x)
    transformed_data |>
      select_at(x) |>
      `colnames<-`("value") |>
      mutate(value = ifelse(is.na(value), "yes", "no")) |>
      `colnames<-`(paste0("ms_", x))
  ) |>
  reduce(cbind) |>
  cbind(mutate(transformed_data, t_wk = ceiling(t / 7))) |>
  select(id, t_wk, t, everything())

ms_added_data <-
  ms_added_data0 |>
  select(-id)
```

```{r Check categorical variables with a category of 1 value, include=FALSE}
var_cat_val1 <-
  ms_added_data |>
  select_if(!sapply(ms_added_data, is.numeric)) |>
  mutate_all(as.character) |>
  gather(variable, value) |>
  group_by_all() |>
  summarize(n = n(), .groups = "drop") |>
  filter(n <= 1) |>
  pull(variable) |>
  unique()
```

```{r Categorical variables with a category of 1 value, echo=FALSE}
var_cat_val1 %>%
  paste0(collapse=', ') %>%
  cat()
```

```{r Pair-wise distribution of categorical variables, include=FALSE}
pairwise_cat_sum <-
  ms_added_data |>
  select_if(
    !sapply(ms_added_data, is.numeric)
    & !colnames(ms_added_data) %in% var_cat_val1
  ) |>
  colnames() |>
  combn(2) |>
  as.data.frame() |>
  lapply(
    \(x)
    ms_added_data |>
      select_at(x) |>
      group_by_all() |>
      summarize(n = n(), .groups = "drop") |>
      select_at(c(x, "n")) |>
      `colnames<-`(c("V1_value", "V2_value", "n")) |>
      mutate(V1 = x[1], V2 = x[2])
  ) |>
  lapply(
    \(x)
    expand.grid(
      V1_value = unique(x$V1_value)
      , V2_value = unique(x$V2_value)
      ) |>
      mutate_all(as.character) |>
      left_join(x, by = join_by(V1_value, V2_value)) |>
      mutate_at("n", \(x) ifelse(is.na(x), 0, x)) |>
      fill(V1, V2)
  ) |>
  reduce(rbind) |>
  select(V1, V1_value, V2, V2_value, everything())
```

```{r Pair-wise perfect separation, include=FALSE}
pairwise_cat_sum_ps <-
  pairwise_cat_sum |>
  group_by(V1, V2) |>
  summarize(ps = any(n == 0), .groups = "drop")
```

```{r table-10, echo=FALSE}
pairwise_cat_sum |>
  inner_join(
    pairwise_cat_sum_ps |>
      filter(ps) |>
      select(-ps)
    , by = join_by(V1, V2)
  ) |>
  filter(n == 0) |>
  kable(
    caption =
      "Table 10. Categorical variables with pair-wise perfect separation."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:5, extra_css = "vertical-align:top;")
```

```{r Variable pairs for correlation tests, include=FALSE}
correlation_pair <-
  ms_added_data |>
  colnames() |>
  setdiff(var_cat_val1) |>
  combn(2) |>
  as.data.frame() |>
  t() |>
  as.data.frame() |>
  `rownames<-`(NULL) |>
  filter(str_remove_all(V1, "^ms_") != str_remove_all(V2, "^ms_")) |>
  filter(!(str_detect(V1, "resp_supp") & str_detect(V2, "resp_supp"))) |>
  filter(
    !(str_detect(V1, "fio2_cum_level") & str_detect(V2, "fio2_cum_level"))
  ) |>
  filter(
    !(str_detect(V1, "fio2_cum_day") & str_detect(V2, "fio2_cum_day"))
  ) |>
  filter(
    !((str_detect(V1, "fio2_raw") & str_detect(V2, "fio2_cum_level"))
      | (str_detect(V1, "fio2_cum_level") & str_detect(V2, "fio2_raw"))
    )
  ) |>
  filter(!(str_detect(V1, "bbw") & str_detect(V2, "bbw"))) |>
  filter(!(str_detect(V1, "bhc") & str_detect(V2, "bhc"))) |>
  filter(
    !((str_detect(V1, "qw") & str_detect(V2, "pct"))
      | (str_detect(V1, "pct") & str_detect(V2, "qw"))
    )
  ) |>
  filter(!(str_detect(V1, "^ms_plt") | str_detect(V2, "^ms_plt"))) |>
  filter(!(str_detect(V1, "^ms_wbc") | str_detect(V2, "^ms_wbc"))) |>
  filter(
    !(str_detect(V1, "^ms_death_age") | str_detect(V2, "^ms_death_age"))
  ) |>
  filter(
    !(str_detect(V1, "^ms_rop_severe") | str_detect(V2, "^ms_rop_severe"))
  ) |>
  filter(
    !(str_detect(V1, "^ms_bpd_grade") | str_detect(V2, "^ms_bpd_grade"))
  ) |>
  filter(
    !(str_detect(V1, "^ms_eugr_hc") | str_detect(V2, "^ms_eugr_hc"))
  ) |>
  filter(
    !(str_detect(V1, "^ms_eugr_bw") | str_detect(V2, "^ms_eugr_bw"))
  ) |>
  filter(
    !(str_detect(V1, "^ms_hearing") | str_detect(V2, "^ms_hearing"))
  ) |>
  filter(!(V1 %in% c("t", "t_wk") & V2 %in% c("t", "t_wk"))) |>
  mutate(V1_unit = V1, V2_unit = V2) |>
  mutate_at(
    vars(V1_unit, V2_unit)
    , \(x)
      case_when(
        str_remove_all(x, "^ms_")
        %in% unlist(
          lapply(raw_data1[str_detect(names(raw_data1), "42d$")], colnames)
        )
        | str_remove_all(x, "^ms_") == "t"
        ~ "id|t_wk|t"
        , str_remove_all(x, "^ms_")
          %in% unlist(
            lapply(raw_data1[str_detect(names(raw_data1), "6w$")], colnames)
          )
          | str_remove_all(x, "^ms_") == "t_wk"
          ~ "id|t_wk"
        , str_remove_all(x, "^ms_")
          %in% unlist(
            lapply(
              raw_data1[!str_detect(names(raw_data1), "42d$|6w$")]
              , colnames
            )
          )
          ~ "id"
      )
  ) |>
  mutate(
    unit =
      mapply(
        \(x, y)
          c(str_split(x, "\\|")[[1]], str_split(y, "\\|")[[1]]) |>
            unique() |>
            paste0(collapse = "|")
        , V1_unit
        , V2_unit
      )
  ) |>
  filter(
    !(V1 == "t" | V2 == "t")
    | (V1 == "t" & V2_unit != "id")
    | (V2 == "t" & V1_unit != "id")
  ) |>
  filter(
    !(V1 == "t_wk" | V2 == "t_wk")
    | (V1 == "t_wk" & V2_unit != "id")
    | (V2 == "t_wk" & V1_unit != "id")
  ) |>
  select(-V1_unit, -V2_unit)
```

```{r Conduct correlation tests per pair with PS, eval=FALSE, include=FALSE}
correlation_matrix_ps0 <-
  correlation_pair |>
  filter(
    paste0(V1, V2)
    %in% c(
      pairwise_cat_sum_ps |>
        filter(ps) |>
        unite(V1V2, V1, V2, sep = "") |>
        pull(V1V2)
    )
  )

correlation_matrix_ps <-
  correlation_matrix_ps0 |>
  pmap(
    \(V1, V2, unit)
    list(
      data =
        ms_added_data0[, c(V1, V2, str_split(unit, "\\|")[[1]])] |>
        unique()
      , V1 = V1
      , V2 = V2
    )
  )

if (!dir.exists("data/correlation_matrix_ps")){
  dir.create("data/correlation_matrix_ps")
}

start <- TRUE
cl <- min(6, detectCores())
source("R/parallel_computing-codes.R")

correlation_matrix_ps[
  correlation_matrix_ps |>
    sapply(
      \(x)
      !paste0(x$V1, "_", x$V2, ".rds")
      %in% list.files("data/correlation_matrix_ps")
    )
  ] |>
  pblapply(
    FUN =
      \(x, auto_stat_tests = auto_stat_tests, ms_added_data = ms_added_data)
      suppressWarnings(auto_stat_tests(
          x$data[[x$V1]]
          , x$data[[x$V2]]
          , perfect_separation = TRUE
        )) |>
        list() |>
        `names<-`("obj") |>
        c(list(V1 = x$V1, V2 = x$V2)) |>
        saveRDS(paste0("data/correlation_matrix_ps/",x$V1,"_",x$V2,".rds"))
    , auto_stat_tests = auto_stat_tests
    , ms_added_data = ms_added_data
    ,  cl = cl
  )

start <- FALSE
source("R/parallel_computing-codes.R")

correlation_matrix_ps <-
  correlation_matrix_ps0 |>
  pmap(\(V1, V2, unit) list(V1 = V1, V2 = V2)) |>
  pblapply(
    \(x)
    suppressWarnings(
      tidy(
        readRDS(
          paste0("data/correlation_matrix_ps/",x$V1,"_",x$V2,".rds")
        )$obj
      )
    ) |>
    filter(!str_detect(term, "\\(Intercept\\)")) |>
    filter(!(conf.low <= 0 & conf.high >= 0)) |>
    summarize(n_sig = n()) |>
    mutate(p.value = ifelse(n_sig > 0, 0, 1)) |>
    filter(!is.na(p.value)) |>
    select(p.value) |>
    mutate(V1 = x$V1, V2 = x$V2)
  ) |>
  reduce(rbind)

saveRDS(correlation_matrix_ps, "data/correlation_matrix_ps.rds")
```

```{r Load pre-conducted correlation tests per pair with PS, include=FALSE}
correlation_matrix_ps <- readRDS("data/correlation_matrix_ps.rds")
```

```{r Conduct correlation tests for each pair without PS, include=FALSE}
correlation_matrix_non_ps <-
  correlation_pair |>
  filter(
    !paste0(V1, V2)
    %in% c(
      pairwise_cat_sum_ps |>
        filter(ps) |>
        unite(V1V2, V1, V2, sep = "") |>
        pull(V1V2)
    )
  ) |>
  pmap(
    \(V1, V2, unit)
    list(
      data =
        ms_added_data0[, c(V1, V2, str_split(unit, "\\|")[[1]])]
      , V1 = V1
      , V2 = V2
    )
  ) |>
  lapply(
    \(x)
    list(
      obj =
        try(
          suppressWarnings(auto_stat_tests(
              x$data[[x$V1]]
              ,x$data[[x$V2]]
              ,normal_V1 = !x$V1 %in% var_num_non_normal_after_trans
              ,normal_V2 = !x$V2 %in% var_num_non_normal_after_trans
            ))
        )
      , V1 = x$V1
      ,V2 = x$V2
    )
  )


correlation_matrix_non_ps_succeed <-
  correlation_matrix_non_ps[
    sapply(
      correlation_matrix_non_ps
      , \(x) paste0(class(x$obj), collapse = " ") != "try-error"
    )
  ] |>
  lapply(
    \(x)
    x$obj |>
      tidy() |>
      filter(!is.na(p.value)) |>
      select(p.value) |>
      mutate(
        V1 = x$V1
        ,V2 = x$V2
      )
  ) |>
  reduce(rbind)

correlation_matrix_non_ps_failed <-
  correlation_pair |>
  filter(
    !paste0(V1, V2)
    %in% c(
      pairwise_cat_sum_ps |>
        filter(ps) |>
        unite(V1V2, V1, V2, sep = "") |>
        pull(V1V2)
    )
  ) |>
  slice(
    which(
      sapply(
        correlation_matrix_non_ps
        , \(x) paste0(class(x$obj), collapse = " ") == "try-error"
      )
    )
  ) |>
  mutate(p.value = as.numeric(NA)) |>
  select(p.value, V1, V2)

correlation_matrix_non_ps <-
  correlation_matrix_non_ps_succeed |>
  rbind(correlation_matrix_non_ps_failed)
```

```{r Conduct correlation tests for each pair, include=FALSE}
correlation_matrix <-
  correlation_matrix_ps |>
  rbind(correlation_matrix_non_ps) |>
  mutate(p.value = p.adjust(p.value, "BH")) |>
  rename(cor.p.value = p.value) |>
  right_join(
    ms_added_data |>
      colnames() |>
      combn(2) |>
      as.data.frame() |>
      t() |>
      as.data.frame() |>
      `rownames<-`(NULL)
    , by = join_by(V1, V2)
  ) |>
  mutate(
    V1 = factor(V1, colnames(ms_added_data))
    ,V2 = factor(V2, levels(V1))
  ) |>
  arrange(V1, V2)
```

```{r Plot correlation matrix, include=FALSE}
same_v_corr_df =
  data.frame(
    cor.p.value = 0
    , V1 = colnames(ms_added_data)
    , V2 = colnames(ms_added_data)
    , sig = "2 - Significant"
  )

correlation_matrix_plot <-
  correlation_matrix |>
  mutate(
    V1 = factor(V1, rev(levels(V1)))
    , sig =
      ifelse(
        is.na(cor.p.value)
        ,ifelse(
          str_remove_all(V1, "^ms_") == str_remove_all(V2, "^ms_")
          ,"3 - Not tested†"
          ,ifelse(
            V1 %in% var_cat_val1
            | V2 %in% var_cat_val1
            ,"4 - Not tested‡"
            ,"5 - Not tested§"
          )
        )
        ,ifelse(cor.p.value <= 0.05, "2 - Significant", "1 - Not significant")
      ) |>
      factor()
    , sig = factor(sig)
    , cor.p.value = ifelse(cor.p.value<0.001, "<0.001", round(cor.p.value,3))
  ) |>
  rbind(same_v_corr_df) |>
  ggplot(aes(V1, V2, fill = sig)) +
  geom_tile(color = "white", na.rm = TRUE) +
  # geom_text(aes(label = cor.p.value), size = 2.5, na.rm = TRUE) +
  geom_tile(data = same_v_corr_df, fill = "white") +
  geom_text(
    data =
      same_v_corr_df |>
      mutate(label = V1)
    , aes(label = label)
    , size = 1.5
    , angle = 45
    , hjust = 1
    , nudge_x = 0.15
    , nudge_y = 0.15
  ) +
  coord_flip() +
  scale_x_discrete(expand = expansion(add = 10)) +
  scale_y_discrete(expand = expansion(add = 5)) +
  xlab("") +
  ylab("") +
  scale_fill_discrete("Significance*") +
  theme(
    panel.grid = element_blank()
    , panel.border = element_blank()
    , axis.ticks = element_blank()
    , axis.text = element_blank()
  )
```

```{r figure-3, echo=FALSE, fig.height=5, fig.width=7}
correlation_matrix_plot
```

Figure 3. Correlation matrix. *, based on p-value (frequentist) or 95% CI (Bayesian); †, pair of variable and its missingness; ‡, at least 1 variable was a categorical variable with a category of 1 value; §, insufficient sample size.

```{r Write pairs with significant correlations, eval=FALSE, include=FALSE}
correlation_matrix |>
  filter(cor.p.value <= 0.05) |>
  select(V1, V2) |>
  write_csv("inst/extdata/correlation.csv")
```

# Missing value imputation

```{r Imputation predictor matrix, include=FALSE}
imp_predictor_matrix <-
  correlation_matrix |>
  filter(!is.na(cor.p.value)) |>
  mutate(imp_predictor = ifelse(cor.p.value <= 0.05, 1, 0)) |>
  filter(imp_predictor == 1) |>
  select(V1, V2, imp_predictor) |>
  mutate_at(c("V1", "V2"), str_remove_all, "^ms_") |>
  mutate_at(c("V1", "V2"), as.character) |>
  mutate_at(c("V1", "V2"), \(x) ifelse(x == "t_wk", "t", x)) |>
  unique()

imp_predictor_matrix <-
  imp_predictor_matrix |>
  rbind(`colnames<-`(imp_predictor_matrix, c("V2", "V1", "imp_predictor"))) |>
  unique() |>
  right_join(
    expand.grid(
      V1 = colnames(transformed_data)
      , V2 = colnames(transformed_data)
      , stringsAsFactors = FALSE
    )
    , by = join_by(V1, V2)
  ) |>
  spread(V2, imp_predictor, fill = 0) |>
  column_to_rownames(var = "V1") |>
  as.matrix()

imp_predictor_matrix <-
  imp_predictor_matrix[
    colnames(transformed_data)
    , colnames(transformed_data)
  ]
```

```{r Performing multiple imputation, eval=FALSE, include=FALSE}
imp_results <-
  suppressWarnings(
    mice(
      data = transformed_data
      , method = 'pmm'
      , m = 10
      , seed = seed
      , predictorMatrix = imp_predictor_matrix
      , print = FALSE
    )
  )

saveRDS(imp_results, "data/imp_results.rds")
```

```{r Load pre-performed multiple imputation, include=FALSE}
imp_results <- readRDS("data/imp_results.rds")
```

```{r Obtain imputed data, eval=FALSE, include=FALSE}
imputed_data <-
  mice.mids(imp_results, newdata = cleaned_data) |>
  complete(1)

imputed_data <-
  imputed_data |>
  imap(
    ~ list(
        select_at(cleaned_data, .y)
        , select_at(imputed_data, .y)
      )[[ifelse(.y %in% colnames(raw_data1$outcomes), 1, 2)]]
  ) |>
  reduce(cbind)

saveRDS(imputed_data, "data/imputed_data.rds")
```

```{r Load pre-obtained imputed data, include=FALSE}
imputed_data <- readRDS("data/imputed_data.rds")
```

```{r Obtain imputed data for indep-test, eval=FALSE, include=FALSE}
imputed_data_indep_test <-
  mice.mids(imp_results, newdata = cleaned_data_indep_test) |>
  complete(1)

imputed_data_indep_test <-
  imputed_data_indep_test |>
  imap(
    ~ list(
        select_at(cleaned_data_indep_test, .y)
        , select_at(imputed_data_indep_test, .y)
      )[[ifelse(.y %in% colnames(raw_data1_indep_test$outcomes), 1, 2)]]
  ) |>
  reduce(cbind)

saveRDS(imputed_data_indep_test, "data/imputed_data_indep_test.rds")
```

```{r Load pre-obtained imputed data for indep-test, include=FALSE}
imputed_data_indep_test <- readRDS("data/imputed_data_indep_test.rds")
```

```{r Finalize readily-analyzed data, include=FALSE}
processed_data <- imputed_data
```

```{r Finalize readily-analyzed data for indep-test, include=FALSE}
processed_data_indep_test <- imputed_data_indep_test
```

# Descriptive statistics

```{r Determine variables, include=FALSE}
var <- list()

var$s <- c("id")

var$t <- c("t")

var$dependent <-
  raw_data1[str_detect(names(raw_data1), "outcome")] |>
  lapply(colnames) |>
  reduce(c) |>
  unique() |>
  setdiff(c(var$s, var$t, "t_day", "t_wk", "ga_wk", "death_age"))

var$independent <-
  raw_data1[str_detect(names(raw_data1), "breath")] |>
  lapply(colnames) |>
  reduce(c) |>
  unique() |>
  setdiff(c(var$s, var$t, "t_day", "t_wk", "ga_wk", "death_age"))

var$independent <-
  var$independent[!str_detect(var$independent, "raw")]

var$covariates=
  processed_data %>%
  colnames() %>%
  setdiff(unlist(var))
```

```{r Read descriptive variable-types, include=FALSE}
variable_desc_type <-
  read_csv("inst/extdata/variable_desc_type.csv", show_col_types = FALSE)
```

```{r Modify descriptive variable-types, include=FALSE}
desc_data <-
  processed_data |>
  filter(id %in% train_id) |>
  imap(
    ~ data.frame(
        value =
          ifelse(
            filter(variable_desc_type, variable == .y)$desc_type != "numeric"
            , ifelse(.y == "id", as.character, as.factor)
            , as.numeric
          )(.x)
      ) |>
      `colnames<-`(.y)
  ) |>
  reduce(cbind)
```

```{r Simplify correlation pair to identify unit of obs, include=FALSE}
correlation_pair_simplified <-
  correlation_pair |>
  mutate_at(c("V1", "V2"), \(x) ifelse(x == "t_wk", "t", x)) |>
  mutate_at("unit", str_replace_all, "t_wk\\|t", "t") |>
  mutate_at("unit", str_replace_all, "t_wk", "t") |>
  unique()
```

```{r Identify unit of obs for each outcome-variable, include=FALSE}
outcome_variable_unit <-
  var$dependent |>
  lapply(
    \(x)
    data.frame(outcome = x, variable = c(var$independent, var$covariates))
  ) |>
  reduce(rbind) |>
  mutate(
    unit =
      mapply(
        FUN =
          \(x, y)
          correlation_pair_simplified |>
            filter((V1 == x & V2 == y) | (V2 == y & V1 == x)) |>
            pull(unit) |>
            paste0(collapse = "//")
          , outcome
          , variable
      )
  ) |>
  mutate(unit = ifelse(unit == "", "id", unit))
```

```{r Outcome-wise average and SD, include=FALSE}
avg_sd_data <-
  var$dependent |>
  `names<-`(var$dependent) |>
  lapply(
    \(x)
    desc_data |>
      select_at(c(var$independent, var$covariates)) |>
      select_if(is.numeric) |>
      mutate(seq = seq(n())) |>
      gather(variable, value, -seq) |>
      left_join(
        desc_data |>
          select_at(c(var$s, var$t, x)) |>
          mutate(seq = seq(n()))
        , by = join_by(seq)
      ) |>
      select(-seq) |>
      mutate(outcome = x) |>
      left_join(outcome_variable_unit, by = join_by(outcome, variable)) |>
      mutate(unit_id = ifelse(unit == "id", id, paste0(id, "_" ,t))) |>
      rename_at(x, \(x) "category") |>
      select(unit_id, outcome, category, variable, unit, value) |>
      unique()|>
      group_by(variable) |>
      mutate(N = n()) |>
      group_by(outcome, category, variable, unit, N) |>
      summarize(
        avg = mean(value)
        , std = sd(value)
        , .groups = 'drop'
      )
  ) |>
  reduce(rbind)
```

```{r Outcome-wise proportion, include=FALSE}
prop_n_data <-
  var$dependent |>
  `names<-`(var$dependent) |>
  lapply(
    \(x)
    desc_data |>
      select_at(c(var$independent, var$covariates)) |>
      select_if(\(x) !is.numeric(x)) |>
      mutate_all(as.character) |>
      mutate(seq = seq(n())) |>
      gather(variable, value, -seq) |>
      left_join(
        desc_data |>
          select_at(c(var$s, var$t, x)) |>
          mutate(seq=seq(n()))
        ,by = join_by(seq)
      ) |>
      select(-seq) |>
      mutate(outcome = x) |>
      left_join(outcome_variable_unit, by = join_by(outcome, variable)) |>
      mutate(unit_id = ifelse(unit == "id", id, paste0(id, "_" ,t))) |>
      rename_at(x, \(x) "category") |>
      select(unit_id, outcome, category, variable, unit, value) |>
      unique() |>
      group_by(variable) |>
      mutate(N = n()) |>
      group_by(outcome, category, variable, unit, N, value) |>
      summarize(n = n(), .groups='drop') |>
      group_by(outcome, category, variable, unit, N) |>
      mutate(total = sum(n)) |>
      ungroup() |>
      mutate(p = round(n / total * 100, 0))
  ) |>
  reduce(rbind)
```

```{r Summarize sample characteristics, include=FALSE}
desc_stats <-
  list(
    avg_sd_data |>
      mutate_at(c("avg", "std"), round, 2) |>
      mutate(std = paste0("(", as.character(std), ")")) |>
      unite(avg_std, avg, std, sep=" ") |>
      mutate(value = NA) |>
      rename(summary = avg_std)
    ,prop_n_data |>
      select(-total) |>
      mutate(n = paste0("(", as.character(n), ")")) |>
      unite(p_n, p, n, sep = " ") |>
      rename(summary = p_n)
  ) |>
  lapply(mutate_at, "category", as.character) |>
  lapply(mutate_at, "category", \(x) ifelse(is.na(x), "(missing)", x)) |>
  lapply(unite, dep_var, outcome, category, sep = " ") |>
  lapply(mutate_at, "dep_var", \(x) factor(x, unique(x))) |>
  lapply(spread, dep_var, summary, fill = "0 (0)") |>
  reduce(rbind) |>
  mutate_at("value", as.character) |>
  mutate_at(
    "value"
    ,\(x) ifelse(is.na(x), "average (SD)", paste0(x," % (n)"))
  ) |>
  rbind(
    prop_n_data |>
      mutate_at("category", as.character) |>
      mutate_at("category", \(x) ifelse(is.na(x), "(missing)", x)) |>
      unite(variable, outcome, category, sep = " ") |>
      select(variable, unit, N,  total) |>
      unique() |>
      mutate_at("variable", \(x) factor(x, unique(x))) |>
      mutate(total = paste0(total, " (", round(total/N*100, 2),")")) |>
      spread(variable, total, fill = 0) |>
      mutate(variable = "total (prevalence)", value = "n (%)") |>
      select(unit, N, variable, value, everything())
  ) |>
  arrange(
    desc(unit)
    , N
    , factor(variable, c("total (prevalence)", var$independent, var$covariates))
  ) |>
  select(unit, N, everything()) |>
  group_by(unit, N) |>
  mutate(variable = ifelse(duplicated(variable), "", variable)) |>
  ungroup() |>
  mutate(
    unit = ifelse(duplicated(unit), "", unit)
    , N = ifelse(duplicated(N), "", N)
  ) |>
  mutate_all(str_replace_all, "NA \\(NA\\)", "N/A")
```

```{r table-11, echo=FALSE}
desc_stats |>
  select_if(
    colnames(desc_stats) %in% c("unit", "N", "variable", "value")
    | str_detect(colnames(desc_stats), "^survive")
  ) |>
  left_join(
    rbind(
        correlation_matrix |>
          filter(str_detect(V2, "^survive")) |>
          select(variable = V1, cor.p.value)
        , correlation_matrix |>
          filter(str_detect(V1, "^survive")) |>
          select(variable = V2, cor.p.value)
      )
    , by = join_by(variable)
  ) |>
  mutate(
    cor.p.value =
      ifelse(
        is.na(cor.p.value)
        , ""
        , ifelse(
            cor.p.value < 0.001
            , "<0.001"
            , ifelse(cor.p.value > 0.05, ">0.05", round(cor.p.value, 3))
          )
      )
  ) |>
  kable(
    caption = "Table 11. Sample characteristics by survival."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:6, extra_css = "vertical-align:top;")
```

```{r table-12, echo=FALSE}
desc_stats |>
  select_if(!str_detect(colnames(desc_stats), "^survive")) |>
  kable(
    caption = "Table 12. Sample characteristics by other outcomes."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:20, extra_css = "vertical-align:top;")
```

# Feature extraction

```{r Write processed data old categories, eval=FALSE, include=FALSE}
processed_data |>
  filter(id %in% train_id) |>
  select_if(is.factor) |>
  mutate_all(as.character) |>
  gather(colname, old_cat) |>
  mutate(colname = factor(colname, unique(colname))) |>
  group_by(colname, old_cat) |>
  summarize(n = n(), .groups = "drop") |>
  select(-n) |>
  mutate(new_cat = NA) |>
  write_csv("inst/extdata/processed_data_old_cat.csv")
```

```{r Read processed data new categories, include=FALSE}
processed_data_new_cat <-
  read_csv("inst/extdata/processed_data_new_cat.csv", show_col_types = FALSE) |>
  mutate_at("old_cat", as.character)
```

```{r table-13, echo=FALSE}
processed_data_new_cat |>
  kable(
    caption = "Table 13. Processed data old and new categories."
    , format = kable_format
  ) |>
  footnote("*, inversed nominal category.") |>
  kable_classic() |>
  column_spec(1:2, extra_css = "vertical-align:top;")
```

```{r Modify categories in processed data, include=FALSE}
processed_data2 <-
  unique(variable_new_type$new_type) |>
  `names<-`(unique(variable_new_type$new_type)) |>
  imap(
    ~ processed_data |>
      select_at(
        filter(variable_new_type, new_type == .x)$variable |>
          intersect(colnames(cleaned_data))
      )
  )

processed_data2$factor <-
  processed_data2$factor |>
  mutate_all(as.character) |>
  mutate(seq = seq(n())) |>
  gather(colname, old_cat, -seq) |>
  left_join(processed_data_new_cat, by = join_by(colname, old_cat)) |>
  select(-old_cat) |>
  mutate_at("colname", \(x) factor(x, unique(x))) |>
  spread(colname, new_cat) |>
  arrange(seq) |>
  select(-seq) |>
  mutate_all(as.factor)

processed_data2 <-
  processed_data2 |>
  reduce(cbind) |>
  select_at(colnames(processed_data))
```

```{r Modify categories in processed data for indep-test, include=FALSE}
processed_data2_indep_test <-
  unique(variable_new_type$new_type) |>
  `names<-`(unique(variable_new_type$new_type)) |>
  imap(
    ~ processed_data_indep_test |>
      select_at(
        filter(variable_new_type, new_type == .x)$variable |>
          intersect(colnames(cleaned_data_indep_test))
      )
  )

processed_data2_indep_test$factor <-
  processed_data2_indep_test$factor |>
  mutate_all(as.character) |>
  mutate(seq = seq(n())) |>
  gather(colname, old_cat, -seq) |>
  left_join(processed_data_new_cat, by = join_by(colname, old_cat)) |>
  select(-old_cat) |>
  mutate_at("colname", \(x) factor(x, unique(x))) |>
  spread(colname, new_cat) |>
  arrange(seq) |>
  select(-seq) |>
  mutate_all(as.factor)

processed_data2_indep_test <-
  processed_data2_indep_test |>
  reduce(cbind) |>
  select_at(colnames(processed_data_indep_test))
```

```{r Split nominal categories in processed data, include=FALSE}
processed_data3 <- split_nominal_categories(processed_data2)
```

```{r Split nominal categories in processed data for indep-test, include=FALSE}
processed_data3_indep_test <-
  split_nominal_categories(processed_data2_indep_test)
```

```{r Finalize data for modeling and evaluation, include=FALSE}
modeval_data <- processed_data3
```

```{r Finalize data for modeling and evaluation for indep-test, include=FALSE}
modeval_data_indep_test <- processed_data3_indep_test
```

```{r Finalize regression-ready data, include=FALSE}
reg_data <-
  modeval_data |>
  filter(id %in% train_id)
```

```{r Regression-ready data new colnames, include=FALSE}
reg_data_new_colname <-
  processed_data_new_cat |>
  rename(old_colname = colname) |>
  mutate(
    new_colname =
      ifelse(
        str_detect(new_cat, "[:digit:]-")
        , old_colname
        , new_cat
      )
  ) |>
  select(old_colname, new_colname) |>
  filter(new_colname != "(removed)") |>
  filter(new_colname != "(missing)") |>
  mutate(new_colname = str_remove_all(new_colname, "\\*$")) |>
  unique()
```

```{r Identify unit of obs for each outcome-modified variable, include=FALSE}
outcome_variable_unit_reg <-
  outcome_variable_unit |>
  left_join(
    reg_data_new_colname |>
      rename(variable = old_colname)
    , by = join_by(variable)
    , relationship = "many-to-many"
  ) |>
  mutate(
    variable = ifelse(is.na(new_colname), variable, new_colname)
  ) |>
  select(-new_colname)
```

```{r Modify pre-determined variables to use new colnames, include=FALSE}
var_reg <-
  var |>
  lapply(
    \(x)
    data.frame(old_colname = x) |>
      left_join(
        reg_data_new_colname
        , by = join_by(old_colname)
      ) |>
      mutate(
        old_colname = ifelse(is.na(new_colname), old_colname, new_colname)
      ) |>
      select(-new_colname) |>
      rename(variable = old_colname) |>
      pull(variable)
  )
```

```{r Identify non-daily-checked variables, include=FALSE}
non_daily_checked_var <-
  raw_data1[c("infection_42d","morbidities_42d")] |>
  lapply(colnames) |>
  unlist() |>
  unique()|>
  lapply(
    \(x)
    data.frame(old_colname = x) |>
      left_join(
        reg_data_new_colname
        , by = join_by(old_colname)
      ) |>
      mutate(
        old_colname = ifelse(is.na(new_colname), old_colname, new_colname)
      ) |>
      select(-new_colname) |>
      rename(variable = old_colname) |>
      pull(variable)
  ) |>
  unlist()
```

# Univariate regression analysis

```{r Conduct univariate regression analysis, include=FALSE}
univar_reg <-
  var_reg$dependent |>
  lapply(
    \(x)
    setdiff(c(var_reg$independent, var_reg$covariates), "death_age") |>
      `names<-`(setdiff(c(var_reg$independent, var_reg$covariates), "death_age")) |>
      lapply(c, x) |>
      lapply(rev) |>
      lapply(paste0, collapse = '~') |>
      lapply(as.formula) |>
      lapply(
        \(x)
        suppressWarnings(
          reg_fn(
            formula = x
            , data =
              reg_data |>
              select_at(
                c(outcome_variable_unit_reg |>
                    filter(outcome == as.character(x)[2]) |>
                    filter(variable == as.character(x)[3]) |>
                    pull(unit) |>
                    str_split("\\|") |>
                    unlist()
                  , as.character(x)[2]
                  , as.character(x)[3]
                )
              ) |>
              mutate_at(
                as.character(x)[2]
                , \(x) ifelse(x == levels(x)[1], 0, 1)
              ) |>
              unique()
          )
        )
      ) |>
      lapply(tidy) |>
      imap( ~ mutate(.x, outcome = x, variable = .y)) |>
      lapply(\(x) select_if(x, colnames(x) != "robust.se")) |>
      reduce(rbind) |>
      select(outcome, variable, everything()) |>
      mutate(
        term = str_remove_all(term, variable)
        , term = ifelse(term == "", "value", term)
        , OR = exp(estimate)
        , LB = exp(estimate - qnorm(0.975) * std.error)
        , UB = exp(estimate + qnorm(0.975) * std.error)
      )
  ) |>
  reduce(rbind)
```

```{r table-14, echo=FALSE}
univar_reg  |>
  filter(term != "(Intercept)") |>
  select_at(c("outcome", "variable", "term", "OR", "LB", "UB", "p.value")) |>
  mutate(
    variable =
      paste0(
        variable
        , ifelse((LB > 1 | UB < 1) & p.value <= 0.05, "*", "")
      )
  ) |>
  mutate_at(4:7, round, 3) |>
  mutate(outcome = factor(outcome, unique(outcome))) |>
  arrange(outcome, p.value) |>
  mutate(
    p.value =
      ifelse(p.value < 0.001, "<0.001", round(p.value, 3)) |>
      as.character()
  ) |>
  kable(
    caption = "Table 14. Univariate regression analysis."
    , format = kable_format
  ) |>
  footnote("*, either LB > 1 or UB < 1 and p-value <= 0.05.") |>
  kable_classic() |>
  column_spec(1:7, extra_css = "vertical-align:top;")
```

```{r Filter significant univariate regression, include=FALSE}
univar_reg_sig <-
  univar_reg |>
  filter(term != '(Intercept)') |>
  filter((LB > 1 | UB < 1) & p.value <= 0.05) |>
  mutate(outcome = factor(outcome, unique(outcome))) |>
  arrange(outcome, p.value)
```

```{r Obtain variables in sig uni reg results, include=FALSE}
univar_reg_sig_var <-
  var_reg$dependent |>
  `names<-`(var_reg$dependent) |>
  lapply(
    \(x)
    univar_reg_sig |>
      filter(outcome == x) |>
      pull(variable) |>
      unique()
  )
```

# Covariate selection

```{r Variables with significant correlations, include=FALSE}
sig_var <-
  correlation_matrix |>
  filter(!(str_detect(V1, "^ms_") | str_detect(V2, "^ms_"))) |>
  filter(!is.na(cor.p.value)) |>
  mutate(predictor = ifelse(cor.p.value <= 0.05, 1, 0)) |>
  filter(predictor == 1) |>
  select(V1, V2, predictor) |>
  mutate_at(c("V1", "V2"), as.character) |>
  mutate_at(c("V1", "V2"), \(x) ifelse(x == "t_wk", "t", x)) |>
  unique()

sig_var <-
  sig_var |>
  left_join(
    reg_data_new_colname |>
      rename(V1 = old_colname)
    , by = join_by(V1)
    , relationship = "many-to-many"
  ) |>
  mutate(
    V1 = ifelse(is.na(new_colname), V1, new_colname)
  ) |>
  select(-new_colname) |>
  left_join(
    reg_data_new_colname |>
      rename(V2 = old_colname)
    , by = join_by(V2)
    , relationship = "many-to-many"
  ) |>
  mutate(
    V2 = ifelse(is.na(new_colname), V2, new_colname)
  ) |>
  select(-new_colname)

sig_var <-
  sig_var |>
  rbind(`colnames<-`(sig_var, c("V2", "V1", "predictor"))) |>
  unique() |>
  right_join(
    expand.grid(
      V1 = colnames(reg_data)
      , V2 = colnames(reg_data)
      , stringsAsFactors = FALSE
    )
    , by = join_by(V1, V2)
  ) |>
  spread(V2, predictor, fill = 0) |>
  column_to_rownames(var = "V1") |>
  as.matrix()

sig_var <-
  sig_var[
    colnames(reg_data)
    , colnames(reg_data)
  ]
```

```{r Create graph data frame based on simplified direction, include=FALSE}
correlation_graph_df <-
  univar_reg_sig_var |>
  imap(
    ~ sig_var[.x, .x] |>
      as.data.frame() |>
      rownames_to_column(var = "from") |>
      gather(to, predictor, -from) |>
      filter(predictor == 1) |>
      select(-predictor)
  )
```

```{r Determine adjustment per pair variable-covariate, include=FALSE}
multivar_adjustment_paired <-
  correlation_graph_df |>
  imap(
    ~ .x |>
      right_join(data.frame(to = univar_reg_sig_var[[.y]]), by = join_by(to)) |>
      select(variable = to, covariates = from) |>
      mutate(
        covariates =
          paste0(
            variable
            , ifelse(
                is.na(covariates) | covariates == "NA"
                , ""
                , paste0("+", covariates)
              )
          )
      ) |>
      mutate(formula = paste0(.y, "~", covariates)) |>
      mutate(
        covariates = str_remove_all(covariates, paste0(variable, "\\+*"))
      ) |>
      arrange(
        factor(variable, unique(filter(univar_reg_sig, outcome == .y)$variable))
      )
  )
```

```{r Conduct multi reg analysis per pair var-covar, eval=FALSE, include=FALSE}
multivar_reg_paired <-
  var_reg$dependent |>
  pblapply(
    \(x)
    multivar_adjustment_paired[[x]] |>
      pull(formula) |>
      `names<-`(multivar_adjustment_paired[[x]]$variable) |>
      lapply(as.formula) |>
      lapply(
        \(x)
        suppressWarnings(
            reg_fn(
              formula = x
              , data =
                reg_data |>
                select_at(
                  c(outcome_variable_unit_reg |>
                      filter(outcome == as.character(x)[2]) |>
                      filter(
                        variable
                        %in% str_split(
                          as.character(x)[3], pattern = " \\+ "
                        )[[1]]
                      ) |>
                      pull(unit) |>
                      str_split("\\|") |>
                      unlist() |>
                      unique()
                    , as.character(x)[2]
                    , str_split(as.character(x)[3], pattern = " \\+ ")[[1]]
                  )
                ) |>
                mutate_at(
                  as.character(x)[2]
                  , \(x) ifelse(x == levels(x)[1], 0, 1)
                ) |>
                unique()
            )
          ) |>
          tidy() |>
          list() |>
          c(list(formula = x))
      ) |>
      imap(
        ~ .x[[1]] |>
          mutate(
            outcome = x
            , variable = .y
            , covariates =
              str_split(as.character(.x[[2]])[3], "\\+")[[1]][2]
          )
      ) |>
      lapply(\(x) select_if(x, colnames(x) != "robust.se")) |>
      reduce(rbind) |>
      select(outcome, variable, covariates, everything()) |>
      mutate(
        term = str_remove_all(term, variable)
        , term = ifelse(term == "", "value", term)
        , OR = exp(estimate)
        , LB = exp(estimate - qnorm(0.975) * std.error)
        , UB = exp(estimate + qnorm(0.975) * std.error)
      )
  ) |>
  reduce(rbind)

saveRDS(multivar_reg_paired, "data/multivar_reg_paired.rds")
```

```{r Load pre-conducted multi reg analysis per pair var-covar, include=FALSE}
multivar_reg_paired <- readRDS("data/multivar_reg_paired.rds")
```

```{r Identify effect size changes after paired adjustment, include=FALSE}
es_change_paired <-
  univar_reg  |>
  filter(term != "(Intercept)") |>
  filter((LB > 1 | UB < 1) & p.value <= 0.05) |>
  select(outcome, variable, term, OR, LB, UB) |>
  left_join(
    multivar_reg_paired  |>
      filter(term != "(Intercept)") |>
      inner_join(
        univar_reg |>
          select(outcome, variable, term) |>
          unique()
        , by = join_by(outcome, variable, term)
      ) |>
      select(outcome, variable, covariates, term, OR, LB, UB)
    , by = join_by(outcome, variable, term)
  ) |>
  mutate_at(c("outcome", "variable"), \(x) factor(x, unique(x))) |>
  select(outcome, variable, covariates, everything()) |>
  mutate(
    es_change =
      case_when(
        (LB.x > 1 & LB.y > OR.x) | (UB.x < 1 & UB.y < OR.x) ~ "larger"
        , (LB.x > 1 & UB.y < 1) | (UB.x < 1 & LB.y > 1) ~ "flipped"
        , (LB.x > 1 & UB.y < OR.x & LB.y > 1)
          | (UB.x < 1 & LB.y > OR.x & UB.y < 1)
          ~ "smaller"
        , (LB.x > 1 & UB.y > 1 & LB.y < 1)
          | (UB.x < 1 & UB.y > 1 & LB.y < 1)
          ~ "insignificant"
        , (UB.y > OR.x & LB.y < OR.x) ~ "unchanged"
        , TRUE ~ "unclassified"
      )
  )
```

```{r Create data frame based on selected covariates, include=FALSE}
covariate_df <-
  var_reg$dependent |>
  `names<-`(var_reg$dependent) |>
  lapply(
    \(x)
    es_change_paired |>
      rbind(
        es_change_paired |>
          mutate(variable2 = covariates, covariates2 = variable) |>
          mutate(variable = variable2, covariates = covariates2) |>
          select(-variable2, -covariates2)
      ) |>
      filter(outcome == x) |>
      filter(es_change %in% c("smaller")) |>
      select(from = variable, to = covariates) |>
      unique() |>
      mutate_all(as.character)
  )
```

# Multivariate regression analysis

```{r Determine adjustment, include=FALSE}
multivar_adjustment <-
  covariate_df |>
  imap(
    ~ .x |>
      right_join(data.frame(to = univar_reg_sig_var[[.y]]), by = join_by(to)) |>
      group_by(to) |>
      mutate(seq = seq(n())) |>
      rbind(
        univar_reg_sig |>
          filter(outcome == .y) |>
          select(-outcome) |>
          select(to = variable) |>
          mutate(seq = 0, from = to)
      ) |>
      arrange(to, seq) |>
      group_by(to) |>
      summarize(covariates = paste0(from[!is.na(from)], collapse = "+")) |>
      rename(variable = to) |>
      mutate(formula = paste0(.y, "~", covariates)) |>
      mutate(
        covariates = str_remove_all(covariates, paste0(variable, "\\+*"))
      ) |>
      arrange(
        factor(variable, unique(filter(univar_reg_sig, outcome == .y)$variable))
      )
  )
```

```{r Conduct multivariate regression analysis, include=FALSE}
multivar_reg <-
  var_reg$dependent |>
  lapply(
    \(x)
    multivar_adjustment[[x]] |>
      pull(formula) |>
      `names<-`(multivar_adjustment[[x]]$variable) |>
      lapply(as.formula) |>
      lapply(
        \(x)
        suppressWarnings(
          reg_fn(
            formula = x
            , data =
              reg_data |>
              select_at(
                c(outcome_variable_unit_reg |>
                    filter(outcome == as.character(x)[2]) |>
                    filter(
                      variable
                      %in% str_split(
                        as.character(x)[3], pattern = " \\+ "
                      )[[1]]
                    ) |>
                    pull(unit) |>
                    str_split("\\|") |>
                    unlist() |>
                    unique()
                  , as.character(x)[2]
                  , str_split(as.character(x)[3], pattern = " \\+ ")[[1]]
                )
              ) |>
              mutate_at(
                as.character(x)[2]
                , \(x) ifelse(x == levels(x)[1], 0, 1)
              ) |>
              unique()
          )
        ) |>
          tidy() |>
          list() |>
          c(list(formula = x))
      ) |>
      imap(
        ~ .x[[1]] |>
          mutate(
            outcome = x
            , variable = .y
            , covariates =
              str_split(as.character(.x[[2]])[3], "\\+")[[1]][-1] |>
              paste0(collapse = " + ")
          )
      ) |>
      lapply(\(x) select_if(x, colnames(x) != "robust.se")) |>
      reduce(rbind) |>
      select(outcome, variable, covariates, everything()) |>
      mutate(
        term = str_remove_all(term, variable)
        , term = ifelse(term == "", "value", term)
        , OR = exp(estimate)
        , LB = exp(estimate - qnorm(0.975) * std.error)
        , UB = exp(estimate + qnorm(0.975) * std.error)
      )
  ) |>
  reduce(rbind)
```

```{r table-15, echo=FALSE}
multivar_reg  |>
  filter(term != "(Intercept)") |>
  inner_join(
    univar_reg |>
      select(outcome, variable, term) |>
      unique()
    , by = join_by(outcome, variable, term)
  ) |>
  select_at(c("outcome", "variable", "term", "OR", "LB", "UB", "p.value")) |>
  left_join(
    multivar_adjustment |>
      imap(~ select(mutate(.x, outcome = .y), outcome, everything())) |>
      reduce(rbind) |>
      select(-formula) |>
      mutate_at("covariates", str_replace_all, "\\+", ", ")
    , by = join_by(outcome, variable)
  ) |>
  mutate(
    variable =
      paste0(
        variable
        , ifelse((LB > 1 | UB < 1) & p.value <= 0.05, "*", "")
      )
  ) |>
  mutate_at(4:7, round, 3) |>
  mutate_at(c("outcome", "variable"), \(x) factor(x, unique(x))) |>
  select(outcome, variable, everything()) |>
  arrange(outcome, p.value) |>
  mutate(
    p.value =
      ifelse(p.value<0.001, "<0.001", round(p.value,3)) |>
      as.character()
  ) |>
  kable(
    caption = "Table 15. Multivariate regression analysis."
    , format = kable_format
  ) |>
  footnote("*, either LB > 1 or UB < 1 and p-value <= 0.05.") |>
  kable_classic() |>
  column_spec(1:8, extra_css = "vertical-align:top;")
```

```{r Filter significant multivariate regression, include=FALSE}
multivar_reg_sig <-
  multivar_reg  |>
  filter(term != "(Intercept)") |>
  inner_join(
    univar_reg |>
      select(outcome, variable, term) |>
      unique()
    , by = join_by(outcome, variable, term)
  ) |>
  filter((LB > 1 | UB < 1) & p.value <= 0.05) |>
  mutate(outcome = factor(outcome, unique(outcome))) |>
  arrange(outcome, p.value)
```

```{r Obtain variables in sig multi reg results, include=FALSE}
multivar_reg_sig_var <-
  var_reg$dependent |>
  `names<-`(var_reg$dependent) |>
  lapply(
    \(x)
    multivar_reg_sig |>
      filter(outcome == x) |>
      pull(variable) |>
      unique()
  )
```

```{r Plot effect sizes, include=FALSE}
es_plots <-
  var_reg$dependent |>
  `names<-`(var_reg$dependent) |>
  lapply(
    \(x)
    univar_reg  |>
      filter(outcome == x) |>
      filter(term != "(Intercept)") |>
      filter((LB > 1 | UB < 1) & p.value <= 0.05) |>
      select(outcome, variable, term, OR, LB, UB) |>
      left_join(
        multivar_reg  |>
          filter(outcome == x) |>
          filter(term != "(Intercept)") |>
          inner_join(
            univar_reg |>
              select(outcome, variable, term) |>
              unique()
            , by = join_by(outcome, variable, term)
          ) |>
          select(outcome, variable, term, OR, LB, UB)
        , by = join_by(outcome, variable, term)
      ) |>
      mutate_at(c("outcome"), \(x) factor(x, unique(x))) |>
      mutate(
        es_change =
          case_when(
            (LB.x > 1 & LB.y > OR.x) | (UB.x < 1 & UB.y < OR.x) ~ "larger"
            , (LB.x > 1 & UB.y < 1) | (UB.x < 1 & LB.y > 1) ~ "flipped"
            , (LB.x > 1 & UB.y < OR.x & LB.y > 1)
              | (UB.x < 1 & LB.y > OR.x & UB.y < 1)
              ~ "smaller"
            , (LB.x > 1 & UB.y > 1 & LB.y < 1)
              | (UB.x < 1 & UB.y > 1 & LB.y < 1)
              ~ "insignificant"
            , (UB.y > OR.x & LB.y < OR.x) ~ "unchanged"
            , TRUE ~ "unclassified"
          ) |>
          factor(
            c("larger"
              , "unchanged"
              , "smaller"
              , "insignificant"
              , "flipped"
              , "unclassified"
            )
          )
      ) |>
      unite(variable_term, variable, term, sep = " = ") |>
      mutate(variable_term = reorder(variable_term, OR.y)) |>
      mutate(seq = seq(n())) |>
      gather(metric, value, -seq, -outcome, -variable_term, -es_change) |>
      separate(metric, c("metric", "adjustment"), sep = "\\.") |>
      spread(metric, value) |>
      arrange(seq) |>
      select(-seq) |>
      mutate(adjustment = ifelse(adjustment == "x", "no", "yes")) |>
      mutate_at(c("OR", "LB", "UB"), \(x) ifelse(x >= 4, 4, x)) |>
      ggplot(aes(variable_term, OR, color = adjustment)) +
      geom_hline(yintercept = 1, lty = 2) +
      geom_point(
        aes(size = adjustment)
        , alpha =0.75, , show.legend = FALSE, na.rm = TRUE
      ) +
      geom_errorbar(
        aes(ymin = LB, ymax = UB)
        , alpha =0.75, width = 0.75, na.rm = TRUE
      ) +
      facet_grid(
        es_change ~ outcome
        , switch = "y", scales = "free_y", space = "free_y"
      ) +
      coord_flip() +
      scale_y_continuous(limits = c(0, 4), labels = c(0 , 1, 2, 3, "4+")) +
      scale_size_manual(values = c(2, 1)) +
      xlab("") +
      ylab("") +
      theme(
        legend.position = "none"
        , strip.text.y.left = element_text(angle = 0)
        , strip.placement = "outside"
      )
  )
```

```{r figure-4, echo=FALSE, fig.height=35, fig.width=7}
ggarrange(
  es_plots[[1]] + theme(legend.position = "top")
  , es_plots[[2]]
  , es_plots[[3]]
  , es_plots[[4]]
  , es_plots[[5]]
  , es_plots[[6]]
  , es_plots[[7]]
  , nrow = length(es_plots)
  , ncol = 1
  , widths = 7
  , heights =
    c(nrow(es_plots[[1]]$data) + 9
      , nrow(es_plots[[2]]$data)
      , nrow(es_plots[[3]]$data) + 9
      , nrow(es_plots[[4]]$data) + 9
      , nrow(es_plots[[5]]$data)
      , nrow(es_plots[[6]]$data)
      , nrow(es_plots[[7]]$data)
    )
)
```

Figure 4. Effect size changes before and after adjustment for confounders.

# Feature selection

```{r Select predictors for baseline and residual, include=FALSE}
predictor <-
  multivar_reg_sig_var |>
  lapply(\(x) data.frame(new_colname = x)) |>
  lapply(left_join, reg_data_new_colname, by = join_by(new_colname)) |>
  lapply(
    mutate
    , old_colname = ifelse(is.na(old_colname), new_colname, old_colname)
  ) |>
  lapply(
    left_join
    , raw_data1 |>
        imap(~ data.frame(dataset = .y, old_colname = colnames(.x))) |>
        reduce(rbind)
    , by = join_by(old_colname)
  ) |>
  lapply(
    mutate
    , type =
      ifelse(!str_detect(dataset, "42d$|6w$"), "baseline", "residual")
  ) |>
  lapply(select, variable = new_colname, type) |>
  imap(
    ~ c("baseline", "residual") |>
      `names<-`(c("baseline", "residual")) |>
      lapply(\(x) .x$variable[.x$type == x])
  )
```

```{r Split data for mod & eval by pre-defined pred & partition, include=FALSE}
modeval_data_set_ori <-
  predictor |>
  lapply(\(x) x[sapply(x, length) > 0]) |>
  imap(
    ~ list(
        baseline =
          modeval_data |>
          mutate_if(is.factor, \(x) ifelse(is.na(x), NA, as.numeric(x) - 1)) |>
          select_at(c(var$s, .y, .x$baseline)) |>
          rename_at(.y, \(x) "outcome") |>
          unique()
        , residual =
          modeval_data |>
          mutate_if(is.factor, \(x) ifelse(is.na(x), NA, as.numeric(x) - 1)) |>
          select_at(c(var$s, .y, var$t, .x$residual)) |>
          rename_at(.y, \(x) "outcome") |>
          unique()
      ) |>
      imap(
        ~ list(train = train_id, validation = val_id, test = test_id) |>
          lapply(\(x) filter(.x, id %in% x))
      )
  )
```

```{r Split data for baseline & residual for indep-test, include=FALSE}
modeval_data_set_ori_indep_test <-
  predictor |>
  lapply(\(x) x[sapply(x, length) > 0]) |>
  imap(
    ~ list(
        baseline =
          modeval_data_indep_test |>
          mutate_if(is.factor, \(x) ifelse(is.na(x), NA, as.numeric(x) - 1)) |>
          select_at(c(var$s, .y, .x$baseline)) |>
          rename_at(.y, \(x) "outcome") |>
          unique()
        , residual =
          modeval_data_indep_test |>
          mutate_if(is.factor, \(x) ifelse(is.na(x), NA, as.numeric(x) - 1)) |>
          select_at(c(var$s, .y, var$t, .x$residual)) |>
          rename_at(.y, \(x) "outcome") |>
          unique()
      ) |>
      imap(~ list(independent_test = .x))
  )
```

# Dimensional reduction

```{r Dim reduction needed for regression training, include=FALSE}
dim_red_train_regression <-
  modeval_data_set_ori |>
  imap(
    ~ names(.x) |>
      lapply(
        \(x)
        names(.x[[x]]) |>
          lapply(
            \(y)
            .x[[x]][[y]] |>
              rename(cat = outcome) |>
              mutate(outcome = .y, type = x, set = y) |>
              group_by(outcome, type, set, cat) |>
              summarize(n = n(), .groups = "drop") |>
              mutate(
                pred =
                  sum(!colnames(.x[[x]][[y]]) %in% c("id", "outcome"))
              )
          ) |>
          reduce(rbind)
      ) |>
      reduce(rbind)
  ) |>
  reduce(rbind) |>
  filter(set == "train") |>
  filter(!is.na(cat)) |>
  group_by(outcome, type, set) |>
  filter(n == min(n)) |>
  ungroup() |>
  mutate(epv = ceiling(n/pred), min_epv = 20, min_epv2 = 150, min_epv3 = 200) |>
  mutate(
    max_pred =
      floor(n/min_epv)
      - ifelse(type != "survive", 1, 0)
      - ifelse(type == "residual", 1, 0)
    , max_pred2 =
      floor(n/min_epv2)
      - ifelse(type != "survive", 1, 0)
      - ifelse(type == "residual", 1, 0)
    , max_pred3 =
      floor(n/min_epv3)
      - ifelse(type != "survive", 1, 0)
      - ifelse(type == "residual", 1, 0)
  ) |>
  pivot_longer(
    cols = c(min_epv, min_epv2, min_epv3, max_pred, max_pred2, max_pred3)
    , names_to = c(".value", "group")
    , names_pattern = "(min_epv|max_pred)(\\d*)"
  ) |>
  select(-group) |>
  select(outcome, type, min_epv, everything())
```

```{r table-16, echo=FALSE}
dim_red_train_regression |>
  mutate(
    outcome =
      paste0(outcome, ifelse(pred > max_pred & max_pred > 1, "*", ""))
  ) |>
  select(-set) |>
  filter(max_pred > 1) |>
  kable(
    caption = "Table 16. Dimensional reduction needed for regression training."
    , format = kable_format
  ) |>
  footnote("*, require dimensional reduction.") |>
  kable_classic() |>
  column_spec(1:5, extra_css = "vertical-align:top;")
```

```{r Prepare dimensional reduction inputs, include=FALSE}
dr_input <-
  dim_red_train_regression |>
  filter(pred > max_pred & max_pred > 1)

dr_input <-
  unique(dr_input$outcome) |>
  `names<-`(unique(dr_input$outcome)) |>
  lapply(
    \(x)
    unique(filter(dr_input, outcome == x)$type) |>
      `names<-`(unique(filter(dr_input, outcome == x)$type)) |>
      lapply(
        \(y)
        unique(filter(dr_input, outcome == x & type == y)$min_epv) |>
          `names<-`(
            unique(filter(dr_input, outcome == x & type == y)$min_epv)
          ) |>
          lapply(\(z) modeval_data_set_ori[[x]][[y]])
      )
  )
```

```{r Prepare dimensional reduction inputs for indep-test, include=FALSE}
dr_input_indep_test <-
  dim_red_train_regression |>
  filter(pred > max_pred & max_pred > 1)

dr_input_indep_test <-
  unique(dr_input_indep_test$outcome) |>
  `names<-`(unique(dr_input_indep_test$outcome)) |>
  lapply(
    \(x)
    unique(filter(dr_input_indep_test, outcome == x)$type) |>
      `names<-`(unique(filter(dr_input_indep_test, outcome == x)$type)) |>
      lapply(
        \(y)
        unique(filter(dr_input_indep_test, outcome == x & type == y)$min_epv) |>
          `names<-`(
            unique(
              filter(dr_input_indep_test, outcome == x & type == y)$min_epv
            )
          ) |>
          lapply(\(z) modeval_data_set_ori_indep_test[[x]][[y]])
      )
  )
```

```{r Conduct principal component analysis, include=FALSE}
dr_model <-
  dr_input |>
  lapply(
    lapply
    , \(x)
      x |>
        lapply(
          \(x)
          select_if(x$train, !colnames(x$train) %in% c("id", "t", "outcome"))
        )
  ) |>
  lapply(lapply, \(x) lapply(x, \(x) prcomp(x, scale. = TRUE)))
```

```{r Describe dimensional reduction models, include=FALSE}
dr_model_desc <-
  dr_model |>
  imap(
    ~ names(.x) |>
      `names<-`(names(.x)) |>
      lapply(
        \(x)
        names(.x[[x]]) |>
          `names<-`(names(.x[[x]])) |>
          lapply(
            \(y)
            .x[[x]][[y]]$rotation[
                , dim_red_train_regression |>
                    filter(outcome == .y & type == x & min_epv == y) |>
                    mutate(old_dim = ifelse(max_pred >= pred, pred, max_pred)) |>
                    pull(old_dim) |>
                    seq()
                , drop = FALSE
              ] |>
              as.data.frame() |>
              rownames_to_column(var =  "old_dim") |>
              gather(new_dim, weight, -old_dim) |>
              mutate(outcome = .y, type = x, min_epv = y) |>
              mutate(
                pve =
                  c(.x[[x]][[y]]$sdev^2/sum(.x[[x]][[y]]$sdev^2))[
                    dim_red_train_regression |>
                      filter(outcome == .y & type == x & min_epv == y) |>
                      mutate(old_dim = ifelse(max_pred >= pred, pred, max_pred)) |>
                      pull(old_dim) |>
                      seq()
                  ] |>
                  sum()
              ) |>
              select(outcome, type, min_epv, pve, everything())
          ) |>
          reduce(rbind)
      ) |>
      reduce(rbind)
  ) |>
  reduce(rbind)
```

```{r Write new dimension old names, eval=FALSE, include=FALSE}
dr_model_desc |>
  select(outcome, type, old_name = new_dim) |>
  unique() |>
  mutate(new_name = old_name) |>
  write_csv("inst/extdata/new_dimension_old_name.csv")
```

```{r Load new dimension new names, include=FALSE}
new_dimension_new_name <-
  read_csv("inst/extdata/new_dimension_new_name.csv", show_col_types = FALSE)
```

```{r Plot dimensional reduction model weights, include=FALSE}
dr_model_weight_plot <-
  unique(dr_model_desc$outcome) |>
  `names<-`(unique(dr_model_desc$outcome)) |>
  lapply(
    \(x)
    unique(filter(dr_model_desc, outcome == x)$type) |>
      `names<-`(unique(filter(dr_model_desc, outcome == x)$type)) |>
      lapply(
        \(y)
        unique(filter(dr_model_desc, outcome == x & type == y)$min_epv) |>
          `names<-`(
            unique(filter(dr_model_desc, outcome == x & type == y)$min_epv)
          ) |>
          lapply(
            \(z)
            dr_model_desc |>
              filter(outcome == x & type == y & min_epv == z) |>
              mutate(
                direction = ifelse(weight < 0, "-", "+")
                , weight  = abs(weight)
              ) |>
              arrange(new_dim, desc(weight)) |>
              group_by(new_dim) |>
              mutate(rank = seq(n())) |>
              ungroup() |>
              mutate(old_dim = reorder(paste0(old_dim, "-", rank), rank)) |>
              left_join(
                new_dimension_new_name |>
                  rename(new_dim = old_name)
                , by = join_by(outcome, type, new_dim)
              ) |>
              mutate(new_dim = factor(new_name, unique(new_name))) |>
              ggplot(aes(old_dim, weight, fill = direction)) +
              geom_col() +
              facet_grid(
                ~ new_dim
                , scales = "free_x"
              ) +
              scale_y_continuous(limits = c(0, max(abs(dr_model_desc$weight)))) +
              scale_fill_discrete("") +
              xlab("") +
              ylab(
                paste0(
                  "PVE = "
                  , dr_model_desc |>
                    filter(outcome == x & type == y & min_epv == z) |>
                    pull(pve) |>
                    unique() |>
                    sapply(\(x) round(x*100, 2))
                  , "%"
                )
              ) +
              theme(
                axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
                , axis.title.y = element_text(size = 9)
              )
          )
      )
  )
```

```{r figure-5, echo=FALSE, fig.height=10, fig.width=12}
ggarrange(
  ggarrange(
    ggarrange(
      dr_model_weight_plot$survive$baseline$`20` +
          theme(legend.position = "none")
      , NULL
      , ncol = 1
      , nrow = 2
      , heights = c(6, 1)
    )
    , dr_model_weight_plot$survive$residual$`150`
    , ncol = 2
    , nrow = 1
    , widths =
      c(nrow(dr_model_weight_plot$survive$baseline$`20`$data)
        , nrow(dr_model_weight_plot$survive$residual$`150`$data) + 4
      )
    , labels = LETTERS[1:2]
  )
  , ggarrange(
      dr_model_weight_plot$survive$residual$`200` +
        theme(legend.position = "none")
      , ggarrange(
          dr_model_weight_plot$hearing$residual$`200`
          , NULL
          , ncol = 1
          , nrow = 2
          , heights = c(5, 1)
        )
      , ncol = 2
      , nrow = 1
      , widths =
        c(nrow(dr_model_weight_plot$survive$residual$`200`$data)
          , nrow(dr_model_weight_plot$hearing$residual$`200`$data)
        )
      , labels = LETTERS[3:4]
    )
  , dr_model_weight_plot$rop_severe$residual$`200`
  , ncol = 1
  , nrow = 3
  , widths = c(3, 5, 5)
  , labels = c("", "", LETTERS[5])
)
```

Figure 5. Dimensional reduction model weights for predictors of: (A) survival baseline prediction (min. 20 EPV); (B) survival residual prediction (min. 150 EPV); (C) survival residual prediction (min. 200 EPV); (D) hearing residual prediction (min. 200 EPV); and (E) severe ROP residual prediction (min. 200 EPV). PVE, proportion of variance explained

```{r Reduce dimensions using the models, include=FALSE}
dr_output <-
  dr_input |>
  imap(
    ~ names(.x) |>
      `names<-`(names(.x)) |>
      lapply(
        \(x)
        names(.x[[x]]) |>
          `names<-`(names(.x[[x]])) |>
          lapply(
            \(y)
            names(.x[[x]][[y]]) |>
              `names<-`(names(.x[[x]][[y]])) |>
              lapply(\(z) reduce_dim_pca(dr_input, dr_model, .y, x, y, z))
          )
      )
  )
```

```{r Reduce dimensions using the models for indep-test, include=FALSE}
dr_output_indep_test <-
  dr_input_indep_test |>
  imap(
    ~ names(.x) |>
      `names<-`(names(.x)) |>
      lapply(
        \(x)
        names(.x[[x]]) |>
          `names<-`(names(.x[[x]])) |>
          lapply(
            \(y)
            names(.x[[x]][[y]]) |>
              `names<-`(names(.x[[x]][[y]])) |>
              lapply(
                \(z) reduce_dim_pca(dr_input_indep_test, dr_model, .y, x, y, z)
              )
          )
      )
  )
```

```{r Change data for mod & eval to dr outputs accordingly, include=FALSE}
modeval_data_set <-
  modeval_data_set_ori |>
  imap(
    ~ names(.x) |>
      `names<-`(names(.x)) |>
      lapply(
        \(x)
        list(`20` = 20, `150` = 150, `200` = 200) |>
          lapply(
            \(y)
            list(
              .x[[x]]
              , dr_output[[.y]][[x]][[as.character(y)]]
            )[[
              ifelse(
                nrow(
                  dr_model_desc |>
                    filter(outcome == .y & type == x & min_epv == y)
                ) > 0
                , 2, 1
              )
            ]]
          )
      )
  )
```

```{r Change data for indep-test to dr outputs accordingly, include=FALSE}
modeval_data_set_indep_test <-
  modeval_data_set_ori_indep_test |>
  imap(
    ~ names(.x) |>
      `names<-`(names(.x)) |>
      lapply(
        \(x)
        list(`20` = 20, `150` = 150, `200` = 200) |>
          lapply(
            \(y)
            list(
              .x[[x]]
              , dr_output_indep_test[[.y]][[x]][[as.character(y)]]
            )[[
              ifelse(
                nrow(
                  dr_model_desc |>
                    filter(outcome == .y & type == x & min_epv == y)
                ) > 0
                , 2, 1
              )
            ]]
          )
      )
  )
```

# Predictive modeling

```{r Determine prediction sequence by competing risks, include=FALSE}
pred_seq <-
  list(
    survive = c("survive")
    , rop_severe = c("survive", "rop_severe")
    , bpd = c("survive", "bpd")
    , bpd_moderate_severe = c("survive", "bpd", "bpd_moderate_severe")
    , eugr_hc = c("survive", "eugr_hc")
    , eugr_bw = c("survive", "eugr_bw")
    , rop_severe = c("survive", "hearing")
  )

save_dir <- "inst/extdata/modeval_data_set/"
if(!dir.exists(save_dir)) dir.create(save_dir, recursive = TRUE)
```

```{r Show prediction sequence by competing risks, echo=FALSE}
pred_seq |>
  imap(~ paste0(.y, ": ", paste0(.x, collapse = " -> "))) |>
  unlist() |>
  paste0(collapse = "\n") |>
  cat()
```

```{r List of algorithms, include=FALSE}
algorithms <- read_csv("inst/extdata/algorithms.csv", show_col_types = FALSE)
```

```{r List of models, include=FALSE}
model_stacks <-
  dim_red_train_regression |>
  filter(pred > 0 & max_pred > 1) |>
  select(outcome, type, pred, min_epv) |>
  left_join(
    algorithms
    , by = join_by(min_epv)
    , relationship = "many-to-many"
  ) 
```

```{r table-17, echo=FALSE}
model_stacks |>
  mutate(
    min_epv = ifelse(duplicated(paste0(outcome, type, pred, min_epv)), "", min_epv)
    , pred = ifelse(duplicated(paste0(outcome, type, pred)), "", pred)
    , type = ifelse(duplicated(paste0(outcome, type)), "", type)
    , outcome = ifelse(duplicated(outcome), "", outcome)
  ) |>
  kable(
    caption = "Table 17. List of model stacks and algorithms."
    , format = kable_format
  ) |>
  footnote("EPV, event per variable") |>
  kable_classic() |>
  column_spec(1:4, extra_css = "vertical-align:top;")
```

```{r Empty list of dimensional reduction before modeling, include=FALSE}
dr_before_modeling_desc <- list()
```

## Survival prediction

```{r Survival prediction - Write baseline 1, eval=FALSE, include=FALSE}
seq(nrow(filter(model_stacks, outcome == "survive" & type == "baseline"))) |>
  lapply(
    \(x)
    filter(model_stacks, outcome == "survive" & type == "baseline") |>
      slice(x)
  ) |>
  lapply(
    \(x)
    modeval_data_set[[
        x$outcome[1]
      ]][[
        x$type[1]
      ]][[
        as.character(x$min_epv[1])
      ]] |>
      c(modeval_data_set_indep_test[[
          x$outcome[1]
        ]][[
          x$type[1]
        ]][[
          as.character(x$min_epv[1])
        ]]
      ) |>
      imap(
        ~ .x |>
          filter(!is.na(outcome)) |>
          write_csv(
            paste0(
              "inst/extdata/modeval_data_set/survive_baseline1_"
              , x$algorithm[1], "_", .y, ".csv"
            )
          )
      )
  )
```

```{r Survival prediction - Baseline 1 results, include=FALSE}
survive_baseline1_rr <-
  obtain_obs_pred(
    prefix = "survive_baseline1_rr"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r Survival prediction - Write stack, eval=FALSE, include=FALSE}
seq(nrow(filter(model_stacks, outcome == "survive" & type == "residual"))) |>
  lapply(
    \(x)
    filter(model_stacks, outcome == "survive" & type == "residual") |>
      slice(x)
  ) |>
  lapply(
    \(x)
    stack_prediction(
        modeval_data_set[[
            x$outcome[1]
          ]][[
            x$type[1]
          ]][[
            as.character(x$min_epv[1])
          ]]
        , data_dir = "inst/extdata/modeval_data_set/"
        , model_dir = "inst/extdata/model/"
        , prior_model_name = "survive_baseline1_rr"
        , indices = c("id")
        , set = c("train", "validation", "test")
      ) |>
      c(stack_prediction(
          modeval_data_set_indep_test[[
              x$outcome[1]
            ]][[
              x$type[1]
            ]][[
              as.character(x$min_epv[1])
            ]]
          , data_dir = "inst/extdata/modeval_data_set/"
          , model_dir = "inst/extdata/model/"
          , prior_model_name = "survive_baseline1_rr"
          , indices = c("id")
          , set = c("independent_test")
        )
      ) |>
      imap(
        ~ .x |>
          filter(!is.na(outcome)) |>
          write_csv(
            paste0(
              "inst/extdata/modeval_data_set/survive_stack_"
              , x$algorithm[1], "_", .y, ".csv"
            )
          )
      )
  )
```

```{r Survival prediction - Stack results, include=FALSE}
survive_stack_rr <-
  obtain_obs_pred(
    prefix = "survive_stack_rr"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

survive_stack_rf <-
  obtain_obs_pred(
    prefix = "survive_stack_rf"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

survive_stack_gbm <-
  obtain_obs_pred(
    prefix = "survive_stack_gbm"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

survive_stack_dnn <-
  obtain_obs_pred(
    prefix = "survive_stack_dnn"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r Survival prediction - Stack evaluation, eval=FALSE, include=FALSE}
survive_stack_eval_df_list <-
  list(
    survive_stack_rr = survive_stack_rr
    , survive_stack_rf = survive_stack_rf
    , survive_stack_gbm = survive_stack_gbm
    , survive_stack_dnn = survive_stack_dnn
  )

survive_stack_eval_calibration <-
  survive_stack_eval_df_list |>
  lapply(\(x) lapply(x, calibration, seed = seed))

survive_stack_eval_discrimination <-
  survive_stack_eval_df_list[
    survive_stack_eval_calibration |>
      select_well_calibrated_model()
  ] |>
  lapply(\(x) lapply(lapply(x, select, -id), discrimination, seed = seed))

survive_stack_eval_discrimination |>
  select_best_auroc_lb_model() |>
  cat()
```

```{r Survival prediction - Required features, include=FALSE}
dr_before_modeling_desc$survive_baseline1_rr <-
  list(outcome = "survive", type = "baseline", min_epv = "20")

dr_before_modeling_desc$survive_stack_dnn <-
  list(outcome = "survive", type = "residual", min_epv = "200")

survive_pred_features <-
  c(baseline = "survive_baseline1_rr", stack = "survive_stack_dnn")

survive_pred_features <-
  survive_pred_features |>
  obtain_pred_features(
    dr_before_modeling_desc[survive_pred_features] |>
      lapply(
        \(x)
        dr_model_desc |>
        filter(outcome == x$outcome & type == x$type & min_epv == x$min_epv)
      )
  )
```

## Severe ROP prediction

```{r Severe ROP prediction - Write stack, eval=FALSE, include=FALSE}
seq(nrow(filter(model_stacks, outcome == "rop_severe" & type == "residual"))) |>
  lapply(
    \(x)
    filter(model_stacks, outcome == "rop_severe" & type == "residual") |>
      slice(x)
  ) |>
  lapply(
    \(x)
    stack_prediction(
        modeval_data_set[[
            x$outcome[1]
          ]][[
            x$type[1]
          ]][[
            as.character(x$min_epv[1])
          ]]
        , data_dir = "inst/extdata/modeval_data_set/"
        , model_dir = "inst/extdata/model/"
        , prior_model_name = "survive_stack_dnn"
        , indices =  c("id", "t")
        , set = c("train", "validation", "test")
      ) |>
      c(stack_prediction(
          modeval_data_set_indep_test[[
              x$outcome[1]
            ]][[
              x$type[1]
            ]][[
              as.character(x$min_epv[1])
            ]]
          , data_dir = "inst/extdata/modeval_data_set/"
          , model_dir = "inst/extdata/model/"
          , prior_model_name = "survive_stack_dnn"
          , indices =  c("id", "t")
          , set = c("independent_test")
        )
      ) |>
      imap(
        ~ .x |>
          filter(!is.na(outcome)) |>
          write_csv(
            paste0(
              "inst/extdata/modeval_data_set/rop_severe_stack_"
              , x$algorithm[1], "_", .y, ".csv"
            )
          )
      )
  )
```

```{r Severe ROP prediction - Stack results, include=FALSE}
rop_severe_stack_rr <-
  obtain_obs_pred(
    prefix = "rop_severe_stack_rr"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

rop_severe_stack_rf <-
  obtain_obs_pred(
    prefix = "rop_severe_stack_rf"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

rop_severe_stack_gbm <-
  obtain_obs_pred(
    prefix = "rop_severe_stack_gbm"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

rop_severe_stack_dnn <-
  obtain_obs_pred(
    prefix = "rop_severe_stack_dnn"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r Severe ROP prediction - Stack evaluation, eval=FALSE, include=FALSE}
rop_severe_stack_eval_df_list <-
  list(
    rop_severe_stack_rr = rop_severe_stack_rr
    , rop_severe_stack_rf = rop_severe_stack_rf
    , rop_severe_stack_gbm = rop_severe_stack_gbm
    , rop_severe_stack_dnn = rop_severe_stack_dnn
  )

rop_severe_stack_eval_calibration <-
  rop_severe_stack_eval_df_list |>
  lapply(\(x) lapply(x, calibration, seed = seed))

rop_severe_stack_eval_discrimination <-
  rop_severe_stack_eval_df_list[
    rop_severe_stack_eval_calibration |>
      select_well_calibrated_model()
  ] |>
  lapply(\(x) lapply(lapply(x, select, -id), discrimination, seed = seed))

rop_severe_stack_eval_discrimination |>
  select_best_auroc_lb_model() |>
  cat()
```

```{r Severe ROP prediction - Required features, include=FALSE}
dr_before_modeling_desc$rop_severe_stack_rr <-
  list(outcome = "rop_severe", type = "residual", min_epv = "20")

rop_severe_pred_features <-
  c(baseline = "survive_baseline1_rr"
    , stack1 = "survive_stack_dnn"
    , stack2 = "rop_severe_stack_rr"
  )

rop_severe_pred_features <-
  rop_severe_pred_features |>
  obtain_pred_features(
    dr_before_modeling_desc[rop_severe_pred_features] |>
      lapply(
        \(x)
        dr_model_desc |>
        filter(outcome == x$outcome & type == x$type & min_epv == x$min_epv)
      )
  )
```

## BPD prediction

```{r BPD prediction - Write stack, eval=FALSE, include=FALSE}
seq(nrow(filter(model_stacks, outcome == "bpd" & type == "residual"))) |>
  lapply(
    \(x)
    filter(model_stacks, outcome == "bpd" & type == "residual") |>
      slice(x)
  ) |>
  lapply(
    \(x)
    stack_prediction(
        modeval_data_set[[
            x$outcome[1]
          ]][[
            x$type[1]
          ]][[
            as.character(x$min_epv[1])
          ]]
        , data_dir = "inst/extdata/modeval_data_set/"
        , model_dir = "inst/extdata/model/"
        , prior_model_name = "survive_stack_dnn"
        , indices =  c("id", "t")
        , set = c("train", "validation", "test")
      ) |>
      c(stack_prediction(
          modeval_data_set_indep_test[[
              x$outcome[1]
            ]][[
              x$type[1]
            ]][[
              as.character(x$min_epv[1])
            ]]
          , data_dir = "inst/extdata/modeval_data_set/"
          , model_dir = "inst/extdata/model/"
          , prior_model_name = "survive_stack_dnn"
          , indices =  c("id", "t")
          , set = c("independent_test")
        )
      ) |>
      imap(
        ~ .x |>
          filter(!is.na(outcome)) |>
          write_csv(
            paste0(
              "inst/extdata/modeval_data_set/bpd_stack_"
              , x$algorithm[1], "_", .y, ".csv"
            )
          )
      )
  )
```

```{r BPD prediction - Stack results, include=FALSE}
bpd_stack_rr <-
  obtain_obs_pred(
    prefix = "bpd_stack_rr"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

bpd_stack_rf <-
  obtain_obs_pred(
    prefix = "bpd_stack_rf"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

bpd_stack_gbm <-
  obtain_obs_pred(
    prefix = "bpd_stack_gbm"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

bpd_stack_dnn <-
  obtain_obs_pred(
    prefix = "bpd_stack_dnn"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r BPD prediction - Stack evaluation, eval=FALSE, include=FALSE}
bpd_stack_eval_df_list <-
  list(
    bpd_stack_rr = bpd_stack_rr
    , bpd_stack_rf = bpd_stack_rf
    , bpd_stack_gbm = bpd_stack_gbm
    , bpd_stack_dnn = bpd_stack_dnn
  )

bpd_stack_eval_calibration <-
  bpd_stack_eval_df_list |>
  lapply(\(x) lapply(x, calibration, seed = seed))

bpd_stack_eval_discrimination <-
  bpd_stack_eval_df_list[
    bpd_stack_eval_calibration |>
      select_well_calibrated_model()
  ] |>
  lapply(\(x) lapply(lapply(x, select, -id), discrimination, seed = seed))

bpd_stack_eval_discrimination |>
  select_best_auroc_lb_model() |>
  cat()
```

```{r BPD prediction - Required features, include=FALSE}
dr_before_modeling_desc$bpd_stack_rf <-
  list(outcome = "bpd", type = "residual", min_epv = "150")

bpd_pred_features <-
  c(baseline = "survive_baseline1_rr"
    , stack1 = "survive_stack_dnn"
    , stack2 = "bpd_stack_rf"
  )

bpd_pred_features <-
  bpd_pred_features |>
  obtain_pred_features(
    dr_before_modeling_desc[bpd_pred_features] |>
      lapply(
        \(x)
        dr_model_desc |>
        filter(outcome == x$outcome & type == x$type & min_epv == x$min_epv)
      )
  )
```

## Moderate/severe BPD prediction

```{r Mod/sev BPD prediction - Write stack, eval=FALSE, include=FALSE}
seq(
    nrow(
      filter(
        model_stacks, outcome == "bpd_moderate_severe" & type == "residual"
      )
    )
  ) |>
  lapply(
    \(x)
    filter(
        model_stacks, outcome == "bpd_moderate_severe" & type == "residual"
      ) |>
      slice(x)
  ) |>
  lapply(
    \(x)
    stack_prediction(
        modeval_data_set[[
            x$outcome[1]
          ]][[
            x$type[1]
          ]][[
            as.character(x$min_epv[1])
          ]]
        , data_dir = "inst/extdata/modeval_data_set/"
        , model_dir = "inst/extdata/model/"
        , prior_model_name = "bpd_stack_rf"
        , indices =  c("id", "t")
        , set = c("train", "validation", "test")
      ) |>
      c(stack_prediction(
          modeval_data_set_indep_test[[
              x$outcome[1]
            ]][[
              x$type[1]
            ]][[
              as.character(x$min_epv[1])
            ]]
          , data_dir = "inst/extdata/modeval_data_set/"
          , model_dir = "inst/extdata/model/"
          , prior_model_name = "bpd_stack_rf"
          , indices =  c("id", "t")
          , set = c("independent_test")
        )
      ) |>
      imap(
        ~ .x |>
          filter(!is.na(outcome)) |>
          write_csv(
            paste0(
              "inst/extdata/modeval_data_set/bpd_moderate_severe_stack_"
              , x$algorithm[1], "_", .y, ".csv"
            )
          )
      )
  )
```

```{r Mod/sev BPD prediction - Stack results, include=FALSE}
bpd_moderate_severe_stack_rr <-
  obtain_obs_pred(
    prefix = "bpd_moderate_severe_stack_rr"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

bpd_moderate_severe_stack_rf <-
  obtain_obs_pred(
    prefix = "bpd_moderate_severe_stack_rf"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

bpd_moderate_severe_stack_gbm <-
  obtain_obs_pred(
    prefix = "bpd_moderate_severe_stack_gbm"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

bpd_moderate_severe_stack_dnn <-
  obtain_obs_pred(
    prefix = "bpd_moderate_severe_stack_dnn"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r Mod/sev BPD prediction - Stack evaluation, eval=FALSE, include=FALSE}
bpd_moderate_severe_stack_eval_df_list <-
  list(
    bpd_moderate_severe_stack_rr = bpd_moderate_severe_stack_rr
    , bpd_moderate_severe_stack_rf = bpd_moderate_severe_stack_rf
    , bpd_moderate_severe_stack_gbm = bpd_moderate_severe_stack_gbm
    , bpd_moderate_severe_stack_dnn = bpd_moderate_severe_stack_dnn
  )

bpd_moderate_severe_stack_eval_calibration <-
  bpd_moderate_severe_stack_eval_df_list |>
  lapply(\(x) lapply(x, calibration, seed = seed))

bpd_moderate_severe_stack_eval_discrimination <-
  bpd_moderate_severe_stack_eval_df_list[
    bpd_moderate_severe_stack_eval_calibration |>
      select_well_calibrated_model()
  ] |>
  lapply(\(x) lapply(lapply(x, select, -id), discrimination, seed = seed))

bpd_moderate_severe_stack_eval_discrimination |>
  select_best_auroc_lb_model() |>
  cat()
```

```{r Mod/sev BPD prediction - Required features, include=FALSE}
dr_before_modeling_desc$bpd_moderate_severe_stack_rf <-
  list(outcome = "bpd_moderate_severe", type = "residual", min_epv = "150")

bpd_moderate_severe_pred_features <-
  c(baseline = "survive_baseline1_rr"
    , stack1 = "survive_stack_dnn"
    , stack2 = "bpd_stack_rf"
    , stack3 = "bpd_moderate_severe_stack_rf"
  )

bpd_moderate_severe_pred_features <-
  bpd_moderate_severe_pred_features |>
  obtain_pred_features(
    dr_before_modeling_desc[bpd_moderate_severe_pred_features] |>
      lapply(
        \(x)
        dr_model_desc |>
        filter(outcome == x$outcome & type == x$type & min_epv == x$min_epv)
      )
  )
```

## EUGR-HC prediction

```{r EUGR-HC prediction - Write baseline 2, eval=FALSE, include=FALSE}
seq(nrow(filter(model_stacks, outcome == "eugr_hc" & type == "baseline"))) |>
  lapply(
    \(x)
    filter(model_stacks, outcome == "eugr_hc" & type == "baseline") |>
      slice(x)
  ) |>
  lapply(
    \(x)
    stack_prediction(
        modeval_data_set[[
            x$outcome[1]
          ]][[
            x$type[1]
          ]][[
            as.character(x$min_epv[1])
          ]]
        , data_dir = "inst/extdata/modeval_data_set/"
        , model_dir = "inst/extdata/model/"
        , prior_model_name = "survive_baseline1_rr"
        , indices =  "id"
        , set = c("train", "validation", "test")
      ) |>
      c(stack_prediction(
          modeval_data_set_indep_test[[
              x$outcome[1]
            ]][[
              x$type[1]
            ]][[
              as.character(x$min_epv[1])
            ]]
          , data_dir = "inst/extdata/modeval_data_set/"
          , model_dir = "inst/extdata/model/"
          , prior_model_name = "survive_baseline1_rr"
          , indices =  "id"
          , set = c("independent_test")
        )
      ) |>
      imap(
        ~ .x |>
          filter(!is.na(outcome)) |>
          write_csv(
            paste0(
              "inst/extdata/modeval_data_set/eugr_hc_baseline2_"
              , x$algorithm[1], "_", .y, ".csv"
            )
          )
      )
  )
```

```{r EUGR-HC prediction - Baseline 2 results, include=FALSE}
eugr_hc_baseline2_rr <-
  obtain_obs_pred(
    prefix = "eugr_hc_baseline2_rr"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r EUGR-HC prediction - Write stack 1, eval=FALSE, include=FALSE}
seq(nrow(filter(model_stacks, outcome == "survive" & type == "residual"))) |>
  lapply(
    \(x)
    filter(model_stacks, outcome == "survive" & type == "residual") |>
      slice(x)
  ) |>
  lapply(
    \(x)
    stack_prediction(
      lapply(modeval_data_set$eugr_hc$baseline$`20`, select, id, outcome) |>
        imap(
          ~ .x |>
            right_join(
              modeval_data_set[[
                  x$outcome[1]
                ]][[
                  x$type[1]
                ]][[
                  as.character(x$min_epv[1])
                ]][[
                  .y
                ]] |>
                select(-outcome)
              , by = join_by(id)
            )
        )
        , data_dir = "inst/extdata/modeval_data_set/"
        , model_dir = "inst/extdata/model/"
        , prior_model_name = "eugr_hc_baseline2_rr"
        , indices =  "id"
        , set = c("train", "validation", "test")
      ) |>
      c(stack_prediction(
        lapply(
            modeval_data_set_indep_test$eugr_hc$baseline$`20`
            , select, id, outcome
          ) |>
          imap(
            ~ .x |>
              right_join(
                modeval_data_set_indep_test[[
                    x$outcome[1]
                  ]][[
                    x$type[1]
                  ]][[
                    as.character(x$min_epv[1])
                  ]][[
                    .y
                  ]] |>
                  select(-outcome)
                , by = join_by(id)
              )
          )
          , data_dir = "inst/extdata/modeval_data_set/"
          , model_dir = "inst/extdata/model/"
          , prior_model_name = "eugr_hc_baseline2_rr"
          , indices =  "id"
          , set = c("independent_test")
        )
      ) |>
      imap(
        ~ .x |>
          filter(!is.na(outcome)) |>
          write_csv(
            paste0(
              "inst/extdata/modeval_data_set/eugr_hc_stack1_"
              , x$algorithm[1], "_", .y, ".csv"
            )
          )
      )
  )
```

```{r EUGR-HC prediction - Stack 1 results, include=FALSE}
eugr_hc_stack1_rr <-
  obtain_obs_pred(
    prefix = "eugr_hc_stack1_rr"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

eugr_hc_stack1_rf <-
  obtain_obs_pred(
    prefix = "eugr_hc_stack1_rf"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

eugr_hc_stack1_gbm <-
  obtain_obs_pred(
    prefix = "eugr_hc_stack1_gbm"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

eugr_hc_stack1_dnn <-
  obtain_obs_pred(
    prefix = "eugr_hc_stack1_dnn"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r EUGR-HC prediction - Stack 1 evaluation, eval=FALSE, include=FALSE}
eugr_hc_stack1_eval_df_list <-
  list(
    eugr_hc_stack1_rr = eugr_hc_stack1_rr
    , eugr_hc_stack1_rf = eugr_hc_stack1_rf
    , eugr_hc_stack1_gbm = eugr_hc_stack1_gbm
    , eugr_hc_stack1_dnn = eugr_hc_stack1_dnn
  )

eugr_hc_stack1_eval_calibration <-
  eugr_hc_stack1_eval_df_list |>
  lapply(\(x) lapply(x, calibration, seed = seed))

eugr_hc_stack1_eval_discrimination <-
  eugr_hc_stack1_eval_df_list[
    eugr_hc_stack1_eval_calibration |>
      select_well_calibrated_model()
  ] |>
  lapply(\(x) lapply(lapply(x, select, -id), discrimination, seed = seed))

eugr_hc_stack1_eval_discrimination |>
  select_best_auroc_lb_model() |>
  cat()
```

```{r EUGR-HC prediction - Write stack, eval=FALSE, include=FALSE}
seq(nrow(filter(model_stacks, outcome == "eugr_hc" & type == "residual"))) |>
  lapply(
    \(x)
    filter(model_stacks, outcome == "eugr_hc" & type == "residual") |>
      slice(x)
  ) |>
  lapply(
    \(x)
    stack_prediction(
        modeval_data_set[[
            x$outcome[1]
          ]][[
            x$type[1]
          ]][[
            as.character(x$min_epv[1])
          ]]
        , data_dir = "inst/extdata/modeval_data_set/"
        , model_dir = "inst/extdata/model/"
        , prior_model_name = "eugr_hc_stack1_dnn"
        , indices =  c("id", "t")
        , set = c("train", "validation", "test")
      ) |>
      c(stack_prediction(
          modeval_data_set_indep_test[[
              x$outcome[1]
            ]][[
              x$type[1]
            ]][[
              as.character(x$min_epv[1])
            ]]
          , data_dir = "inst/extdata/modeval_data_set/"
          , model_dir = "inst/extdata/model/"
          , prior_model_name = "eugr_hc_stack1_dnn"
          , indices =  c("id", "t")
          , set = c("independent_test")
        )
      ) |>
      imap(
        ~ .x |>
          filter(!is.na(outcome)) |>
          write_csv(
            paste0(
              "inst/extdata/modeval_data_set/eugr_hc_stack_"
              , x$algorithm[1], "_", .y, ".csv"
            )
          )
      )
  )
```

```{r EUGR-HC prediction - Stack results, include=FALSE}
eugr_hc_stack_rr <-
  obtain_obs_pred(
    prefix = "eugr_hc_stack_rr"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

eugr_hc_stack_rf <-
  obtain_obs_pred(
    prefix = "eugr_hc_stack_rf"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

eugr_hc_stack_gbm <-
  obtain_obs_pred(
    prefix = "eugr_hc_stack_gbm"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

eugr_hc_stack_dnn <-
  obtain_obs_pred(
    prefix = "eugr_hc_stack_dnn"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r EUGR-HC prediction - Stack evaluation, eval=FALSE, include=FALSE}
eugr_hc_stack_eval_df_list <-
  list(
    eugr_hc_stack_rr = eugr_hc_stack_rr
    , eugr_hc_stack_rf = eugr_hc_stack_rf
    , eugr_hc_stack_gbm = eugr_hc_stack_gbm
    , eugr_hc_stack_dnn = eugr_hc_stack_dnn
  )

eugr_hc_stack_eval_calibration <-
  eugr_hc_stack_eval_df_list |>
  lapply(\(x) lapply(x, calibration, seed = seed))

eugr_hc_stack_eval_discrimination <-
  eugr_hc_stack_eval_df_list[
    eugr_hc_stack_eval_calibration |>
      select_well_calibrated_model()
  ] |>
  lapply(\(x) lapply(lapply(x, select, -id), discrimination, seed = seed))

eugr_hc_stack_eval_discrimination |>
  select_best_auroc_lb_model() |>
  cat()
```

```{r EUGR-HC prediction - Required features, include=FALSE}
dr_before_modeling_desc$eugr_hc_baseline2_rr <-
  list(outcome = "eugr_hc", type = "baseline", min_epv = "20")

dr_before_modeling_desc$eugr_hc_stack1_dnn <-
  list(outcome = "survive", type = "residual", min_epv = "200")

dr_before_modeling_desc$eugr_hc_stack_rr <-
  list(outcome = "eugr_hc", type = "residual", min_epv = "20")

eugr_hc_pred_features <-
  c(baseline1 = "survive_baseline1_rr"
    ,baseline2 = "eugr_hc_baseline2_rr"
    , stack1 = "eugr_hc_stack1_dnn"
    , stack2 = "eugr_hc_stack_rr"
  )

eugr_hc_pred_features <-
  eugr_hc_pred_features |>
  obtain_pred_features(
    dr_before_modeling_desc[eugr_hc_pred_features] |>
      lapply(
        \(x)
        dr_model_desc |>
        filter(outcome == x$outcome & type == x$type & min_epv == x$min_epv)
      )
  )
```

## EUGR-BW prediction

```{r EUGR-BW prediction - Write baseline 2, eval=FALSE, include=FALSE}
seq(nrow(filter(model_stacks, outcome == "eugr_bw" & type == "baseline"))) |>
  lapply(
    \(x)
    filter(model_stacks, outcome == "eugr_bw" & type == "baseline") |>
      slice(x)
  ) |>
  lapply(
    \(x)
    stack_prediction(
        modeval_data_set[[
            x$outcome[1]
          ]][[
            x$type[1]
          ]][[
            as.character(x$min_epv[1])
          ]]
        , data_dir = "inst/extdata/modeval_data_set/"
        , model_dir = "inst/extdata/model/"
        , prior_model_name = "survive_baseline1_rr"
        , indices =  "id"
        , set = c("train", "validation", "test")
      ) |>
      c(stack_prediction(
          modeval_data_set_indep_test[[
              x$outcome[1]
            ]][[
              x$type[1]
            ]][[
              as.character(x$min_epv[1])
            ]]
          , data_dir = "inst/extdata/modeval_data_set/"
          , model_dir = "inst/extdata/model/"
          , prior_model_name = "survive_baseline1_rr"
          , indices =  "id"
          , set = c("independent_test")
        )
      ) |>
      imap(
        ~ .x |>
          filter(!is.na(outcome)) |>
          write_csv(
            paste0(
              "inst/extdata/modeval_data_set/eugr_bw_baseline2_"
              , x$algorithm[1], "_", .y, ".csv"
            )
          )
      )
  )
```

```{r EUGR-BW prediction - Baseline 2 results, include=FALSE}
eugr_bw_baseline2_rr <-
  obtain_obs_pred(
    prefix = "eugr_bw_baseline2_rr"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r EUGR-BW prediction - Write stack 1, eval=FALSE, include=FALSE}
seq(nrow(filter(model_stacks, outcome == "survive" & type == "residual"))) |>
  lapply(
    \(x)
    filter(model_stacks, outcome == "survive" & type == "residual") |>
      slice(x)
  ) |>
  lapply(
    \(x)
    stack_prediction(
      lapply(modeval_data_set$eugr_bw$baseline$`20`, select, id, outcome) |>
        imap(
          ~ .x |>
            right_join(
              modeval_data_set[[
                  x$outcome[1]
                ]][[
                  x$type[1]
                ]][[
                  as.character(x$min_epv[1])
                ]][[
                  .y
                ]] |>
                select(-outcome)
              , by = join_by(id)
            )
        )
        , data_dir = "inst/extdata/modeval_data_set/"
        , model_dir = "inst/extdata/model/"
        , prior_model_name = "eugr_bw_baseline2_rr"
        , indices =  "id"
        , set = c("train", "validation", "test")
      ) |>
      c(stack_prediction(
        lapply(
            modeval_data_set_indep_test$eugr_bw$baseline$`20`
            , select, id, outcome
          ) |>
          imap(
            ~ .x |>
              right_join(
                modeval_data_set_indep_test[[
                    x$outcome[1]
                  ]][[
                    x$type[1]
                  ]][[
                    as.character(x$min_epv[1])
                  ]][[
                    .y
                  ]] |>
                  select(-outcome)
                , by = join_by(id)
              )
          )
          , data_dir = "inst/extdata/modeval_data_set/"
          , model_dir = "inst/extdata/model/"
          , prior_model_name = "eugr_bw_baseline2_rr"
          , indices =  "id"
          , set = c("independent_test")
        )
      ) |>
      imap(
        ~ .x |>
          filter(!is.na(outcome)) |>
          write_csv(
            paste0(
              "inst/extdata/modeval_data_set/eugr_bw_stack1_"
              , x$algorithm[1], "_", .y, ".csv"
            )
          )
      )
  )
```

```{r EUGR-BW prediction - Stack 1 results, include=FALSE}
eugr_bw_stack1_rr <-
  obtain_obs_pred(
    prefix = "eugr_bw_stack1_rr"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

eugr_bw_stack1_rf <-
  obtain_obs_pred(
    prefix = "eugr_bw_stack1_rf"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

eugr_bw_stack1_gbm <-
  obtain_obs_pred(
    prefix = "eugr_bw_stack1_gbm"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

eugr_bw_stack1_dnn <-
  obtain_obs_pred(
    prefix = "eugr_bw_stack1_dnn"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r EUGR-BW prediction - Stack 1 evaluation, eval=FALSE, include=FALSE}
eugr_bw_stack1_eval_df_list <-
  list(
    eugr_bw_stack1_rr = eugr_bw_stack1_rr
    , eugr_bw_stack1_rf = eugr_bw_stack1_rf
    , eugr_bw_stack1_gbm = eugr_bw_stack1_gbm
    , eugr_bw_stack1_dnn = eugr_bw_stack1_dnn
  )

eugr_bw_stack1_eval_calibration <-
  eugr_bw_stack1_eval_df_list |>
  lapply(\(x) lapply(x, calibration, seed = seed))

eugr_bw_stack1_eval_discrimination <-
  eugr_bw_stack1_eval_df_list[
    eugr_bw_stack1_eval_calibration |>
      select_well_calibrated_model()
  ] |>
  lapply(\(x) lapply(lapply(x, select, -id), discrimination, seed = seed))

eugr_bw_stack1_eval_discrimination |>
  select_best_auroc_lb_model() |>
  cat()
```

```{r EUGR-BW prediction - Write stack, eval=FALSE, include=FALSE}
seq(nrow(filter(model_stacks, outcome == "eugr_bw" & type == "residual"))) |>
  lapply(
    \(x)
    filter(model_stacks, outcome == "eugr_bw" & type == "residual") |>
      slice(x)
  ) |>
  lapply(
    \(x)
    stack_prediction(
        modeval_data_set[[
            x$outcome[1]
          ]][[
            x$type[1]
          ]][[
            as.character(x$min_epv[1])
          ]]
        , data_dir = "inst/extdata/modeval_data_set/"
        , model_dir = "inst/extdata/model/"
        , prior_model_name = "eugr_bw_stack1_dnn"
        , indices =  c("id", "t")
        , set = c("train", "validation", "test")
      ) |>
      c(stack_prediction(
          modeval_data_set_indep_test[[
              x$outcome[1]
            ]][[
              x$type[1]
            ]][[
              as.character(x$min_epv[1])
            ]]
          , data_dir = "inst/extdata/modeval_data_set/"
          , model_dir = "inst/extdata/model/"
          , prior_model_name = "eugr_bw_stack1_dnn"
          , indices =  c("id", "t")
          , set = c("independent_test")
        )
      ) |>
      imap(
        ~ .x |>
          filter(!is.na(outcome)) |>
          write_csv(
            paste0(
              "inst/extdata/modeval_data_set/eugr_bw_stack_"
              , x$algorithm[1], "_", .y, ".csv"
            )
          )
      )
  )
```

```{r EUGR-BW prediction - Stack results, include=FALSE}
eugr_bw_stack_rr <-
  obtain_obs_pred(
    prefix = "eugr_bw_stack_rr"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

eugr_bw_stack_rf <-
  obtain_obs_pred(
    prefix = "eugr_bw_stack_rf"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

eugr_bw_stack_gbm <-
  obtain_obs_pred(
    prefix = "eugr_bw_stack_gbm"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

eugr_bw_stack_dnn <-
  obtain_obs_pred(
    prefix = "eugr_bw_stack_dnn"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r EUGR-BW prediction - Stack evaluation, eval=FALSE, include=FALSE}
eugr_bw_stack_eval_df_list <-
  list(
    eugr_bw_stack_rr = eugr_bw_stack_rr
    , eugr_bw_stack_rf = eugr_bw_stack_rf
    , eugr_bw_stack_gbm = eugr_bw_stack_gbm
    , eugr_bw_stack_dnn = eugr_bw_stack_dnn
  )

eugr_bw_stack_eval_calibration <-
  eugr_bw_stack_eval_df_list |>
  lapply(\(x) lapply(x, calibration, seed = seed))

eugr_bw_stack_eval_discrimination <-
  eugr_bw_stack_eval_df_list[
    eugr_bw_stack_eval_calibration |>
      select_well_calibrated_model()
  ] |>
  lapply(\(x) lapply(lapply(x, select, -id), discrimination, seed = seed))

eugr_bw_stack_eval_discrimination |>
  select_best_auroc_lb_model() |>
  cat()
```

```{r EUGR-BW prediction - Required features, include=FALSE}
dr_before_modeling_desc$eugr_bw_baseline2_rr <-
  list(outcome = "eugr_bw", type = "baseline", min_epv = "20")

dr_before_modeling_desc$eugr_bw_stack1_dnn <-
  list(outcome = "survive", type = "residual", min_epv = "200")

dr_before_modeling_desc$eugr_bw_stack_rr <-
  list(outcome = "eugr_bw", type = "residual", min_epv = "20")

eugr_bw_pred_features <-
  c(baseline1 = "survive_baseline1_rr"
    ,baseline2 = "eugr_bw_baseline2_rr"
    , stack1 = "eugr_bw_stack1_dnn"
    , stack2 = "eugr_bw_stack_rr"
  )

eugr_bw_pred_features <-
  eugr_bw_pred_features |>
  obtain_pred_features(
    dr_before_modeling_desc[eugr_bw_pred_features] |>
      lapply(
        \(x)
        dr_model_desc |>
        filter(outcome == x$outcome & type == x$type & min_epv == x$min_epv)
      )
  )
```

## Failed hearing test prediction

```{r Failed hearing prediction - Write stack, eval=FALSE, include=FALSE}
seq(nrow(filter(model_stacks, outcome == "hearing" & type == "residual"))) |>
  lapply(
    \(x)
    filter(model_stacks, outcome == "hearing" & type == "residual") |>
      slice(x)
  ) |>
  lapply(
    \(x)
    stack_prediction(
        modeval_data_set[[
            x$outcome[1]
          ]][[
            x$type[1]
          ]][[
            as.character(x$min_epv[1])
          ]]
        , data_dir = "inst/extdata/modeval_data_set/"
        , model_dir = "inst/extdata/model/"
        , prior_model_name = "survive_stack_dnn"
        , indices =  c("id", "t")
        , set = c("train", "validation", "test")
      ) |>
      c(stack_prediction(
          modeval_data_set_indep_test[[
              x$outcome[1]
            ]][[
              x$type[1]
            ]][[
              as.character(x$min_epv[1])
            ]]
          , data_dir = "inst/extdata/modeval_data_set/"
          , model_dir = "inst/extdata/model/"
          , prior_model_name = "survive_stack_dnn"
          , indices =  c("id", "t")
          , set = c("independent_test")
        )
      ) |>
      imap(
        ~ .x |>
          filter(!is.na(outcome)) |>
          write_csv(
            paste0(
              "inst/extdata/modeval_data_set/hearing_stack_"
              , x$algorithm[1], "_", .y, ".csv"
            )
          )
      )
  )
```

```{r Failed hearing prediction - Stack results, include=FALSE}
hearing_stack_rr <-
  obtain_obs_pred(
    prefix = "hearing_stack_rr"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

hearing_stack_rf <-
  obtain_obs_pred(
    prefix = "hearing_stack_rf"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

hearing_stack_gbm <-
  obtain_obs_pred(
    prefix = "hearing_stack_gbm"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )

hearing_stack_dnn <-
  obtain_obs_pred(
    prefix = "hearing_stack_dnn"
    , data_dir = "inst/extdata/modeval_data_set/"
    , model_dir = "inst/extdata/model/"
  )
```

```{r Failed hearing prediction - Stack evaluation, eval=FALSE, include=FALSE}
hearing_stack_eval_df_list <-
  list(
    hearing_stack_rr = hearing_stack_rr
    , hearing_stack_rf = hearing_stack_rf
    , hearing_stack_gbm = hearing_stack_gbm
    , hearing_stack_dnn = hearing_stack_dnn
  )

hearing_stack_eval_calibration <-
  hearing_stack_eval_df_list |>
  lapply(\(x) lapply(x, calibration, seed = seed))

hearing_stack_eval_discrimination <-
  hearing_stack_eval_df_list[
    hearing_stack_eval_calibration |>
      select_well_calibrated_model()
  ] |>
  lapply(\(x) lapply(lapply(x, select, -id), discrimination, seed = seed))

hearing_stack_eval_discrimination |>
  select_best_auroc_lb_model() |>
  cat()
```

```{r Failed hearing prediction - Required features, include=FALSE}
dr_before_modeling_desc$hearing_stack_rr <-
  list(outcome = "hearing", type = "residual", min_epv = "20")

hearing_pred_features <-
  c(baseline = "survive_baseline1_rr"
    , stack1 = "survive_stack_dnn"
    , stack2 = "hearing_stack_rr"
  )

hearing_pred_features <-
  hearing_pred_features |>
  obtain_pred_features(
    dr_before_modeling_desc[hearing_pred_features] |>
      lapply(
        \(x)
        dr_model_desc |>
        filter(outcome == x$outcome & type == x$type & min_epv == x$min_epv)
      )
  )
```

# Model evaluation

```{r Create empty list for model evaluation, include=FALSE}
eval <- list()
eval_plot <- list()
th <- list()
```

```{r Create a list of best model names for evaluation, include=FALSE}
eval_list <-
  c("survive_baseline1_rr"
    , "survive_stack_dnn"
    , "rop_severe_stack_rr"
    , "bpd_stack_rf"
    , "bpd_moderate_severe_stack_rf"
    , "eugr_hc_baseline2_rr"
    , "eugr_hc_stack_rr"
    , "eugr_bw_baseline2_rr"
    , "eugr_bw_stack_rr"
    , "hearing_stack_rr"
  )
```

```{r Create a list of best model evaluation data, include=FALSE}
eval_df_list <-
  list(
    survive_baseline1_rr
    , survive_stack_dnn
    , rop_severe_stack_rr
    , bpd_stack_rf
    , bpd_moderate_severe_stack_rf
    , eugr_hc_baseline2_rr
    , eugr_hc_stack_rr
    , eugr_bw_baseline2_rr
    , eugr_bw_stack_rr
    , hearing_stack_rr
  ) |>
  `names<-`(eval_list)
```

```{r Evaluate calibration, eval=FALSE, include=FALSE}
eval$calibration <-
  eval_list[str_detect(eval_list, "baseline")] |>
  `names<-`(eval_list[str_detect(eval_list, "baseline")]) |>
  lapply(\(x) lapply(eval_df_list[[x]], calibration, seed = seed)) |>
  c(list(
      survive_stack_dnn = survive_stack_eval_calibration$survive_stack_dnn
      , rop_severe_stack_rr =
        rop_severe_stack_eval_calibration$rop_severe_stack_rr
      , bpd_stack_rf = bpd_stack_eval_calibration$bpd_stack_rf
      , bpd_moderate_severe_stack_rf =
        bpd_moderate_severe_stack_eval_calibration$bpd_moderate_severe_stack_rf
      , eugr_hc_stack_rr = eugr_hc_stack_eval_calibration$eugr_hc_stack_rr
      , eugr_bw_stack_rr = eugr_bw_stack_eval_calibration$eugr_bw_stack_rr
      , hearing_stack_rr = hearing_stack_eval_calibration$hearing_stack_rr
    )
  )

eval$calibration <- eval$calibration[eval_list]
saveRDS(eval$calibration, "data/eval_calibration.rds")
```

```{r Load pre-evaluated calibration, include=FALSE}
eval$calibration <- readRDS("data/eval_calibration.rds")
```

```{r Evaluate decision, eval=FALSE, include=FALSE}
eval$decision <-
  eval_df_list |>
  pblapply(\(x) lapply(lapply(x, select, -id), decision, seed = seed))

saveRDS(eval$decision, "data/eval_decision.rds")
```

```{r Load pre-evaluated decision, include=FALSE}
eval$decision <- readRDS("data/eval_decision.rds")
```

```{r Evaluate discrimination, eval=FALSE, include=FALSE}
eval$discrimination <-
  eval_list[str_detect(eval_list, "baseline")] |>
  `names<-`(eval_list[str_detect(eval_list, "baseline")]) |>
  lapply(
    \(x)
    lapply(lapply(eval_df_list[[x]], select, -id), discrimination, seed = seed)
  ) |>
  c(list(
      survive_stack_dnn = survive_stack_eval_discrimination$survive_stack_dnn
      , rop_severe_stack_rr =
        rop_severe_stack_eval_discrimination$rop_severe_stack_rr
      , bpd_stack_rf = bpd_stack_eval_discrimination$bpd_stack_rf
      , bpd_moderate_severe_stack_rf =
        bpd_moderate_severe_stack_eval_discrimination[[
          "bpd_moderate_severe_stack_rf"
        ]]
      , eugr_hc_stack_rr = eugr_hc_stack_eval_discrimination$eugr_hc_stack_rr
      , eugr_bw_stack_rr = eugr_bw_stack_eval_discrimination$eugr_bw_stack_rr
      , hearing_stack_rr = hearing_stack_eval_discrimination$hearing_stack_rr
    )
  )

eval$discrimination <- eval$discrimination[eval_list]
saveRDS(eval$discrimination, "data/eval_discrimination.rds")
```

```{r Load pre-evaluated discrimination, include=FALSE}
eval$discrimination <- readRDS("data/eval_discrimination.rds")
```

```{r Determine threshold using train set, eval=FALSE, include=FALSE}
eval$threshold <-
  eval_df_list |>
  pblapply(
    \(x)
    lapply(x, select, -id)["train"] |>
    lapply(
      thresholding
      , standard = FALSE, optimal = TRUE, clinical = FALSE, seed = seed
    )
  )

saveRDS(eval$threshold, "data/eval_threshold.rds")
```

```{r Load pre-evaluated threshold, include=FALSE}
eval$threshold <- readRDS("data/eval_threshold.rds")
```

```{r Create a list of best model names with int for evaluation, include=FALSE}
eval_intermediate_list <-
  eval_list |>
  c("eugr_hc_stack1_dnn"
    , "eugr_bw_stack1_dnn"
  )
```

```{r Create a list of best model eval data with intermediary, include=FALSE}
eval_intermediate_df_list <-
  eval_df_list |>
  c(list(
      eugr_hc_stack1_dnn
      , eugr_bw_stack1_dnn
    )
  ) |>
  `names<-`(eval_intermediate_list)
```

```{r Create a list of best model feature data with intermediary, include=FALSE}
feature_intermediate_df_list <-
  paste0(
    "inst/extdata/modeval_data_set/", eval_intermediate_list, "_train.csv"
  ) |>
  `names<-`(eval_intermediate_list) |>
  lapply(read_csv, show_col_types = FALSE)
```

```{r Obtain pre-computed SHAPs of best model with intermediary, include=FALSE}
shap_values <-
  paste0(
    "inst/extdata/model/", eval_intermediate_list, "_train_shap_values.csv"
  ) |>
  `names<-`(eval_intermediate_list) |>
  lapply(read_csv, show_col_types = FALSE) |>
  lapply(numerize_chr_expected_value_if_any)
```

```{r Combine SHAP with features of best model with intermediary, include=FALSE}
shap_feature_values <-
  shap_values |>
  lapply(mutate, seq = seq(n())) |>
  lapply(gather, feature, shap_value, -seq) |>
  imap(
    ~ .x |>
      left_join(
        feature_intermediate_df_list[[.y]] |>
          unite_id_t_if_any() |>
          select(-outcome) |>
          mutate(expected_value = NA) |>
          mutate(seq = seq(n())) |>
          gather(feature, feature_value, -seq, -id_t)
        , by = join_by(seq, feature)
      )
  ) |>
  imap(
    ~ .x |>
      left_join(
        eval_intermediate_df_list[[.y]]$train |>
          mutate(seq = seq(n()))
        ,by = join_by(seq)
      )
  )
```

```{r Map back SHAP values to original features, include=FALSE}
ori_shap_feature_values <-
  shap_feature_values |>
  imap(~ obtain_old_dim_shap_values_if_any(.x, .y))
```

```{r Chain back SHAP values across stacked models, include=FALSE}
stacked_ori_shap_feature_values <-
  list(
    survive_baseline1_rr = ori_shap_feature_values$survive_baseline1_rr
    , survive_stack_dnn =
      ori_shap_feature_values$survive_stack_dnn |>
      obtain_prior_feature_shap_values_if_any(
        ori_shap_feature_values$survive_baseline1_rr
        , connector = "id"
      )
    , rop_severe_stack_rr =
      ori_shap_feature_values$rop_severe_stack_rr |>
      obtain_prior_feature_shap_values_if_any(
        ori_shap_feature_values$survive_stack_dnn
        , connector = "id_t"
      ) |>
      obtain_prior_feature_shap_values_if_any(
        ori_shap_feature_values$survive_baseline1_rr
        , connector = "id"
      )
    , bpd_stack_rf =
      ori_shap_feature_values$bpd_stack_rf |>
      obtain_prior_feature_shap_values_if_any(
        ori_shap_feature_values$survive_stack_dnn
        , connector = "id_t"
      ) |>
      obtain_prior_feature_shap_values_if_any(
        ori_shap_feature_values$survive_baseline1_rr
        , connector = "id"
      )
    , bpd_moderate_severe_stack_rf =
      ori_shap_feature_values$bpd_moderate_severe_stack_rf |>
      obtain_prior_feature_shap_values_if_any(
        ori_shap_feature_values$bpd_stack_rf
        , connector = "id_t"
      ) |>
      obtain_prior_feature_shap_values_if_any(
        ori_shap_feature_values$survive_stack_dnn
        , connector = "id_t"
      ) |>
      obtain_prior_feature_shap_values_if_any(
        ori_shap_feature_values$survive_baseline1_rr
        , connector = "id"
      )
    , eugr_hc_baseline2_rr =
      ori_shap_feature_values$eugr_hc_baseline2_rr |>
      obtain_prior_feature_shap_values_if_any(
        ori_shap_feature_values$survive_baseline1_rr
        , connector = "id"
      )
    , eugr_hc_stack_rr =
      ori_shap_feature_values$eugr_hc_stack_rr |>
      obtain_prior_feature_shap_values_if_any(
        ori_shap_feature_values$eugr_hc_stack1_dnn
        , connector = "id_t"
      ) |>
      obtain_prior_feature_shap_values_if_any(
        ori_shap_feature_values$eugr_hc_baseline2_rr
        , connector = "id"
      ) |>
      obtain_prior_feature_shap_values_if_any(
        ori_shap_feature_values$survive_baseline1_rr
        , connector = "id"
      )
    , eugr_bw_baseline2_rr =
      ori_shap_feature_values$eugr_bw_baseline2_rr |>
      obtain_prior_feature_shap_values_if_any(
        ori_shap_feature_values$survive_baseline1_rr
        , connector = "id"
      )
    , eugr_bw_stack_rr =
      ori_shap_feature_values$eugr_bw_stack_rr |>
      obtain_prior_feature_shap_values_if_any(
        ori_shap_feature_values$eugr_bw_stack1_dnn
        , connector = "id_t"
      ) |>
      obtain_prior_feature_shap_values_if_any(
        ori_shap_feature_values$eugr_bw_baseline2_rr
        , connector = "id"
      ) |>
      obtain_prior_feature_shap_values_if_any(
        ori_shap_feature_values$survive_baseline1_rr
        , connector = "id"
      )
    , hearing_stack_rr =
      ori_shap_feature_values$hearing_stack_rr |>
      obtain_prior_feature_shap_values_if_any(
        ori_shap_feature_values$survive_stack_dnn
        , connector = "id_t"
      ) |>
      obtain_prior_feature_shap_values_if_any(
        ori_shap_feature_values$survive_baseline1_rr
        , connector = "id"
      )
  )
```

## Evaluation metrics

### Survival baseline

```{r Determine threshold for survive baseline by train set, include=FALSE}
th$survive_baseline1_rr <-
  eval$threshold$survive_baseline1_rr$train |>
  filter(metric == "th") |>
  pull(avg)
```

```{r Evaluate survive baseline using test set, include=FALSE}
eval_plot$survive_baseline1_rr <-
  lapply(eval, \(x) x$survive_baseline1_rr$test) |>
  arrange_eval_plot(
    shap_feature_values = stacked_ori_shap_feature_values$survive_baseline1_rr
    , threshold = th$survive_baseline1_rr
    , dc_xby = 0.1, dc_yby = 0.1, dc_ta_angle = -60
    , seed = seed
  )
```

```{r figure-6, echo=FALSE, fig.height=6.5, fig.width=10}
eval_plot$survive_baseline1_rr
```

Figure 6. Survival baseline prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; (C) ROC curve; and (D) SHAP beeswarm plot. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics; SHAP, the Shapley additive explanation.

### Survival stack

```{r Determine threshold for survive stack by train set, include=FALSE}
th$survive_stack_dnn <-
  eval$threshold$survive_stack_dnn$train |>
  filter(metric == "th") |>
  pull(avg)
```

```{r Evaluate survive stack using test set, include=FALSE}
eval_plot$survive_stack_dnn <-
  lapply(eval, \(x) x$survive_stack_dnn$test) |>
  arrange_eval_plot(
    shap_feature_values = stacked_ori_shap_feature_values$survive_stack_dnn
    , threshold = th$survive_stack_dnn
    , dc_xby = 0.1, dc_yby = 0.1
    , dc_ta_angle = -60
    , seed = seed
    , transparency = 0.05
    , shap_height = 3.5
  )
```

```{r figure-7, echo=FALSE, fig.height=7.5, fig.width=10}
eval_plot$survive_stack_dnn
```

Figure 7. Survival stacked prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; (C) ROC curve; and (D) SHAP beeswarm plot. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics; SHAP, the Shapley additive explanation.

### Severe ROP stack

```{r Determine threshold for severe ROP stack by train set, include=FALSE}
th$rop_severe_stack_rr <-
  eval$threshold$rop_severe_stack_rr$train |>
  filter(metric == "th") |>
  pull(avg)
```

```{r Evaluate severe ROP stack using test set, include=FALSE}
eval_plot$rop_severe_stack_rr <-
  lapply(eval, \(x) x$rop_severe_stack_rr$test) |>
  arrange_eval_plot(
    shap_feature_values = stacked_ori_shap_feature_values$rop_severe_stack_rr
    , threshold = th$rop_severe_stack_rr
    , dc_xmax = 0.6, dc_xby = 0.1
    , dc_ymax = 0.15, dc_yby = 0.01
    , dc_ta_angle = -80
    , seed = seed
    , transparency = 0.05
    , shap_height = 4
  )
```

```{r figure-8, echo=FALSE, fig.height=8, fig.width=10}
eval_plot$rop_severe_stack_rr
```

Figure 8. Severe ROP stacked prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; (C) ROC curve; and (D) SHAP beeswarm plot. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics; SHAP, the Shapley additive explanation.

### BPD stack

```{r Determine threshold for BPD stack by train set, include=FALSE}
th$bpd_stack_rf <-
  eval$threshold$bpd_stack_rf$train |>
  filter(metric == "th") |>
  pull(avg)
```

```{r Evaluate BPD stack using test set, include=FALSE}
eval_plot$bpd_stack_rf <-
  lapply(eval, \(x) x$bpd_stack_rf$test) |>
  arrange_eval_plot(
    shap_feature_values = stacked_ori_shap_feature_values$bpd_stack_rf
    , threshold = th$bpd_stack_rf
    , dc_xmax = 0.6, dc_xby = 0.1
    , dc_ymax = 0.35, dc_yby = 0.05
    , dc_ta_angle = -70
    , seed = seed
    , transparency = 0.05
    , shap_height = 3
  )
```

```{r figure-9, echo=FALSE, fig.height=7, fig.width=10}
eval_plot$bpd_stack_rf
```

Figure 9. BPD stacked prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; (C) ROC curve; and (D) SHAP beeswarm plot. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics; SHAP, the Shapley additive explanation.

### Moderate/severe BPD stack

```{r Determine threshold for moderate/severe BPD stack by train set, include=FALSE}
th$bpd_moderate_severe_stack_rf <-
  eval$threshold$bpd_moderate_severe_stack_rf$train |>
  filter(metric == "th") |>
  pull(avg)
```

```{r Evaluate moderate/severe BPD stack using test set, include=FALSE}
eval_plot$bpd_moderate_severe_stack_rf <-
  lapply(eval, \(x) x$bpd_moderate_severe_stack_rf$test) |>
  arrange_eval_plot(
    shap_feature_values =
      stacked_ori_shap_feature_values$bpd_moderate_severe_stack_rf
    , threshold = th$bpd_moderate_severe_stack_rf
    , dc_xmax = 0.6, dc_xby = 0.1
    , dc_ymax = 0.35, dc_yby = 0.05
    , dc_ta_angle = -70
    , seed = seed
    , transparency = 0.05
    , shap_height = 3.5
  )
```

```{r figure-10, echo=FALSE, fig.height=7.5, fig.width=10}
eval_plot$bpd_moderate_severe_stack_rf
```

Figure 10. Moderate/severe BPD stacked prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; (C) ROC curve; and (D) SHAP beeswarm plot. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics; SHAP, the Shapley additive explanation.

### EUGR-HC baseline

```{r Determine threshold for EUGR-HC baseline by train set, include=FALSE}
th$eugr_hc_baseline2_rr <-
  eval$threshold$eugr_hc_baseline2_rr$train |>
  filter(metric == "th") |>
  pull(avg)
```

```{r Evaluate EUGR-HC baseline using test set, include=FALSE}
eval_plot$eugr_hc_baseline2_rr <-
  lapply(eval, \(x) x$eugr_hc_baseline2_rr$test) |>
  arrange_eval_plot(
    shap_feature_values = stacked_ori_shap_feature_values$eugr_hc_baseline2_rr
    , threshold = th$eugr_hc_baseline2_rr
    , dc_xmax = 0.6, dc_xby = 0.1
    , dc_ymax = 0.3, dc_yby = 0.05
    , dc_ta_angle = -75
    , seed = seed
  )
```

```{r figure-11, echo=FALSE, fig.height=6.5, fig.width=10}
eval_plot$eugr_hc_baseline2
```

Figure 11. EUGR-HC baseline prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; (C) ROC curve; and (D) SHAP beeswarm plot. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics; SHAP, the Shapley additive explanation.

### EUGR-HC stack

```{r Determine threshold for EUGR-HC stack by train set, include=FALSE}
th$eugr_hc_stack_rr <-
  eval$threshold$eugr_hc_stack_rr$train |>
  filter(metric == "th") |>
  pull(avg)
```

```{r Evaluate EUGR-HC stack using test set, include=FALSE}
eval_plot$eugr_hc_stack_rr <-
  lapply(eval, \(x) x$eugr_hc_stack_rr$test) |>
  arrange_eval_plot(
    shap_feature_values = stacked_ori_shap_feature_values$eugr_hc_stack_rr
    , threshold = th$eugr_hc_stack_rr
    , dc_xmax = 0.6, dc_xby = 0.1
    , dc_ymax = 0.3, dc_yby = 0.05
    , dc_ta_angle = -75
    , seed = seed
    , transparency = 0.05
    , shap_height = 4
  )
```

```{r figure-12, echo=FALSE, fig.height=8, fig.width=10}
eval_plot$eugr_hc_stack_rr
```

Figure 12. EUGR-HC stacked prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; (C) ROC curve; and (D) SHAP beeswarm plot. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics; SHAP, the Shapley additive explanation.

### EUGR-BW baseline

```{r Determine threshold for EUGR-BW baseline by train set, include=FALSE}
th$eugr_bw_baseline2_rr <-
  eval$threshold$eugr_bw_baseline2_rr$train |>
  filter(metric == "th") |>
  pull(avg)
```

```{r Evaluate EUGR-BW baseline using test set, include=FALSE}
eval_plot$eugr_bw_baseline2_rr <-
  lapply(eval, \(x) x$eugr_bw_baseline2_rr$test) |>
  arrange_eval_plot(
    shap_feature_values = stacked_ori_shap_feature_values$eugr_bw_baseline2_rr
    , threshold = th$eugr_bw_baseline2_rr
    , dc_xmax = 0.4, dc_xby = 0.1
    , dc_ymax = 0.25, dc_yby = 0.05
    , dc_ta_angle = -75
    , seed = seed
  )
```

```{r figure-13, echo=FALSE, fig.height=6.5, fig.width=10}
eval_plot$eugr_bw_baseline2
```

Figure 13. EUGR-BW baseline prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; (C) ROC curve; and (D) SHAP beeswarm plot. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics; SHAP, the Shapley additive explanation.

### EUGR-BW stack

```{r Determine threshold for EUGR-BW stack by train set, include=FALSE}
th$eugr_bw_stack_rr <-
  eval$threshold$eugr_bw_stack_rr$train |>
  filter(metric == "th") |>
  pull(avg)
```

```{r Evaluate EUGR-BW stack using test set, include=FALSE}
eval_plot$eugr_bw_stack_rr <-
  lapply(eval, \(x) x$eugr_bw_stack_rr$test) |>
  arrange_eval_plot(
    shap_feature_values = stacked_ori_shap_feature_values$eugr_bw_stack_rr
    , threshold = th$eugr_bw_stack_rr
    , dc_xmax = 0.6, dc_xby = 0.1
    , dc_ymax = 0.25, dc_yby = 0.05
    , dc_ta_angle = -80
    , seed = seed
    , transparency = 0.05
    , shap_height = 4
  )
```

```{r figure-14, echo=FALSE, fig.height=8, fig.width=10}
eval_plot$eugr_bw_stack
```

Figure 14. EUGR-BW stacked prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; (C) ROC curve; and (D) SHAP beeswarm plot. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics; SHAP, the Shapley additive explanation.

### Failed hearing test stack

```{r Determine threshold for failed hearing stack by train set, include=FALSE}
th$hearing_stack_rr <-
  eval$threshold$hearing_stack_rr$train |>
  filter(metric == "th") |>
  pull(avg)
```

```{r Evaluate failed hearing stack using test set, include=FALSE}
eval_plot$hearing_stack_rr <-
  lapply(eval, \(x) x$hearing_stack_rr$test) |>
  arrange_eval_plot(
    shap_feature_values = stacked_ori_shap_feature_values$hearing_stack_rr
    , threshold = th$hearing_stack_rr
    , dc_xmax = 0.3, dc_xby = 0.1
    , dc_ymax = 0.12, dc_yby = 0.02
    , dc_ta_angle = -80
    , seed = seed
    , transparency = 0.05
    , shap_height = 3.5
  )
```

```{r figure-15, echo=FALSE, fig.height=7.5, fig.width=10}
eval_plot$hearing_stack_rr
```

Figure 15. Failed hearing test stacked prediction model evaluation using test set for: (A) calibration plot; (B) decision curve; (C) ROC curve; and (D) SHAP beeswarm plot. Vertical dashed line in panels A and B indicates the chosen threshold. ROC, receiver operating characteristics; SHAP, the Shapley additive explanation.

## Predictive performance

```{r Compute CM using train-set threshold, eval=FALSE, include=FALSE}
eval$cm <-
  names(eval_df_list) |>
  `names<-`(names(eval_df_list)) |>
  pblapply(
    \(x)
    lapply(eval_df_list[[x]], select, -id)[
      c("validation", "test", "independent_test")
    ] |>
    lapply(
      thresholding
      , custom_metric = "th", custom_ref = th[[x]], seed = seed
    )
  )

saveRDS(eval$cm, "data/eval_cm.rds")
```

```{r Load pre-computed CM using train-set threshold, include=FALSE}
eval$cm <- readRDS("data/eval_cm.rds")
```

```{r Summarize confusion matrix using test set, include=FALSE}
cm_summary <-
  eval[c("calibration", "decision", "discrimination")] |>
  lapply(\(x) reduce(imap(x, ~ mutate(.x$test$metrics, model = .y)), rbind)) |>
  reduce(rbind) |>
  filter(term %in% c("AUC-ROC")) |>
  mutate(lb = estimate - ci, ub = estimate + ci) |>
  select(-ci) |>
  select(model, metric = term, avg = estimate, everything()) |>
  rbind(
    eval$cm |>
      imap(~ mutate(.x$test, model = .y)) |>
      reduce(rbind) |>
      filter(ref_type == "TH" & !metric %in% c("th", "nb")) |>
      mutate(metric = str_to_upper(metric)) |>
      select(-ref_type, -ref_value) |>
      select(model, metric, avg, everything())
  ) |>
  mutate_at(c("avg", "lb", "ub"), format, digits = 2) |>
  unite(ci, lb, ub, sep = ", ") |>
  mutate_at("ci", \(x) paste0("(", x, ")")) |>
  unite(summary, avg, ci, sep = " ") |>
  mutate(
    model = factor(model, unique(model))
    , metric = factor(metric, c("AUC-ROC", "F1", "TNR", "TPR", "PPV", "NPV"))
  ) |>
  spread(metric, summary) |>
  left_join(
    reduce(imap(th, ~ data.frame(model = .y, TH = .x)), rbind)
    , by = join_by(model)
  ) |>
  select(model, `AUC-ROC`, TH, everything())
```

```{r Summarize confusion matrix using indep-test set, include=FALSE}
cm_summary_indep_test <-
  eval[c("calibration", "decision", "discrimination")] |>
  lapply(
    \(x)
    reduce(imap(x, ~ mutate(.x$independent_test$metrics, model = .y)), rbind)
  ) |>
  reduce(rbind) |>
  filter(term %in% c("AUC-ROC")) |>
  mutate(lb = estimate - ci, ub = estimate + ci) |>
  select(-ci) |>
  select(model, metric = term, avg = estimate, everything()) |>
  rbind(
    eval$cm |>
      imap(~ mutate(.x$independent_test, model = .y)) |>
      reduce(rbind) |>
      filter(ref_type == "TH" & !metric %in% c("th", "nb")) |>
      mutate(metric = str_to_upper(metric)) |>
      select(-ref_type, -ref_value) |>
      select(model, metric, avg, everything())
  ) |>
  mutate_at(c("avg", "lb", "ub"), format, digits = 2) |>
  unite(ci, lb, ub, sep = ", ") |>
  mutate_at("ci", \(x) paste0("(", x, ")")) |>
  unite(summary, avg, ci, sep = " ") |>
  mutate(
    model = factor(model, unique(model))
    , metric = factor(metric, c("AUC-ROC", "F1", "TNR", "TPR", "PPV", "NPV"))
  ) |>
  spread(metric, summary) |>
  left_join(
    reduce(imap(th, ~ data.frame(model = .y, TH = .x)), rbind)
    , by = join_by(model)
  ) |>
  select(model, `AUC-ROC`, TH, everything())
```

```{r table-18, echo=FALSE}
cm_summary |>
  mutate(dataset = "Modeling") |>
  rbind(mutate(cm_summary_indep_test, dataset = "Independent test")) |>
  select(model, dataset, everything()) |>
  mutate(dataset = factor(dataset, unique(dataset))) |>
  arrange(model, dataset) |>
  mutate(model = ifelse(duplicated(model), "", model)) |>
  kable(
    caption = "Table 18. Predictive performance using test sets."
    , format = kable_format
  ) |>
  footnote(
    paste0(
      "AUC-ROC, area under the curve - receiver operating characteristics; "
      , "TH, the chosen threshold, balanced sensitivity and specificity; "
      , "F1, the F1-score; "
      , "TNR, true negative rate (specificity); "
      , "TPR, true positive rate (sensitivity/recall); "
      , "PPV, positive predictive value (precision); "
      , "NPV, negative predictive value. "
    )
  ) |>
  kable_classic() |>
  column_spec(1:7, extra_css = "vertical-align:top;")
```

```{r Compute val-CM by train-set cutoff for the selected time, include=FALSE}
eval$cm_selected_time_val <-
  modeval_data_set |>
  lapply(\(x) filter(x$residual$`20`$validation, !is.na(outcome))) |>
  lapply(
    \(x)
    x |>
      select_at(colnames(x)[colnames(x) != "ga_wk"]) |>
      left_join(
        modeval_data_set$survive$residual$`20`$validation |>
          select(id, t, ga_wk)
        , by = join_by(id, t)
      ) |>
      select(id, ga_wk, t, everything())
  ) |>
  lapply(
    \(x)
    c(1, 1*7, 2*7, 4*7, 6*7) |>
      `names<-`(paste0("t_", c(1, 1*7, 2*7, 4*7, 6*7))) |>
      lapply(
        \(y)
        x |>
          mutate(seq = seq(n())) |>
          filter(t == y) |>
          pull(seq)
      ) |>
      c(c(36*7) |>
          `names<-`(paste0("ga_wk_t_", c(36))) |>
          lapply(
            \(y)
            x |>
              mutate(seq = seq(n()), ga_wk_t = ga_wk * 7 + t) |>
              filter(ga_wk_t == y) |>
              pull(seq)
          )
      )
  ) |>
  imap(
    ~ .x |>
      lapply(
        \(x)
        list(
          eval_df =
            eval_df_list[
              !str_detect(names(eval_df_list), "baseline")
              & str_detect(names(eval_df_list), paste0("^", .y, "_"))
            ][[1]]$validation[x, , drop = FALSE] |>
            `rownames<-`(NULL) |>
            select(-id)
          , custom_ref =
            th[
              !str_detect(names(th), "baseline")
              & str_detect(names(th), paste0("^", .y, "_"))
            ][[1]]
        )
      )
  ) |>
  pblapply(
    \(x)
    x |>
      lapply(
        \(x)
        thresholding(
          eval_df = x$eval_df
          , custom_metric = "th"
          , custom_ref = x$custom_ref
          , seed = seed
        )
      )
  )
```

```{r Summarize CM using validation set for the selected time, include=FALSE}
cm_selected_time_summary_val <-
  eval$cm_selected_time_val |>
  imap(
    ~ names(.x) |>
      lapply(
        \(x)
        mutate(.x[[x]], outcome = .y, timing = x)
      ) |>
      reduce(rbind)
  ) |>
  reduce(rbind) |>
  filter(ref_type == "TH" & !metric %in% c("th", "nb")) |>
  mutate(metric = str_to_upper(metric)) |>
  select(-ref_type, -ref_value) |>
  select(outcome, metric, avg, everything())
```

```{r Compute CM using train-set threshold for the selected time, include=FALSE}
cm_selected_time_test_input <-
  modeval_data_set |>
  lapply(\(x) filter(x$residual$`20`$test, !is.na(outcome))) |>
  lapply(
    \(x)
    x |>
      select_at(colnames(x)[colnames(x) != "ga_wk"]) |>
      left_join(
        modeval_data_set$survive$residual$`20`$test |>
          select(id, t, ga_wk)
        , by = join_by(id, t)
      ) |>
      select(id, ga_wk, t, everything())
  ) |>
  lapply(
    \(x)
    c(1, 1*7, 2*7, 4*7, 6*7) |>
      `names<-`(paste0("t_", c(1, 1*7, 2*7, 4*7, 6*7))) |>
      lapply(
        \(y)
        x |>
          mutate(seq = seq(n())) |>
          filter(t == y) |>
          pull(seq)
      ) |>
      c(c(36*7) |>
          `names<-`(paste0("ga_wk_t_", c(36))) |>
          lapply(
            \(y)
            x |>
              mutate(seq = seq(n()), ga_wk_t = ga_wk * 7 + t) |>
              filter(ga_wk_t == y) |>
              pull(seq)
          )
      )
  ) |>
  imap(
    ~ .x |>
      lapply(
        \(x)
        list(
          eval_df =
            eval_df_list[
              !str_detect(names(eval_df_list), "baseline")
              & str_detect(names(eval_df_list), paste0("^", .y, "_"))
            ][[1]]$test[x, , drop = FALSE] |>
            `rownames<-`(NULL) |>
            select(-id)
          , custom_ref =
            th[
              !str_detect(names(th), "baseline")
              & str_detect(names(th), paste0("^", .y, "_"))
            ][[1]]
        )
      )
  )

eval$cm_selected_time <-
  cm_selected_time_test_input |>
  pblapply(
    \(x)
    x |>
      lapply(
        \(x)
        thresholding(
          eval_df = x$eval_df
          , custom_metric = "th"
          , custom_ref = x$custom_ref
          , seed = seed
        )
      )
  )
```

```{r Summarize CM using test set for the selected time, include=FALSE}
cm_selected_time_summary <-
  eval$cm_selected_time |>
  imap(
    ~ names(.x) |>
      lapply(
        \(x)
        mutate(.x[[x]], outcome = .y, timing = x)
      ) |>
      reduce(rbind)
  ) |>
  reduce(rbind) |>
  filter(ref_type == "TH" & !metric %in% c("th", "nb")) |>
  mutate(metric = str_to_upper(metric)) |>
  select(-ref_type, -ref_value) |>
  select(outcome, metric, avg, everything())
```

```{r Compute indep-test-CM by train-set cutoff for the sel time, include=FALSE}
cm_selected_time_indep_test_input <-
  modeval_data_set_indep_test |>
  lapply(\(x) filter(x$residual$`20`$independent_test, !is.na(outcome))) |>
  lapply(
    \(x)
    x |>
      select_at(colnames(x)[colnames(x) != "ga_wk"]) |>
      left_join(
        modeval_data_set_indep_test$survive$residual$`20`$independent_test |>
          select(id, t, ga_wk)
        , by = join_by(id, t)
      ) |>
      select(id, ga_wk, t, everything())
  ) |>
  lapply(
    \(x)
    c(1, 1*7, 2*7, 4*7, 6*7) |>
      `names<-`(paste0("t_", c(1, 1*7, 2*7, 4*7, 6*7))) |>
      lapply(
        \(y)
        x |>
          mutate(seq = seq(n())) |>
          filter(t == y) |>
          pull(seq)
      ) |>
      c(c(36*7) |>
          `names<-`(paste0("ga_wk_t_", c(36))) |>
          lapply(
            \(y)
            x |>
              mutate(seq = seq(n()), ga_wk_t = ga_wk * 7 + t) |>
              filter(ga_wk_t == y) |>
              pull(seq)
          )
      )
  ) |>
  imap(
    ~ .x |>
      lapply(
        \(x)
        list(
          eval_df =
            eval_df_list[
              !str_detect(names(eval_df_list), "baseline")
              & str_detect(names(eval_df_list), paste0("^", .y, "_"))
            ][[1]]$validation[x, , drop = FALSE] |>
            `rownames<-`(NULL) |>
            select(-id)
          , custom_ref =
            th[
              !str_detect(names(th), "baseline")
              & str_detect(names(th), paste0("^", .y, "_"))
            ][[1]]
        )
      )
  )

eval$cm_selected_time_indep_test <-
  cm_selected_time_indep_test_input |>
  pblapply(
    \(x)
    x |>
      lapply(
        \(x)
        thresholding(
          eval_df = x$eval_df
          , custom_metric = "th"
          , custom_ref = x$custom_ref
          , seed = seed
        )
      )
  )
```

```{r Summarize CM using indep-test set for the selected time, include=FALSE}
cm_selected_time_summary_indep_test <-
  eval$cm_selected_time_indep_test |>
  imap(
    ~ names(.x) |>
      lapply(
        \(x)
        mutate(.x[[x]], outcome = .y, timing = x)
      ) |>
      reduce(rbind)
  ) |>
  reduce(rbind) |>
  filter(ref_type == "TH" & !metric %in% c("th", "nb")) |>
  mutate(metric = str_to_upper(metric)) |>
  select(-ref_type, -ref_value) |>
  select(outcome, metric, avg, everything())
```

```{r figure-16, fig.height=3.5, fig.width=7}
mutate(cm_selected_time_summary_val, set = "Validation") |>
  rbind(mutate(cm_selected_time_summary, set = "Test")) |>
  timing_selection_plot("survive", "t_7")
```

Figure 16. Performance for predicting survival at particular time using the chosen threshold. The best timing was selected according to TPR and PPV using validation set. PPV, positive predictive value or precision; TPR, true positive rate or sensitivity.

```{r figure-17, fig.height=5, fig.width=7}
mutate(cm_selected_time_summary_val, set = "Validation") |>
  rbind(mutate(cm_selected_time_summary, set = "Test")) |>
  timing_selection_plot("rop_severe", "t_14")
```

Figure 17. Performance for predicting severe ROP at particular time using the chosen threshold. The best timing was selected according to TPR, TNR, and NPV using validation set. NPV, negative predictive value; ROP, retinopathy of prematurity; TNR, true negative rate or specificity; TPR, true positive rate or sensitivity.

```{r figure-18, fig.height=5, fig.width=7}
mutate(cm_selected_time_summary_val, set = "Validation") |>
  rbind(mutate(cm_selected_time_summary, set = "Test")) |>
  timing_selection_plot("bpd", "t_28")
```

Figure 18. Performance for predicting BPD at particular time using the chosen threshold. The best timing was selected according to TPR, TNR, and NPV using validation set. BPD, bronchopulmonary disease; NPV, negative predictive value; TNR, true negative rate or specificity; TPR, true positive rate or sensitivity.

```{r figure-19, fig.height=5, fig.width=7}
mutate(cm_selected_time_summary_val, set = "Validation") |>
  rbind(mutate(cm_selected_time_summary, set = "Test")) |>
  timing_selection_plot("bpd_moderate_severe", "t_28")
```

Figure 19. Performance for predicting moderate-to-severe BPD at particular time using the chosen threshold. The best timing was selected according to TPR, TNR, and NPV using validation set. BPD, bronchopulmonary disease; NPV, negative predictive value; TNR, true negative rate or specificity; TPR, true positive rate or sensitivity.

```{r figure-20, fig.height=5, fig.width=7}
mutate(cm_selected_time_summary_val, set = "Validation") |>
  rbind(mutate(cm_selected_time_summary, set = "Test")) |>
  timing_selection_plot("eugr_hc", "t_28")
```

Figure 20. Performance for predicting EUGR-HC at particular time using the chosen threshold. The best timing was selected according to TPR, PPV, TNR, and NPV using validation set. EUGR-HC, extrauterine growth restriction by head circumference; NPV, negative predictive value; PPV, positive predictive value or precision; TNR, true negative rate or specificity; TPR, true positive rate or sensitivity.

```{r figure-21, fig.height=5, fig.width=7}
mutate(cm_selected_time_summary_val, set = "Validation") |>
  rbind(mutate(cm_selected_time_summary, set = "Test")) |>
  timing_selection_plot("eugr_bw", "t_14")
```

Figure 21. Performance for predicting EUGR-BW at particular time using the chosen threshold. The best timing was selected according to TPR and NPV using validation set. EUGR-BW, extrauterine growth restriction by body weight; NPV, negative predictive value; TPR, true positive rate or sensitivity.

```{r figure-22, fig.height=5, fig.width=7}
mutate(cm_selected_time_summary_val, set = "Validation") |>
  rbind(mutate(cm_selected_time_summary, set = "Test")) |>
  timing_selection_plot("hearing", "t_14")
```

Figure 22. Performance for predicting failed hearing test at particular time using the chosen threshold. The best timing was selected according to TPR, TNR, and NPV using validation set. NPV, negative predictive value; TNR, true negative rate or specificity; TPR, true positive rate or sensitivity.

```{r figure-23, echo=FALSE, fig.height=5, fig.width=7}
figure23 <-
  mutate(cm_selected_time_summary, set = "Test") |>
  rbind(
    mutate(cm_selected_time_summary_indep_test, set = "Independent test")
  ) |>
  timing_selection_plot(show_plot = FALSE) |>
  timing_selection_filter()

figure23 |>
  filter(set == "Independent test") |>
  left_join(
    figure23 |>
      filter(set == "Test") |>
      select(outcome, metric, timing, ref = lb)
    , by = join_by(outcome, metric, timing)
  ) |>
  mutate(
    ci = ub - avg
    , avg = avg - ref
    , lb = avg - ci
    , ub = avg + ci
  ) |>
  select(-ci) |>
  mutate(lower = factor(ifelse(ub < -0.05, "Yes", "No"), c("Yes", "No"))) |>
  mutate(outcome = paste0(outcome, "\n", timing)) |>
  mutate(outcome = factor(outcome, unique(outcome))) |>
  mutate(metric = factor(metric, rev(c("TPR", "PPV", "F1", "TNR", "NPV")))) |>
  ggplot(aes(metric, avg, color = lower))  +
  geom_hline(yintercept = -0.05, lty = 2) +
  geom_errorbar(aes(ymin = lb, ymax = ub), width = 0.5, na.rm = TRUE) +
  geom_point(size = 1, na.rm = TRUE) +
  facet_grid(outcome ~ ., scale = "free", space = "free", switch = "y") +
  coord_flip() +
  xlab("") +
  scale_y_continuous(
    "Difference from test set (95% CI)"
    , breaks = seq(-1, 1, 0.1), limits = c(-0.25, 0.25)
  ) +
  scale_color_discrete("Less than\ntest set\nby >5% from\nlower bound?") +
  theme(
    strip.text.y.left = element_text(angle = 0, hjust = 1)
    , strip.background = element_blank()
    , strip.placement = "outside"
  )
```

Figure 23. Predictive performance using independent test sets at particular time.

```{r table-19, echo=FALSE}
cm_selected_time_summary |>
  mutate(dataset = "Modeling") |>
  rbind(
    cm_selected_time_summary_indep_test |>
      mutate(dataset = "Independent test")
  ) |>
  timing_selection_filter() |>
  mutate_at(c("avg", "lb", "ub"), format, digits = 2) |>
  unite(ci, lb, ub, sep = ", ") |>
  mutate_at("ci", \(x) paste0("(", x, ")")) |>
  unite(summary, avg, ci, sep = " ") |>
  mutate(
    outcome = factor(outcome, unique(outcome))
    , timing = factor(timing, unique(timing))
    , metric = factor(metric, c("AUC-ROC", "F1", "TNR", "TPR", "PPV", "NPV"))
  ) |>
  spread(metric, summary) |>
  left_join(
    reduce(imap(th, ~ data.frame(model = .y, TH = .x)), rbind) |>
      filter(!str_detect(model, "baseline")) |>
      mutate_at("model", str_remove_all, "_stack_[:alpha:]*") |>
      rename(outcome = model)
    , by = join_by(outcome)
  ) |>
  select(outcome, timing, TH, dataset, everything()) |>
  mutate(TH = ifelse(duplicated(paste0(outcome, timing, TH)), "", TH)) |>
  mutate(timing = ifelse(duplicated(paste0(outcome, timing)), "", timing)) |>
  mutate(outcome = ifelse(duplicated(outcome), "", outcome)) |>
  mutate(
    F1 = ifelse(str_detect(F1, "NaN"), "N/A*", F1)
    , TNR = ifelse(str_detect(TNR, "NaN"), "N/A†", TNR)
    , TPR = ifelse(str_detect(TPR, "NaN"), "N/A‡", TPR)
    , PPV = ifelse(str_detect(PPV, "NaN"), "N/A§", PPV)
    , NPV = ifelse(str_detect(NPV, "NaN"), "N/A¶", NPV)
  ) |>
  kable(
    caption =
      "Table 19. Predictive performance using test set at particular time."
    , format = kable_format
  ) |>
  footnote(
    paste0(
      "*, No positives or no predicted positives; "
      , "†, No negatives; "
      , "‡, No positives; "
      , "§, No predicted positives; "
      , "¶, No predicted negatives; "
      , "TH, the chosen threshold, balanced sensitivity and specificity; "
      , "F1, the F1-score; "
      , "TNR, true negative rate (specificity); "
      , "TPR, true positive rate (sensitivity/recall); "
      , "PPV, positive predictive value (precision); "
      , "NPV, negative predictive value. "
    )
  ) |>
  kable_classic() |>
  column_spec(1:7, extra_css = "vertical-align:top;")
```

```{r BPD indep-test discrimination, include=FALSE}
cm_selected_time_indep_test_bpd_disc <-
  cm_selected_time_indep_test_input$bpd$t_28$eval_df |>
  discrimination(seed = seed)
```

```{r figure-24, echo=FALSE, fig.height=2, fig.width=7}
cm_selected_time_indep_test_bpd_disc$metrics |>
  mutate(
    study = "Our study, 95% CI"
    , lb = estimate - ci
    , ub = estimate + ci
  ) |>
  select(study, avg = estimate, lb, ub) |>
  rbind(
    read_csv(
      "inst/extdata/10.1016_j.jpeds.2023.01.024.csv"
      , show_col_types = FALSE
    )
  ) |>
  rbind(
    read_csv(
        "inst/extdata/10.1038_s41390-022-02451-8.csv"
        , show_col_types = FALSE
      ) |>
      mutate(study = paste0(study, "*"))
  ) |>
  mutate(set = "External validation") |>
  rbind(
    read_csv(
        "inst/extdata/10.1016_j.heliyon.2023.e18964.csv"
        , show_col_types = FALSE
      ) |>
      mutate(set = "Internal validation")
  ) |>
  rbind(
    read_csv(
        "inst/extdata/10.1164_rccm.201101-0055OC.csv"
        , show_col_types = FALSE
      ) |>
      mutate(set = "Internal validation")
  ) |>
  mutate_at("study", \(x) factor(x, rev(unique(x)))) |>
  mutate_at("set", \(x) factor(x, rev(unique(x)))) |>
  ggplot(aes(study, avg, color = set)) +
  geom_errorbar(aes(ymin = lb, ymax = ub), width = 0.2) +
  geom_point() +
  coord_flip() +
  xlab("") +
  ylab("c-statistic") +
  scale_color_discrete("")
```

Figure 24. Predictive performance of BPD prediction models in our study versus previous studies. *, Kwok TC et al. (2023) did not summarize the estimates; hence, each individual's c-statistics are shown (n=6); BPD, bronchopulmonary disease; CI, confidence interval; PI, prediction interval.

```{r Moderate/severe BPD test discrimination, include=FALSE}
cm_selected_time_test_bpd_moderate_severe_disc <-
  cm_selected_time_test_input$bpd_moderate_severe$t_28$eval_df |>
  discrimination(seed = seed)
```

```{r Moderate/severe BPD indep-test discrimination, include=FALSE}
cm_selected_time_indep_test_bpd_moderate_severe_disc <-
  cm_selected_time_indep_test_input$bpd_moderate_severe$t_28$eval_df |>
  discrimination(seed = seed)
```

```{r figure-25, echo=FALSE, fig.height=1.5, fig.width=7}
cm_selected_time_test_bpd_moderate_severe_disc$metrics |>
  mutate(
    study = "Our study, 95% CI (internal validation)"
    , lb = estimate - ci
    , ub = estimate + ci
  ) |>
  select(study, avg = estimate, lb, ub) |>
  rbind(
    cm_selected_time_indep_test_bpd_moderate_severe_disc$metrics |>
      mutate(
        study = "Our study, 95% CI (external validation)"
        , lb = estimate - ci
        , ub = estimate + ci
      ) |>
      select(study, avg = estimate, lb, ub)
  ) |>
  rbind(
    read_csv(
      "inst/extdata/10.3389_fped.2023.1102878.csv"
      , show_col_types = FALSE
    )
  ) |>
  mutate_at("study", \(x) factor(x, rev(unique(x)))) |>
  ggplot(aes(study, avg)) +
  geom_errorbar(aes(ymin = lb, ymax = ub), width = 0.2) +
  geom_point() +
  coord_flip() +
  xlab("") +
  scale_y_continuous("c-statistic", limits = c(0.5, 1))
```

Figure 25. Predictive performance of moderate/severe BPD prediction models in our study versus previous studies. BPD, bronchopulmonary disease; CI, confidence interval.

# Model deployment

```{r Compile any-outcome baseline & stack predictions per id-t, include=FALSE}
pred_results_train <-
  c("baseline", "stack") |>
  lapply(
    \(x)
    names(eval_df_list)[str_detect(names(eval_df_list), x)] |>
      `names<-`(names(eval_df_list)[str_detect(names(eval_df_list), x)]) |>
      imap(
        ~ .x |>
          obtain_pred(
            data_dir = "inst/extdata/modeval_data_set/"
            , model_dir = "inst/extdata/model/"
            , identifiers =
              ifelse(c(x, x) %in% "baseline", c("id", "id"), c("id", "t")) |>
              unique()
          ) |>
          mutate(model = .y) |>
          left_join(
            reduce(imap(th, ~ data.frame(model = .y, TH = .x)), rbind)
            , by = join_by(model)
          ) |>
          select(-model) |>
          mutate(
            target =
              str_remove_all(.y, paste0("_", x, "[:digit:]*|_rr|_rf|_gbm|_dnn"))
          ) |>
          select(target, everything())
      ) |>
      reduce(rbind) |>
      rename_at("pred", \(y) x) |>
      rename_at("TH", \(y) paste0(x, "_th"))
  ) |>
  reduce(right_join, by = join_by(id, target)) |>
  mutate_at("id", as.character) |>
  left_join(
    modeval_data_set |>
      imap(~ mutate(select(.x$residual$`20`$train, id, t, outcome), target = .y)) |>
      reduce(rbind)
    , by = join_by(id, t, target)
  ) |>
  left_join(select(modeval_data, id, t, death_age), by = join_by(id, t)) |>
  mutate(death_age = (round(death_age) + 1))
```

```{r Create empty list to select prediction results, include=FALSE}
selected_pred_results <- list()
```

```{r Truly (~90%)-predicted die in 14-42 days, include=FALSE}
selected_pred_results$die_14_to_42_day_true <-
  pred_results_train |>
  filter(
    id %in% c(
      pred_results_train |>
        filter(target == "survive") |>
        filter(outcome == 0 & stack < stack_th) |>
        filter(death_age >= 14 & death_age <= 42) |>
        group_by(id) |>
        filter(n() >= 0.9 * 42) |>
        ungroup() |>
        pull(id)
    )
  )
```

```{r Falsely (1+)-predicted die in 14-42 days, include=FALSE}
selected_pred_results$die_14_to_42_day_false <-
  pred_results_train |>
  filter(
    id %in% c(
      pred_results_train |>
        filter(target == "survive") |>
        filter(outcome == 1 & stack < stack_th) |>
        pull(id)
    )
  )
```

```{r Truly (~50%)-predicted survive, include=FALSE}
selected_pred_results$survive_true <-
  pred_results_train |>
  filter(
    id %in% c(
      pred_results_train |>
        filter(target == "survive") |>
        filter(outcome == 1 & stack >= stack_th) |>
        group_by(id) |>
        filter(n() >= 0.5 * 42) |>
        ungroup() |>
        pull(id)
    )
  )
```

```{r Falsely (~20%)-predicted survive, include=FALSE}
selected_pred_results$survive_false <-
  pred_results_train |>
  filter(
    id %in% c(
      pred_results_train |>
        filter(target == "survive") |>
        filter(outcome == 0 & stack >= stack_th) |>
        group_by(id) |>
        filter(n() >= 0.2 * 42) |>
        ungroup() |>
        pull(id)
    )
  )
```

```{r Truly (~20%)-pred ous among truly (~50%)-pred survivors, include=FALSE}
selected_pred_results$other_outcomes_true <-
  selected_pred_results$survive_true |>
  filter(
    id %in% c(
      c("rop_severe"
        , "bpd", "bpd_moderate_severe"
        , "eugr_hc", "eugr_bw"
        , "hearing"
        ) |>
        lapply(
          \(x)
          selected_pred_results$survive_true |>
            filter(target == x) |>
            filter(outcome == 1 & stack >= stack_th) |>
            group_by(id) |>
            filter(n() >= 0.2 * 42) |>
            ungroup() |>
            pull(id)
        ) |>
        reduce(intersect)
    )
  )
```

```{r Falsely (~20%)-pred ous among truly (~50%)-pred survivors, include=FALSE}
selected_pred_results$other_outcomes_false <-
  selected_pred_results$survive_true |>
  filter(
    id %in% c(
      c("rop_severe"
        , "bpd", "bpd_moderate_severe"
        , "eugr_hc", "eugr_bw"
        , "hearing"
        ) |>
        lapply(
          \(x)
          selected_pred_results$survive_true |>
            filter(target == x) |>
            filter(outcome == 1 & stack < stack_th) |>
            group_by(id) |>
            filter(n() >= 0.2 * 42) |>
            ungroup() |>
            pull(id)
        ) |>
        reduce(intersect)
    )
  )
```

```{r Randomly select ID for each evaluation type, include=FALSE}
selected_pred_ids <- c()

for(i in names(selected_pred_results[sapply(selected_pred_results, nrow) > 0])){
  set.seed(seed)
  selected_pred_ids <-
    selected_pred_ids |>
    c(`names<-`(sample(unique(selected_pred_results[[i]]$id), 1), i))
}

selected_pred_ids <-
  data.frame(
    eval_type = names(selected_pred_ids)
    , id = selected_pred_ids
    , row.names = NULL
  )
```

```{r Compile demo trajectories, include=FALSE}
demo_trajectories <-
  selected_pred_ids |>
  filter(eval_type != "survive_true") |>
  inner_join(
    pred_results_train, by = join_by(id), relationship = "many-to-many"
  )

demo_trajectories <-
  demo_trajectories |>
  select(-t, -stack, -stack_th) |>
  rename(pred = baseline, th = baseline_th) |>
  unique() |>
  mutate(t = 0) |>
  rbind(
    demo_trajectories |>
      select(-baseline, -baseline_th) |>
      rename(pred = stack, th = stack_th)
  ) |>
  mutate_at(c("eval_type", "target"), \(x) factor(x, unique(x))) |>
  arrange(eval_type, target, t)
```

```{r figure-26, echo=FALSE, fig.height=5, fig.width=7}
demo_trajectories |>
  filter(eval_type == "other_outcomes_true") |>
  mutate(
    pred_class = ifelse(pred >= th, "+", "-")
    , outcome = ifelse(outcome == 1, "+", "-")
    , eval =
      case_when(
        outcome == "+" & pred_class == "+" ~ "TP"
        , outcome == "+" & pred_class == "-" ~ "FN"
        , outcome == "-" & pred_class == "+" ~ "FP"
        , outcome == "-" & pred_class == "-" ~ "TN"
      )
    , th_type = ifelse(t == 0, "at birth", "during care")
  ) |>
  filter(!is.na(eval)) |>
  ggplot(aes(t, pred, color = target)) +
  geom_vline(xintercept = c(14, 28, 42), color = "grey", linewidth = 2, lty = 1) +
  geom_smooth(method = "loess", formula = y ~ x, se = FALSE, na.rm = TRUE) +
  geom_point(aes(shape = eval), na.rm = TRUE) +
  scale_x_continuous(
    breaks = c(0, 7, 14, 21, 28, 35, 42), limits = c(0, 42)
  ) +
  scale_linetype_manual(values = c(3, 4)) +
  ylab("") +
  theme(
    strip.text.y.left = element_text(angle = 0)
    , strip.placement = "outside"
  )
```

Figure 26. A case with ~50% truly-predicted survive and ~20% truly-predicted positives for other outcomes.

```{r Plot demo trajectories, include=FALSE}
demo_trajectories_plot <-
  list(TRUE, FALSE) |>
  lapply(
    \(x)
    demo_trajectories |>
      filter(str_detect(eval_type, "die_14_to_42|survive_false") ==  x) |>
      filter(str_detect(target, "survive") ==  x) |>
      mutate(
        pred_class = ifelse(pred >= th, "+", "-")
        , outcome = ifelse(outcome == 1, "+", "-")
        , eval =
          case_when(
            outcome == "+" & pred_class == "+" ~ "TP"
            , outcome == "+" & pred_class == "-" ~ "FN"
            , outcome == "-" & pred_class == "+" ~ "FP"
            , outcome == "-" & pred_class == "-" ~ "TN"
          )
        , th_type = ifelse(t == 0, "at birth", "during care")
      ) |>
      filter(!is.na(eval)) |>
      ggplot(aes(t, pred)) +
      geom_vline(aes(xintercept = death_age), lty = 2, na.rm = TRUE) +
      geom_hline(aes(yintercept = th, lty = th_type), na.rm = TRUE) +
      geom_line(na.rm = TRUE) +
      geom_point(aes(color = eval), size = 0.5, na.rm = TRUE) +
      facet_grid(
        target ~ eval_type
        , switch = "y", scales = "free_y"
      ) +
      scale_x_continuous(
        breaks = c(0, 7, 14, 21, 28, 35, 42), limits = c(0, 42)
      ) +
      scale_linetype_manual(values = c(3, 4)) +
      ylab("") +
      theme(
        strip.text.y.left = element_text(angle = 0)
        , strip.placement = "outside"
      )
  )
```

```{r figure-27, echo=FALSE, fig.height=3, fig.width=7}
demo_trajectories_plot[[1]]
```

Figure 27. Survival trajectories with ~90% truly and 1+ falsely predicted deaths and ~20% falsely predicted survive. Vertical dashed line indicates death age.

```{r figure-28, echo=FALSE, fig.height=5, fig.width=7}
demo_trajectories_plot[[2]]
```

Figure 28. Other outcome trajectories with ~20% truly and ~20% falsely predicted outcomes among ~50% truly predicted survive.

```{r Required features, include=FALSE}
pred_features <-
  list(
    survive = survive_pred_features
    , rop_severe = rop_severe_pred_features
    , bpd = bpd_pred_features
    , bpd_moderate_severe = bpd_moderate_severe_pred_features
    , eugr_hc = eugr_hc_pred_features
    , eugr_bw = eugr_bw_pred_features
    , hearing = hearing_pred_features
  ) |>
  lapply(gather, layer, used, -feature) |>
  imap(~ mutate(.x, outcome = .y)) |>
  reduce(rbind) |>
  mutate(
    layer =
      paste0(layer, ifelse(!str_detect(layer, "[:digit:]$"), "1", ""))
    , timing =
      ifelse(str_detect(layer, "baseline"), "at_birth", "during_care")
  ) |>
  select(outcome, timing, feature, used) |>
  mutate_at(c("outcome", "timing"), \(x) factor(x, unique(x))) |>
  group_by(outcome, timing, feature) |>
  summarize(used = as.integer(sum(used) > 0, 1, 0), .groups = "drop") |>
  filter(used == 1) |>
  group_by(outcome, feature) |>
  mutate(used = n()) |>
  ungroup() |>
  left_join(
    raw_data_new_colname |>
      select(feature = new_colname, label = old_colname) |>
      unique()
    , by = join_by(feature)
  ) |>
  mutate(feature = ifelse(is.na(label), feature, label)) |>
  select(-label) |>
  group_by(outcome, timing) |>
  summarize(
    n1 = sum(used == 1)
    , n2 = sum(used > 1)
    , features = paste0(feature, collapse = ", ")
    , .groups = "drop"
  ) |>
  mutate(
    n =
      paste0(
        ifelse(n2 == 0 | timing == "at_birth", n1, paste0(n2, " + ", n1 + 1))
        , " features:"
      )
    , features =
      ifelse(timing == "at_birth", features, paste0(features, ", Age_D"))
  ) |>
  select(-n1, -n2) |>
  unite(features, n, features, sep = " ") |>
  spread(timing, features, fill = "") |>
  left_join(
    raw_data_new_colname |>
      select(outcome = new_colname, label = old_colname) |>
      unique()
    , by = join_by(outcome)
  ) |>
  mutate(outcome = ifelse(is.na(label), outcome, label)) |>
  select(-label) |>
  mutate(outcome = str_replace_all(outcome, "^bpd", "BPD"))
```

```{r table-20, echo=FALSE}
pred_features |>
  kable(
    caption = "Table 20. Required features."
    , format = kable_format
  ) |>
  kable_classic() |>
  column_spec(1:3, extra_css = "vertical-align:top;")
```

```{r eval=FALSE, include=FALSE}
saveRDS(dim_red_train_regression, "data/dep_dim_red_train_regression.rds")
saveRDS(new_dimension_new_name, "data/dep_new_dimension_new_name.rds")
dr_model$survive$baseline$`20` |>
  saveRDS("data/dep_dr_model_survive_baseline_20.rds")
dr_model$survive$residual$`200` |>
  saveRDS("data/dep_dr_model_survive_residual_200.rds")
```

## Severe ROP

```{r Severe ROP - Check input its range, eval=FALSE, include=FALSE}
modeval_data_set_ori$survive$baseline$train |>
  summary()

modeval_data_set$survive$baseline$`20`$train |>
  summary()

modeval_data_set_ori$survive$residual$train |>
  filter(t == 14) |>
  summary()

modeval_data_set_ori$rop_severe$residual$train |>
  filter(t == 14) |>
  summary()
```

```{r Severe ROP - Check models and inputs, eval=FALSE, include=FALSE}
model_stacks

eval_intermediate_list

modeval_data_set_ori$survive$baseline$train |>
  dep_reduce_dim_pca(
    dr_model$survive$baseline$`20`
    , "survive", "baseline", "20"
  )

modeval_data_set$survive$baseline$`20`$train

modeval_data_set_ori$survive$residual$train |>
  dep_reduce_dim_pca(
    dr_model$survive$residual$`200`
    , "survive", "residual", "200"
  ) |>
  mutate(prior = NA) |>
  select(id, prior, everything())

modeval_data_set$survive$residual$`200`$train

modeval_data_set_ori$rop_severe$residual$train |>
  mutate(prior = NA) |>
  select(id, prior, everything())

modeval_data_set$rop_severe$residual$`20`$train

th$rop_severe_stack_rr
```

## EUGR-HC

```{r EUGR-HC - Check input its range, eval=FALSE, include=FALSE}
modeval_data_set_ori$survive$baseline$train |>
  summary()

modeval_data_set$survive$baseline$`20`$train |>
  summary()

modeval_data_set_ori$eugr_hc$baseline$train |>
  summary()

modeval_data_set_ori$survive$residual$train |>
  filter(t == 28) |>
  summary()

modeval_data_set_ori$eugr_hc$residual$train |>
  filter(t == 28) |>
  summary()
```

```{r EUGR-HC - Check models and inputs, eval=FALSE, include=FALSE}
model_stacks

eval_intermediate_list

modeval_data_set_ori$survive$baseline$train |>
  dep_reduce_dim_pca(
    dr_model$survive$baseline$`20`
    , "survive", "baseline", "20"
  )

modeval_data_set$survive$baseline$`20`$train

modeval_data_set$eugr_hc$baseline$`20`$train

modeval_data_set_ori$survive$residual$train |>
  dep_reduce_dim_pca(
    dr_model$survive$residual$`200`
    , "survive", "residual", "200"
  ) |>
  mutate(prior = NA) |>
  select(id, prior, everything())

modeval_data_set$survive$residual$`200`$train

modeval_data_set_ori$eugr_hc$residual$train |>
  mutate(prior = NA) |>
  select(id, prior, everything())

modeval_data_set$eugr_hc$residual$`20`$train

th$eugr_hc_stack_rr
```

## Failed hearing test

```{r Failed hearing test - Check input its range, eval=FALSE, include=FALSE}
modeval_data_set_ori$survive$baseline$train |>
  summary()

modeval_data_set$survive$baseline$`20`$train |>
  summary()

modeval_data_set_ori$survive$residual$train |>
  filter(t == 42) |>
  summary()

modeval_data_set_ori$hearing$residual$train |>
  filter(t == 42) |>
  summary()
```

```{r Failed hearing test - Check models and inputs, eval=FALSE, include=FALSE}
model_stacks

eval_intermediate_list

modeval_data_set_ori$survive$baseline$train |>
  dep_reduce_dim_pca(
    dr_model$survive$baseline$`20`
    , "survive", "baseline", "20"
  )

modeval_data_set$survive$baseline$`20`$train

modeval_data_set_ori$survive$residual$train |>
  dep_reduce_dim_pca(
    dr_model$survive$residual$`200`
    , "survive", "residual", "200"
  ) |>
  mutate(prior = NA) |>
  select(id, prior, everything())

modeval_data_set$survive$residual$`200`$train

modeval_data_set$hearing$residual$`20`$train

th$hearing_stack_rr
```




































































